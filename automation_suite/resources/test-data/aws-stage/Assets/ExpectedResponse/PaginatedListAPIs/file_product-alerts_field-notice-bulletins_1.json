{
    "data": [
        {
            "fieldNoticeId": 3028,
            "status": "P",
            "bulletinLastUpdated": "2007-07-27T09:15:04Z",
            "bulletinTitle": "FN# 3028 - Port Adaptor Compatibility for 7200 VXR Routers",
            "bulletinFirstPublished": "1999-02-23T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "Some Port Adapters currently used in Cisco 7200 routers will not function in Cisco 7200 VXR routers due to the new and higher speed PCI midplane unless the Port Adapter Arbiter EPLD has been upgraded. The Arbiter EPLD change is necessary for correct operation and forward compatibility with 7200 VXR routers. The down-version Port Adapters will not be recognized, will fail diagnostics, and will not pass traffic. Not all affected port adapters are upgradeable, therefore some are not supported in the 7200 VXR routers. In addition, all other port adapters not addressed in this field notice are compatible with the 7200 and 7200 VXR routers and require no action or upgrade unless previously documented as not supported in the 7200 router platform. Those will also not be supported in the 7200 VXR routers. Details below. Backward compatibility with 7200 routers is maintained. There is no risk to customers who have 7200 routers.",
            "background": "When port adaptors without the Arbiter EPLD upgrade are installed in a 7200 VXR router, they will not operate properly.  The down-version Port Adapters will not be recognized, will fail diagnostics, and will not pass traffic.  Not all port adapters are upgradeable or supported in the 7200 VXR router.<BR><BR>The Cisco 7200 VXR routers support all port adapters supported on the Cisco 7200, except for following:<BR><BR>FDDI Port Adapters:<BR>PA-F-MM<BR>PA-F-SM<BR>PA-F/FD-MM<BR>PA-F/FD-SM\t<BR><BR>Token Ring Interface:<BR>PA-4R<BR>PA-4R-FDX  <BR><BR>Channelized T1/E1 Port Adapters:<BR>PA-2CT1/PRI<BR>PA-2CE1/PRI-75<BR>PA-2CE1/PRI-120\t<BR><BR>Channelized DS3 Port Adapter:<BR>PA-CT3/4T1 (dual wide)<BR><BR>Compression Hardware Accelerator:<BR>SA-COMP/1<BR>SA-COMP/4<BR><BR>The following PAs are supported with 7200 VXR router and require the minimum hardware revision listed below.<BR>              <BR>  PA-8E, Rev. 1.14<BR>  PA-4E, Rev. 1.14<BR>  PA-5EFL, Rev. 1.5<BR>  PA-8T-V35, Rev. 1.13<BR>  PA-8T-232, Rev. 1.4<BR>  PA-8T-X21, Rev. 1.13<BR>  PA-H, Rev. 1.17<BR>  PA-2H, Rev. 1.3<BR>  PA-A3-T3, Rev. 2.0<BR>  PA-A3-E3, Rev. 2.0<BR>  PA-A3-OC3 MM, Rev. 2.0<BR>  PA-A3-OC3 SMI, Rev. 2.0<BR>  PA-A3-OC3 SML, Rev. 2.0<BR><BR>All other port adapters not listed are compatible with 7200 and 7200 VXR routers unless previously documented as not supported in the 7200 router.  Those will also not be supported in the 7200 VXR router.<BR><BR>There is no risk to customers who have 7200 routers (non-VXR routers).\r\n&nbsp;",
            "problemSymptoms": "When port adaptors without the Arbiter EPLD upgrade are installed in a system with a 7200 VXR router, they will not operate properly.  The down-version Port Adapters will not be recognized, will fail diagnostics, and will not pass traffic.  There is no risk to customers who have 7200 routers.<BR><BR>An example of the error message of a PA that requires a minimum hardware level in a 7200 VXR router is as follows:<BR><BR><pre><font face=\"courier\"><BR><font color=\"blue\"><b>%PA-3-REVNOTSUPPORTED: PA in slot2 (Ethernet) requires base h/w revision of (1.14) for this chassis</b></font><BR></font></pre><BR><BR>An example of the error message of a PA that is not supported all with a 7200 VXR router is as follows:<BR><BR>(Example for a PA-2CT1/PRI)<BR><pre><font face=\"courier\"><BR>00:00:28: %OIR-6-INSCARD: Card inserted in slot 1, interfaces administratively shut down<BR>00:00:29: <font color=\"blue\"><b>%PA-3-NOTSUPPORTED: PA in slot1 (Channelized T1) is not supported on this chassis</b></font><BR>00:00:29: %PA-3-DEACTIVATED: port adapter in bay [1] powered off.<BR>00:00:29: %PA-2-PABRIDGE: Failed to config bridge for PA 1<BR></font></pre><BR><BR>(Example for a PA-F/FD-MM)<BR><pre><font face=\"courier\"><BR>00:01:37: %OIR-6-INSCARD: Card inserted in slot 3, interfaces administratively shut down<BR>00:01:38: <font color=\"blue\"><b>%PA-3-NOTSUPPORTED: PA in slot3 (FD FDDI DAS (Multimode), PA-F/FD-MM) is not supported on this chassis</b></font><BR>00:01:38: %PA-3-DEACTIVATED: port adapter in bay [3] powered off.<BR>00:01:38: %PA-2-PABRIDGE: Failed to config bridge for PA 3<BR></font></pre><BR><BR>Show diag will show that the PAs are disabled.  Two examples are given.<BR><pre><font face=\"courier\"><BR>Router#sh diag 1<BR>Slot 1:<BR>        Channelized T1 port adapter, 2 ports<BR>        <font color=\"blue\"><b>Port adapter is disabled unsuitable deactivated powered off</b></font><BR>        Port adapter insertion time unknown<BR>        EEPROM contents at hardware discovery:<BR>        Hardware revision 1.1           Board revision A0<BR>        Serial number     5105485       Part number    73-1565-05<BR>        Test history      0x0           RMA number     00-00-00<BR>        EEPROM format version 1<BR>        EEPROM contents (hex):<BR>          0x20: 01 07 01 01 00 4D E7 4D 49 06 1D 05 00 00 00 00<BR>          0x30: 50 00 00 00 97 05 31 00 FF FF FF FF FF FF FF FF<BR><BR><BR>Router#sh diag 3<BR>Slot 3:<BR>        FD FDDI DAS (Multimode), PA-F/FD-MM port adapter, 1 port<BR>        <font color=\"blue\"><b>Port adapter is disabled unsuitable deactivated powered off</b></font><BR>        Port adapter insertion time unknown<BR>        EEPROM contents at hardware discovery:<BR>        Hardware revision 1.13          Board revision A0<BR>        Serial number     6688085       Part number    73-2138-03<BR>        Test history      0x0           RMA number     00-00-00<BR>        EEPROM format version 1<BR>        EEPROM contents (hex):<BR>          0x20: 01 31 01 0D 00 66 0D 55 49 08 5A 03 00 00 00 00<BR>          0x30: 50 00 00 00 97 10 07 00 FF FF FF FF FF FF FF FF<BR></font></pre><BR><BR>Supported upgradeable port adapters affected by this change can be physically identified as listed in the table below.  Please note that any part number previous to the ones listed will require an upgrade.<BR> <BR>PA-8E<BR>New P/N - 800-02069-04<BR><BR>PA-4E<BR>New P/N - 800-02070-04<BR><BR>PA-5EFL<BR>New P/N - 800-01885-04<BR><BR>PA-8T-V35<BR>New P/N - 800-01836-05<BR><BR>PA-8T-232<BR>New P/N - 800-01835-05<BR><BR>PA-8T-X21<BR>New P/N - 800-01837-05<BR><BR>PA-H<BR>New P/N - 800-02747-06<BR><BR>PA-2H<BR>New P/N - 800-03306-02<BR><BR>PA-A3-T3<BR>New P/N - 800-02600-04<BR><BR>PA-A3-E3<BR>New P/N - 800-02602-04<BR><BR>PA-A3-OC3 MM<BR>New P/N - 800-02598-04<BR><BR>PA-A3-OC3 SMI<BR>New P/N - 800-02595-04<BR><BR>PA-A3-OC3 SML<BR>New P/N - 800-02596-04<BR>\r\n&nbsp;",
            "workaround": "There is no risk or exposure to the installed base of 7200 routers or to new 7200 routers.\r\n\r\nThis change pertains only to 7200 VXR routers currently installed that may have older version port adapter spares or the port adapters from existing 7200 non-VXR routers are planned for use in the VXR. \r\n\r\nNew 7200 VXR routers will be shipping with the required port adapter revision.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/000/fn3028.html"
        },
        {
            "fieldNoticeId": 8611,
            "status": "P",
            "bulletinLastUpdated": "2006-02-14T12:42:06Z",
            "bulletinTitle": "*Expired* FN - 8611- NPE-175 & NPE-225 Recall Due To Anomalous Packet Handling Behavior",
            "bulletinFirstPublished": "2000-07-11T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "Initially, a problem was observed with an output stuck condition on the PA-POS-OC3 with a NPE-225. The problem was observed with a private 12.0S image, however, the same problem was found to occur with other images during testing.\r\n\r\nFurther investigation found that a system with either a NPE-175 or NPE-225 and a PA-POS-OC3 port adapter under extreme high traffic conditions may exhibit anomalous and unpredictable behaviour ranging from a port adapter interface no longer able to transmit, system crash or system hang (catastrophic failures).\r\n\r\nHowever, investigation of this anomaly also found that it is not a common occurrence and has not been detected in the field. This problem was detected in extreme manufacturing quality test conditions. Hence, upgrading is not believed to be an immediate need and can be scheduled at the customer''s convenience. \r\n\r\nThis problem is tracked in CSCdp57908 (See DDTS Section below).",
            "background": "The problem has been traced to an errata with a specific third party chip and cannot solely be fixed in software. The fix for this specific problem requires a respin of the chip as well an software upgrade. This is a NPE-175 & NPE-225 specific issue.\r\n\r\nSince proper operation is not guaranteed, the anomalous packet handling behavior may affect any port adapter in the router leading to unpredictable and catastrophic results.",
            "problemSymptoms": "The following example represents one specific commonly observed failure condition. Note that it is possible for any other unknown, unpredictable, and possibly catastrophic error to occur based on our knowledge of the errata for this third party chip.<BR><BR><pre><font face=\"courier\"><BR>c7200#sh int pos 1/0   <BR>POS1/0 is up, line protocol is up<BR>  Hardware is Packet over Sonet<BR>  Internet address is 10.1.1.2/24<BR>  MTU 4470 bytes, BW 155000 Kbit, DLY 100 usec, rely 255/255, load 1/255<BR>  Encapsulation HDLC, crc 16, loopback not set<BR>  Keepalive set (10 sec)<BR>  Scramble disabled<BR>  Last input 00:00:04, output 00:14:32, output hang never<BR>  Last clearing of \"show interface\" counters 00:14:55<BR>  Queueing strategy: fifo<BR> <font color=red> <b>Output queue 40/40, 950101 drops;</b></font> input queue 0/75, 0 drops<BR>  5 minute input rate 523000 bits/sec, 667 packets/sec<BR>  5 minute output rate 387000 bits/sec, 495 packets/sec<BR>     1272858 packets input, 127279338 bytes, 0 no buffer<BR>     Received 0 broadcasts, 0 runts, 0 giants, 0* throttles<BR>              0 parity<BR>     0 input errors, 0 CRC, 0 frame, 0 overrun, 0 ignored, 0 abort<BR>     322691 packets output, 32269087 bytes, 0 underruns<BR>     0 output errors, 0 applique, 2 interface resets<BR>     0 output buffer failures, 0 output buffers swapped out<BR>     0 carrier transitions<BR>c7200#                    <BR></font></pre><BR><BR><hr><BR><b> New Software, Affected Hardware Symptom</b><BR>If the repaired Cisco IOS is installed on a system with affected Cisco NPE-175 or NPE-225, one of the following error messages will be encountered: <BR><BR><pre><font face=\"courier\"><BR>%PLATFORM-4-RECALLED_NPE: Old version NPE-175-225 with Rev= ZZZ system controller. Contact upgraged-info@cisco.com for replacement.<BR></font></pre><BR><BR><pre><font face=\"courier\"><BR>%C7200-4-RECALLED_NPE: Old version NPE-175/225 with Rev = xxx system controller.  Contact upgrades-info@cisco.com for replacement.<BR></font></pre><BR><BR>Use of older IOS images may lead to unpredictable malfunctions including system crashes.<BR>\r\n&nbsp;",
            "workaround": "The only solution to this problem is to replace the NPE-175 and NPE-225 boards with new revision boards that have the correct component.  Request RMA for replacement product.  In addition, a software upgrade to the repaired Cisco IOS version listed in  <a href= #ST1>Solution Table</a> below.<BR>\r\n<BR>\r\nSales orders shipped after January, 2000 have the corrected hardware version.  Lead time for replacement product is anticipated to be two to four weeks.<a name=ST1><table BORDER COLS=6 WIDTH=\"10%\" ><caption><b>Solution Table: Required Version for Solution</b></caption><tr><td WIDTH=\"10%\" BGCOLOR=\"#CCCCCC\"><b>Product</b></td><td WIDTH=20% BGCOLOR=\"#CCCCCC\"><b>Hardware Part Number <sup>*1</sup></b></td><td WIDTH=10% BGCOLOR=\"#CCCCCC\"><b>Hardware <br>Availability</b></td><td WIDTH=\"10%\" BGCOLOR=\"#CCCCCC\"><b>Minimum <br>Software Required</b></td><td WIDTH=\"10%\" BGCOLOR=\"#CCCCCC\"><b>Software Image</b></td><td BGCOLOR=\"#CCCCCC\"><b>Software <br>Availability</b></td></tr><tr><td>NPE-175(=)</td><td><ul><li>800-05420-02 (or later)</li><li>73-3453-04 (or later)</li></ul></td><td ROWSPAN=\"2\"> January 2000</td><td ROWSPAN=\"2\"><ul><li>12.0(5)XE6</li><BR>\r\n<li>12.0(9)S</li><li>12.1(1)</li></ul></td><td ROWSPAN=\"2\"> c7200-*-mz</td><td ROWSPAN=\"2\"><ul><li>12.0(5)XE6 Available on CCO January 3, 2000, MFG January 10, 2000</li><li>12.0(9)S Anticipated availability February, 2000 </li><li>12.1(1) Anticipated availability March/April 2000</li></ul></td></tr><tr><td>NPE-225(=)</td><td><ul><li>800-05418-02 (or later)</li><BR>\r\n<li>73-3453-04 (or later)</li></ul></td></tr></table><sup>*1</sup> - Go to the Section  <a href= \"#HW-LEVELS\" >\"How To Identify Hardware Levels\"</a><BR>\r\n<sup>*2</sup> - 12.0T will not have the software defect repaired due to the Cisco IOS release process of migrating Cisco IOS 12.0T to 12.1 mainline. Cisco IOS 12.1 mainline is a renumber of 12.0T that will integrate only software defect repairs.\r\n&nbsp;",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/000/fn8611.html"
        },
        {
            "fieldNoticeId": 12092,
            "status": "P",
            "bulletinLastUpdated": "2002-04-18T00:00:00Z",
            "bulletinTitle": "FN12092 -- Simplex TCC, TCC+, TCCi, XC, XCVT and XC10G Configuration are Unsupported",
            "bulletinFirstPublished": "2000-06-16T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "In an ONS15454 system running in simplex TCC, TCC+, TCCi, XC, XCVT or XC10G systems , a TCC or XC reset (all types) or hardware failure may cause a traffic outage.  Node connectivity issues are also a known problem of simplex TCC operation which may result in the inability to manage an NE.",
            "background": "The 15454 was designed as a duplex system for redundancy and reliability purposes, thus background process are run between common equipment in order to ensure the health of the sytem. Although the system will run in simplex mode, Cisco Systems does not perform software verification and reliability testing on Non-Redundant ONS 15454 systems and therefore cannot endorse simplex configurations.",
            "problemSymptoms": "In networks operating non-redundant TCC's or XC's, a failure of either of these boards can result in a traffic outage.  \r\n\r\n<b>Simplex TCC Operation</b>\r\nThe following are some issues that you can expect to see if running an ONS 15454 using a non-redundance TCC, where the TCC is reset either manually or as a result of a board failure.\r\n\r\n<b>Intercard communication</b> -- Messages sent between cards require an Active running TCC and Standby TCC.  When a single TCC resets for any reason, there could be a period of approximately 2 minutes when no intercard messages can get through.  This can have severe traffic implications if a protection switch needs to occur during this timeframe. \r\n\r\n<b>No access to the node</b> -- If the single TCC is reset for any reason, there is a timeframe, typically at least 2 minutes,  when that node cannot report any alarms, receive configuration requests or communicate other critical processes.  This could have a compounding effect for DCC connected nodes, since none of their administrative data can be communicated to the resetting node.   If the TCC has failed, it will be necessary to physically insert a known good TCC to restore traffic.\r\n\r\n<b>Software Upgrade</b> -- If you encounter a problem during a software upgrade, you may experience significant downtime if operating with a simplex TCC.  With dual TCCs, we first activate the new load on the Standby TCC, converting the database and verifying the integrity of the release with the database before switching to the standy TCC with the new release.  If there is a problem we can abort the Activation before switching avoiding traffic affecting issues.  With a simplex TCC, the boards are activated without this verfication process.  If a problem occurs during activation you may have to physically reset the node to restore traffic. \r\n\r\n<b>Timing</b> -- since the TCC sources the Sync clock to the other cards, during TCC resets, the XCON provides the clock.  While this is a generally accepted operation, there can be issues with some cards like DS3/DS3E when operating in this mode. \r\n\r\n<b>E100/E1000 cards</b> -- During a TCC reset all E100/E1000 traffic will be down since spanning tree runs on the TCC.\r\n\r\n<br>\r\n<br>\r\n<b>Simplex XC Operation</b>\r\nThe problem may occur during a reset of a simplex XC (all versions).  During the reset an outage will result which may require physical intervention to restore traffic.\r\n\r\n<b>XC Resets</b> -- Some hardware conditions, like \"out of frame\" can be solved only with an XC switch over and a reboot of the XC card.  With a simplex XC, traffic will be lost as the card reboots. \r\n\r\n<b>XC Soft Resets</b> -- while the XC soft resets, no protection (1+1, BLSR and UPSR) may work.  If there is a line/path problem during the reset, traffic will be lost. \r\n\r\n<b>IO Card Reboots</b> -- During card reboots bus noise can be present which may cause the XC to switch to its peer.  In a simplex system this will result in a traffice outage.\r\n\r\n<b>Diagnostics</b> -- during XC soft resets, diagnostics are run to detect input port lockup problems on the SXC1 and/or SXC2 (depending on the board).  These diagnotics are only run on the standby card to help detect and fix problems.  In a simplex sytem, we cannot catch the problem as the diagnostics are not running which may result in a traffic outage.\r\n\r\n<b>TCC reboot</b> -- When a TCC reboots, line degradation can occur because of loss of timing.  On BLSR rings, this will translate to a ring or span switch.  As the TCC is not up and running, intercard communication is not working, which leads to traffic loss.",
            "workaround": "If you are currently running a Cisco ONS 15454 using a simplex (single) TCC, TCC+, TCCi,  XC, XCVT, XC10G, Cisco strongly recommends you upgrade your system to duplex (dual) TCC and XC cards.  Upgrading to a duplex configuration can be performed \"in service\" without affecting traffic.\r\n\r\nCisco recommends upgrading your system to duplex TCC's (dual TCC's) prior to upgrading to a newer software release.  If you would like details on obtaining an upgrade, please contact your Cisco Sales Representative directly or submit your order using Cisco's Marketplace Online at <a href=\"http://www.cisco.com/go/marketplace/\">http://www.cisco.com/go/marketplace/</a>.\r\n\r\nThe Technical Assistance Center (TAC) is unable to support simplex configuration or perform root cause analysis on failed simplex configurations.  To support this level of analysis an operational Standy TCC is a minimal system requirement.  \r\n\r\nIf you need assistance in upgrading your system to duplex TCC's or XC's please refer to the user documentation or contact Cisco's Technical Assistance Center for the correct procedure.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/100/fn12092_06162000.html"
        },
        {
            "fieldNoticeId": 12971,
            "status": "P",
            "bulletinLastUpdated": "2002-01-15T00:00:00Z",
            "bulletinTitle": "FN12971: ONS 15454 - Shelf Assembly quality issue",
            "bulletinFirstPublished": "2000-11-02T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "In some shelf assemblies [15454-SA-NEBS3E=] there is a potential manufacturing defect present that can cause \"fit\" issues with the Fan Tray Assembly (FTA) [15454-FTA2=].",
            "background": "The issue was identified in the field and was confirmed through a detailed mechanical inspection of the shelf assembly. We have further identified that defect was introduced in manufacturing through the use of a #6-32x3/8\" screw instead of a #6-32x1/4\" screw",
            "problemSymptoms": "In some shelf assemblies it is possible that tolerance build up may result in a screw contacting the FTA upon insertion into the shelf assembly. This screw may prevent full (complete) insertion of the FTA module into the shelf assembly. This would be apparent at turn-up as the FTA slot is populated and would cause the FTA to protrude from the shelf assembly causing a poor fit",
            "workaround": "As a result of this manufacturing issue, it may be necessary to replace the screw highlighted in the picture below \"ONS 15454 (Rear Panel)\" <b>marked with the letter \"C\"</b> with a 6-32x1/4\" screw as supplied by the Cisco Technical Assistance Center.<BR><BR>If you discover that you have a shelf assembly that you believe has been affected by this issue, please contact Cisco's Technical Assistance Center to either have a screw dispatched for replacement or to request an on-site visit from one of our support technicians to perform the replacement.<BR><BR><b>Instructions For Screw Replacement</b><BR><ol><li>Remove the five screws marked by the letter \"A\" and the red circles. (qty 5)</li><BR><li>Remove plastic alarm cover marked by the letter \"B\" and the green arrow. (qty 1)</li><BR><li>Remove the screw marked by the letter \"C\" and the blue arrow. (qty 1) along with the plastic clamp marked with the letter \"D\" and the black arrow. (qty 1)</li><BR><li>Replace the screw removed in step 3 with the 6-32x1/4\" screw supplied by the Technical Assistance Center along with the plastic clamp. (qty 1)</li><BR><li>Replace the alarm cover removed in step 2.</li><BR><li>Replace the screws removed in step 1.</li><BR><BR><i>ONS 15454 (Rear Panel)</i><BR><IMG SRC=\"/Support_Library/field_alerts/fn12971_g3gliw.gif\"></ol><BR><BR>This issue will be addressed with the introduction of a pem stud and nut to attach the power management clip to the shelf.  This will be introduced in the part number 800-07149-02.  Until this is implemented we have modified the Bill of Materials to eliminate the use of the 6-32x3/8\" screw.<BR>\r\n&nbsp;",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/100/fn12971.html"
        },
        {
            "fieldNoticeId": 13061,
            "status": "P",
            "bulletinLastUpdated": "2006-08-09T09:34:01Z",
            "bulletinTitle": "FN# 13061 - Old Versions of NPE-225 are Incompatible with C7200-I/O-2FE/E - RMA Required",
            "bulletinFirstPublished": "2001-02-23T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "When installing a new C7200-I/O-2FE/E(=) into a 7200(VXR) with a NPE-225(=), the boot flash will not be recognized on the I/O controller.   If the router is configured to net boot, it will fail to boot and will eventually hang.  If IOS is loaded on the PCMCIA flash, the router will eventually boot.<BR><BR><b>Please note, that the C7200-I/O-2FE/E(=) was not designed to work in a non-VXR chassis.  This controller is only supported in VXR chassis.</b>\r\n&nbsp;",
            "background": "When the C7200-I/O-2FE/E was released, a ROMMON upgrade was required for the NPE-225 so that the boot flash would be recognized on the I/O controller. Systems with NPE-225 hardware versions lower than 1.3 will not recognize the boot flash on the I/O controller. NPE-225 hardware version 1.3 or higher will fix this issue.",
            "problemSymptoms": "If boot-up on a 7200 (VXR) system containing an NPE-225 (version 1.2 or lower) and the C7200-I/O-2FE/E controller is attempted, the system will fail to boot from bootflash. The system will eventually boot from slot0. The router will display the following message before booting from slot0:\r\n\r\ngetdevnum warning: device \"boot flash\" has size of zero\r\ngetdevnum warning: device \"boot flash\" has size of zero\r\nopen: read error...requested 0x4 bytes, got 0xffffffff\r\ntrouble reading device magic number\r\nboot: cannot open \"bootflash:\"\r\nboot: cannot determine first file name on device \"bootflash:\"\r\n\r\nIf the router is configured to net boot, the same message will be displayed and the router will eventually hang.",
            "workaround": "The workaround is to copy IOS to the PCMCIA flash and configure the system to boot from the PCMCIA flash. For instructions on this process, please refer to the following documents on CCO:\r\n<a href=\"http://www.cisco.com/warp/public/63/how_install.shtml\" style=\"font-family: Arial, Helvetica, sans-serif; color: #336699; font-size: 12px; font-weight: normal\">\r\nhttp://www.cisco.com/warp/public/63/how_install.shtml</a> <a href=\"http://www.cisco.com/warp/public/63/install_tftp.html\" style=\"font-family: Arial, Helvetica, sans-serif; color: #336699; font-size: 12px; font-weight: normal\">\r\nhttp://www.cisco.com/warp/public/63/install_tftp.html</a>\r\n\r\nIf the router is setup to perform a net boot, the net boot will fail. A new NPE-225 (hardware version 1.3 or higher) is required to fix this problem. Please use the standard RMA process to get the replacement NPE-225.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/100/fn13061.html"
        },
        {
            "fieldNoticeId": 14967,
            "status": "P",
            "bulletinLastUpdated": "2006-10-11T15:54:22Z",
            "bulletinTitle": "NPE-200 Fails to Boot IOS in Certain 7204VXR & 7206VXR Chassis",
            "bulletinFirstPublished": "2001-10-31T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "The snoop arbiter on the VXR midplane fails to recognize the NPE-200 when Port Adapters are installed in the chassis.  This results in the system failing to boot IOS and only booting to a ROMMON prompt.  This problem does not occur when Port Adapters are not installed in the system.<BR><BR><b>Note:  This problem does not exist on any other NPE / VXR combinations.  It is only a problem with the NPE-200 on a VXR Chassis.</b>\r\n&nbsp;",
            "background": "A change was made to the snoop arbiter on the VXR midplane which causes the NPE-200 not be recognized. This results in the system not booting to IOS but instead booting to a ROMMON prompt. This problem occurs on the 7204VXR with product number 73-3905-07 and 7206VXR with product number 73-3223-09. Any version of the product number not listed will not experience this problem.The problem surfaces when Port Adapters are installed in the system. If there are no Port Adapters installed, the problem will not occur.",
            "problemSymptoms": "When a 7204VXR or 7206VXR with the new snoop arbiter has an NPE-200 and Port Adapters installed, the system will only boot to a ROMMON prompt.<BR><BR><tt>rommon></tt>\r\n&nbsp;",
            "workaround": "To resolve this issue, a new snoop arbiter is now being used in the latest version of the chassis. This new snoop arbiter will recognize the NPE-200 when Port Adapters are installed in the chassis. The new product numbers for the 7204VXR are 800-04766-09 and 73-3905-08. The new product numbers for the 7206VXR are 800-04667-09 and 73-3223-10.\r\n\r\nIn order to resolve this issue, replace the chassis (7204VXR or 7206VXR) through the RMA process. Please use RMA ARFN (Administrative Request Field Notice).",
            "hardwareLevels": "",
            "upgradeProgram": "",
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/100/fn14967.html"
        },
        {
            "fieldNoticeId": 22633,
            "status": "P",
            "bulletinLastUpdated": "2004-03-10T00:00:00Z",
            "bulletinTitle": "15454-FTA2= and 15454-FTA3-T= -- Reversed polarity on capacitors may cause premature failure of FTA units",
            "bulletinFirstPublished": "2004-10-26T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "Due to a defect introduced in the Manufacturing Process between production weeks 46-49, any 15454-FTA2= or 15454-FTA3-T= built in this period has a high probability of failure (~30% of build). These failures may not happen immediately, but the product will eventually fail if this defect is present. This failure is caused by reverse polarity on the capacitor located at C2 on the Fan Tray Assembly FCB (Fan Control Board).",
            "background": "This issue was introduced in the factory during the 46th through 49th weeks of production at Cisco Manufacturing. (Week 48 was the week of Thanksgiving and no units wer produced) The issue stems from a reversed capacitor at location C2. The defect was detected and corrective action was taken within the manufacturing line to eliminate this issue starting with the 50th week of production. All product built prior to and following the the 46th through 49th weeks of production are believed to be free from this defect. There were a number of boards from this production lot that were identified prior to shipment. For a list serial numbers from this range that are not affected please see the \"How To Identify Hardware Levels\" section below.",
            "problemSymptoms": "The reversed cap will eventually cause the fans to intermittently oscillate or stop completely. This should be indicated by a FAN alarm within CTC and a Critical Alarm on the NE itself.",
            "workaround": "There is no workaround for this defect. As a result of this defect all affected assemblies will eventually fail. If you have products listed in this field notice that match the serial number pattern and are not listed in the list of screened parts, please contact our Technical Assistance Center to initiate an RMA (Return Materials Authorization)",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/200/fn22633.html"
        },
        {
            "fieldNoticeId": 24054,
            "status": "P",
            "bulletinLastUpdated": "2005-11-01T11:09:38Z",
            "bulletinTitle": "FN # 24054 - Interoperability Issue between Mixed Version IP phones, Aironet Access Points, and Line Power Switches",
            "bulletinFirstPublished": "2003-04-07T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "IP Phones and Aironet Access Points may not be provided inline power. Customers deploying hardware version -05 CP-7940G and CP-7960G Cisco IP Phones within the same network as Cisco IP Phones with previous hardware versions (-04 or prior) and/or Aironet Access Points may experience the failure of an IP Phone or the Aironet Access Point to initialize and receive Ethernet in-line power.\r\n\r\nThis specific combination does not always result in the failure of the IP Phone to initialize and receive in-line power. Once the IP Phones have been installed and are operational in those ports, this problem will not occur, even if the IP Phones are re-initialized at a later time. \r\n\r\nThis issue can only occur if the differing hardware versions are connected to vertically adjacent ports* of a line card running in a Catalyst 4000 or 6000 Series Switch. Only Line Cards mentioned in the \"Products Affected' section of this document are exposed to this issue.\r\n\r\nThere is no impact to phones connected to horizontally adjacent ports or to phones or devices in a homogeneouse environment (ie. all -05 or later version phones or all version -03/-04 Phones combined with Aironet).\r\n\r\n*Vertically adjacent ports refers to an odd and even port pair. On the line cards affected, the odd ports are on the top row of the port blade and the even ports are on the bottom row.",
            "background": "The failure of an IP Phone or Aironet Access Point to initialize and receive Ethernet inline power when connected to the vertically adjacent ports on the same inline power card is caused by an over-current situation in the -05 version Cisco IP Phone. In the scenario in which two affected endpoints are plugged in to a vertically adjacent ports, it is possible that one will not power; or that the second endpoint added will cause the first endpoint to lose power. There is no damage to the switch, phone, or Aironet Access Point, or any impact to Ethernet functionality of the switch. This will not occur with any other combination of IP Phone hardware version other than the -05 hardware version.",
            "problemSymptoms": "The Cisco IP Phone or Aironet Access Point may fail to power up when connected to a line card mentioned in the \"Products Affected\" section above. This will occur when the line card is providing inline power to the phone and the -05 version phone is plugged in to a vertically adjacent port to the prior version phone or the Cisco Aironet Access Point.",
            "workaround": "<p>For customers experiencing this issue on a Catalyst 4000 or 6000 Series switch, the workaround for this issue is to avoid combining the CP-7960G (68-1735-05) or CP-7940G (68-1679-05) versions in vertically adjacent switch ports which contain prior manufacturing versions of the CP-7960/CP-7960G or CP-7940/CP-7940G or the Cisco Aironet AP350 and AP1200 Series Access Points.</p>\r\n\r\n<p>In some cases, the line card may shut down the inline power to the port after approximately five minutes. If this occurs, you will see from the <b>show inlinepower</b> command that the admin state has been changed by software to <tt>off</tt>.</p>\r\n\r\n<p>In the following example where port 3/8 inlinepower is shutdown by the software, you will see:</p>\r\n\r\n<blockquote><pre>sjcf-11a-sw1> (enable) <b>show port inlinepower 3 </b>\r\nConfigured Default Inline Power allocation per port: 7.00 Watts (0.16 Amps @42V) Total inline power drawn by module 3: 63.00 Watts ( 1.50 Amps @42V) \r\nPort InlinePowered PowerAllocated \r\nAdmin Oper Detected mWatt mA @42V \r\n----- ----- ------ -------- ----- -------- \r\n3/1 auto on yes 6300 150 \r\n3/2 auto on yes 6300 150 \r\n3/3 auto off no 0 0 \r\n3/4 auto on yes 6300 150 \r\n3/5 auto off no 0 0 \r\n3/6 auto on yes 6300 150 \r\n3/7 auto on yes 6300 150 \r\n3/8 off off no 0 0 \r\n3/9 auto off no 0 0 \r\n3/10 auto off no 0 0 \r\n3/11 auto off no 0 0 \r\n3/12 auto off no 0 0 \r\n3/13 auto on yes 6300 150 \r\n3/14 auto off no 0 0 \r\n3/15 auto on yes 6300 150 \r\n3/16 auto off no 0 0 \r\n3/17 auto off no 0 0 \r\n3/18 auto on yes 6300 150 </pre>\r\n</blockquote>\r\n\r\n<p>To re-enable the power, you will need to set the inlinepower Admin state on the line card back to auto using the <b>set port inlinepower 3/8 auto</b> command.</p>\r\n\r\n<p>In rare cases, this issue may also result in the port existing in a non-responsive state with the link LED on. In this case, disable and re-enable the port using the following commands:</p>\r\n\r\n<p><b>set port disable <i>[mod/port]</i></b></p>\r\n\r\n<p><b>set port enable <i>[mod/port]</i></b></p>\r\n\r\n<p>Customers may also choose to upgrade their -05 version phones to an -06 version or later using the RMA process.</p>\r\n&nbsp;",
            "hardwareLevels": "",
            "upgradeProgram": "",
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/200/fn24054.html"
        },
        {
            "fieldNoticeId": 24894,
            "status": "P",
            "bulletinLastUpdated": "2003-06-24T00:00:00Z",
            "bulletinTitle": "CSCdx59414 PXM-UI-S3 Ethernet interface can drop packets.",
            "bulletinFirstPublished": "2003-06-24T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "PXM1E equipped with PXM-UI-S3 backcard loses up to 20% of ethernet packets when pinged through some brands of hubs. \r\n\r\nThis problem does not apply to the PXM1 series or PXM45 or PXM45/B equipped with PXM-UI-S3 back cards. Note that the PXM45/C does not support the PXM-UI-S3.",
            "background": "This problem is the result of low noise tolerance on the ethernet interface of the PXM-UI-S3.",
            "problemSymptoms": "Pings to the MGX8800 equipped with the PXM1E-type cards and the PXM-UI-S3 may not complete 100% of the time.  Access to the MGX8800 may be interrupted or appear slow.  With Cisco products exhibiting the anomaly, use the <B>show port</B> command.  The example given is for a CATALYST 2948. Observe the transmit and receive errors counters as shown below. <BR><BR>USNY-2948-0.20> (enable) sho port 2/3<BR> Port  Name               Status     Vlan       Level  Duplex Speed Type<BR> ----- ------------------ ---------- ---------- ------ ------ ----- ------------<BR>  2/3                     connected  1          normal   half    10 10/100BaseTX<BR><BR> Port  AuxiliaryVlan AuxVlan-Status     InlinePowered     PowerAllocated<BR>                                    Admin Oper   Detected mWatt mA @51V<BR> ----- ------------- -------------- ----- ------ -------- ----- --------<BR>  2/3  none          none           -     -      -        -     -<BR><BR><BR> Port  Security Violation Shutdown-Time Age-Time Max-Addr Trap     IfIndex<BR> ----- -------- --------- ------------- -------- -------- -------- -------<BR>  2/3  disabled  shutdown             0        0        1 disabled      11<BR><BR> Port  Num-Addr Secure-Src-Addr   Age-Left Last-Src-Addr     Shutdown/Time-Left<BR> ----- -------- ----------------- -------- ----------------- ------------------<BR>  2/3         0                 -        -                 -        -         -<BR><BR> Port  Status     Channel              Admin Ch<BR>                  Mode                 Group Id<BR> ----- ---------- -------------------- ----- -----<BR>  2/3  connected  auto silent             14     0<BR><BR> Port  Align-Err  FCS-Err    <B>Xmit-Err   Rcv-Err</B>    UnderSize<BR> ----- ---------- ---------- ---------- ---------- ---------<BR>  2/3           -          0          <B>3          3</B>         0<BR><BR> Port  Single-Col Multi-Coll Late-Coll  Excess-Col Carri-Sen Runts     Giants<BR> ----- ---------- ---------- ---------- ---------- --------- --------- ---------<BR>  2/3           0          0          0          0         0         3         0<BR><BR> Last-Time-Cleared<BR> --------------------------<BR> Wed Jan 15 2003, 15:45:55<BR><BR>Other vendor's products may also have similar statistics.  \r\n&nbsp;",
            "workaround": "WorkAround: None.\r\n\r\nSolution: Upgrade the PXM-UI-S3 with an PXM-UI-S3/B. Use the upgrade form attached below.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/200/fn24894.html"
        },
        {
            "fieldNoticeId": 24955,
            "status": "P",
            "bulletinLastUpdated": "2008-10-31T12:56:21Z",
            "bulletinTitle": "FN# 24955 Cisco 12410 + PRP-1: redundancy issue with CSC Online Insertion Removal",
            "bulletinFirstPublished": "2003-08-29T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "If OIR of a CSC card (either card 0 or card 1) is performed on a Cisco 12410 equipped with a PRP-1, not only is the CSC redundancy lost, the corresponding SFC reduncancy is also lost. Full reduncancy of CSC and SFC is restored automatically as soon as the CSC card is reinserted.",
            "background": "Initially the GSR architecture was designed to support only 5 fabric cards in the system (2 CSC cards and 3 SFC cards). Therefore the backplane connection for the line card only has 5 fabric present input pins.\r<br>The Cisco 12410 is a special system since it has 2 CSC cards and 5 SFC cards.\r<br>Due to this configuration of 2 CSC cards and 5 SFC cards, the CSC0/CSC1 'present indication' is always set to be present (pulled down). All of our line cards except for the PRP-1 look at the signal as is and make a decision to loopback the SerDes based on that indication.\r<br>The PRP-1 however has a pull up on it and can create an unstable situation with regards to the present buffer",
            "problemSymptoms": "When a CSC is physically removed from a Cisco 12410 chassis equipped with PRP's , there is a voltage at the input of the present buffer, which causes this input to become unstable. When this happens, the SerDes of SFC0 is put in loopback and the PRP-1's start seeing errors on that channel, initiating error recovery code and turning off the SFC card associated with the removed CSC card.",
            "workaround": "Workaround:\r\n<br>For the install base, there is no SW work around for this situation, however note that with no additional failure in the SFCs, traffic will flow normally. Also insertion back of the CSC card (even if a faulty card) would cause the SFC to resume operation.\r\n<br>\r\n<br>Solution:\r\n<br>Customers who wish to return their cards can do so by requesting RMAs with the failure type \"MFGN\".  As of 1/25/2005 the Umpire program to replace effected PRP-1= cards has been closed.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/200/fn24955.html"
        },
        {
            "fieldNoticeId": 26094,
            "status": "P",
            "bulletinLastUpdated": "2003-12-15T00:00:00Z",
            "bulletinTitle": "NSE-100 Unexpected failure",
            "bulletinFirstPublished": "2003-12-15T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "A problem has been identified with some of the original shipments of 7300-NSE-100 that may cause the router to fail. The problem is limited to 7300-NSE-100 with only top assembly numbers (TAN) 68-1002-02 and 68-1002-03. These assemblies only potentially contain a component that was only used on these revisions of the board. Not all these assemblies contain the faulty component (oscillator) from the specific manufacturer.",
            "background": "The unexpected behavior is caused by a component (oscillator) not generating the right output clock. The oscillator is used in two different locations on the 7300-NSE-100 board, on the base board and the daughter card. The failure rate is about 10% of the Customer Install Base with TAN 68-1002-02 and 68-1002-03. The reported failures have been random \r<br>\r<br>Note:\r<br>The component (oscillator) in question is located on the Base Board at U55 and on the Daughter Card at U37. The component will be marked with MF.",
            "problemSymptoms": "The following are the reported Failure symptoms;\r<br> \r<br>Symptoms seen when the component failure occurs on the daughter card \r<br>1- The router may fail (crash) during normal operation and unable to recover.\r<br>2- After power up the system does not boot to rommon mode. \r<br>3- After power up, the console displays some random meaningless characters on the console.\r<br>4- After power up, nothing is seen on the console.\r<br> \r<br> \r<br>Symptoms seen when the component failure occurs on the main board \r<br>1- The router may fail (crash) during normal operation and unable to recover.\r<br>2- System crashes to rommon while booting IOS with Mistral errors.\r<br>3- System crashes to rommon while booting IOS with FPGA incompatibility errors.\r<br>4- Sample error messages is: MISTRAL_IO_BUS_INT_MASK_LO: 27\r<br>\r<br>",
            "workaround": "Workaround:\r<br>No workaround.\r<br>Solution:\r<br>If the TAN matches the part number identified in the Products Affected section above please RMA the NSE-100 board.\r<br>\r<br>Note:\r<br>All Service Depots units have the TAN 68-1002-05 or newer\r<br>Also the default memory of the NSE-100= has been upgraded to 512MB",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/200/fn26094.html"
        },
        {
            "fieldNoticeId": 26454,
            "status": "P",
            "bulletinLastUpdated": "2008-07-03T03:01:24Z",
            "bulletinTitle": "* Expired * FN: 26454 - WS-C6509 Chassis Handles May Break Off",
            "bulletinFirstPublished": "2003-10-15T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "Some Catalyst WS-C6509 series chassis manufactured between February and June 2003 have handles which may break off when they are used to lift or move the chassis.",
            "background": "",
            "problemSymptoms": "<b>CAUTION:</b> While the handles may appear to be firmly fastened to the chassis, they can potentially break off while the chassis is being lifted or carried. If you need to move a suspect chassis, please use the procedure described in the <i>How To Identify Hardware Levels</i> section below.",
            "workaround": "<b>Note:</b> As of November 1, 2003, RMA Service Depot stock has been screened and purged of units containing this defect.  At this time, all WS-C6509 chassis shipping from RMA Service Depots should be free of this defect.\r\n\r\nThere is no known workaround for this issue.  If you have a chassis in the affected serial number range, please replace that chassis immediately using the standard RMA process (standard lead-times will apply).  If you absolutely must move or lift a suspect chassis, please follow the lifting procedure reference in the <i>How To Identify Hardware Levels</i> section below.\r\n\r\nAdditionally, Cisco will provide customers who have purchased chassis within the aforementioned serial number range with a set of warning stickers which should be used to mark chassis which cannot be immediately decommissioned and returned to Cisco for replacement.  If you are in possession of affected chassis which have already been deployed, and cannot be removed from service, please affix these stickers to those chassis so they may be easily identified in the future.  \r\n\r\nOn November 3, 2003, Cisco proactively distributed warning stickers by mail to customers who had been shipped a chassis within the affected serial number range.  Each of the identified customers should have received one set of stickers for each affected chassis they were shipped.  If you have not been provided a set of stickers and believe you have a WS-C6509 chassis which may be at risk, please send an email to <a href=mailto:fn26454-stickers@cisco.com>FN26454-Stickers@cisco.com</a> to request a replacement set of warning stickers for your chassis.  In your email, please be sure to include the following information:<pre>\r\n<br>      Name\r\n<br>      Shipping Address\r\n<br>      WS-C6509 Serial Number(s)\r\n<br>      Number of warning sticker sets required</pre>\r\nCustomers who purchased an affected chassis directly from Cisco should have been shipped a set of stickers automatically, with no customer action required.  Customers who purchased a suspect chassis from a 3rd party vendor or channel partner may need to contact Cisco via the email at <a href=mailto:fn26454-stickers@cisco.com>FN26454-Stickers@cisco.com</a>, in order to receive a set of stickers.\r\n\r\n<i><b>NOTE:</b> Advance Servies (AS) customers were proactively contacted by their respective AS engineers for WS-C6509 chassis replacements.</i>",
            "hardwareLevels": "",
            "upgradeProgram": "",
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/200/fn26454.html"
        },
        {
            "fieldNoticeId": 28655,
            "status": "P",
            "bulletinLastUpdated": "2008-04-18T15:45:29Z",
            "bulletinTitle": "*Expired* FN - 28655 - VG224 Chassis Guard - Safety Regulation",
            "bulletinFirstPublished": "2004-01-19T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "New chassis safety guard introduction to extend environment deployments.\r<br>\r<br>These products can be installed in a rack, but if mounted on a wall, the floor must be cement or another noncombustible material. \r<br>\r<br>Some existing customers who need to install the device over a floor with combustible material may not have the appropriate accessory kit to do this safely.\r<br>\r<br>\r<br>Currently, the 'Quick Start Guide Cisco VG224 Voice Gateway', has a warning caution regarding wall mounting.\r<br>\r<br>\r<br>See the quick start link provided below for caution statements relating to wall mounting.",
            "background": "These products where release with restrictions on how and where they can be mounted.\r<br>\r<br>Warnings are in the 'Regulatory Compliance and Safety Information' and 'Quick Start Guide'.\r<br>\r<br>\r<br>The new chassis safety guard will now allow for wall mounting in previously restricted environments.",
            "problemSymptoms": "If the floor is not concrete or a combustible material, you can not mount the unit either horizontally or vertically on a wall, this will expose the possibility of burning material to fall out of the underside venting holes",
            "workaround": "Cisco has added a new optional chassis guard to the accessory kit. The chassis guard is mandatory to meet Safety Regulations for customers who need to mount the unit over a floor with combustible material. The unit must be mounted vertically for chassis guard to be in effect to meet the following Safety Regulations for installation areas with floors with combustible material:<BR><BR>North America <BR><BR>Safety UL60950, CAN/CSA-22.2 NO. 60950<BR><BR>European Union <BR><BR>Safety EN 60950, IEC 60950 <BR><BR>Other Counties: <BR><BR>Safety TS001, AS/NZS 3260 with Amendment 1,2,3 and 4 <BR><BR>Please refer to the 'Quick Start Guide - Cisco VG224 Voice Gateway' for detailed information on the installation of the chassis guard.<BR><BR><BR>How to Obtain a New Accessory Kit:<BR><BR>To obtain the chassis guard if one does not exist in the accessory kit received, please contact vg224-interest@cisco.com team with your name, company and address and the kit will be promptly sent to you.<BR><BR><BR>Cisco VG224 Voice Gateway Regulatory Compliance and Safety Information:<BR> <a href=\"http://www.cisco.com/univercd/cc/td/doc/product/access/vg/vg224/rcsi/index.htm\">http://www.cisco.com/univercd/cc/td/doc/product/access/vg/vg224/rcsi/index.htm</a><BR><BR>Quick Start Guide - Cisco VG224 Voice Gateway:<BR><BR><a href=\"http://www.cisco.com/univercd/cc/td/doc/product/access/vg/vg224/qsg/index.htm\">http://www.cisco.com/univercd/cc/td/doc/product/access/vg/vg224/qsg/index.htm</a><BR><BR><BR>Marketing Contacts:<BR><BR>Cisco VG224 alias, vg224-interest@cisco.com<BR><BR>Jennifer Blatnik, Product Manager, jennyng@cisco.com<BR><BR>Andy Chen, Technical Marketing Engineer, andychen@cisco.com<BR><BR>\r<br>&nbsp;",
            "hardwareLevels": "",
            "upgradeProgram": "",
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/200/fn28655.html"
        },
        {
            "fieldNoticeId": 29400,
            "status": "P",
            "bulletinLastUpdated": "2005-10-28T15:32:27Z",
            "bulletinTitle": "FN#29400-WS-C6513- Chassis Handles May Break Off-Replace the chassis",
            "bulletinFirstPublished": "2004-04-23T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "Some Catalyst WS-C6513 series chassis manufactured between July 7, 2003 and October 12, 2003 have handles which may break off when they are used to lift or move the chassis.",
            "background": "Some Catalyst WS-C6513 series chassis manufactured between July 7, 2003 and October 12, 2003 have handles which may break off when they are used to lift or move the chassis.",
            "problemSymptoms": "CAUTION: While the handles may appear to be firmly fastened to the chassis, they can potentially break off while the chassis is being lifted or carried. If you need to move a suspect chassis, please use the procedure described in the How To Identify Hardware Levels section below.",
            "workaround": "There is no known work around for this issue. If you have a chassis in the affected serial number range, please upgrade that chassis immediately using the advanced replacement form in the Upgrade Program section of this Field Notice. If you absolutely must move or lift a suspect chassis, please follow the lifting procedure reference in the How To Identify Hardware Levels section below. \r<br>\r<br>Additionally, Cisco will be contacting customers who have purchased chassis within the aforementioned serial number range in order to provide them with a set of warning stickers which should be used to mark a chassis which cannot be immediately decommissioned and returned to Cisco for replacement. If you have any affected chassis which have already been deployed and cannot be removed from service, please affix these stickers to all such chassis so they may be easily identified in the future. \r<br>\r<br>On April 26, 2004, Cisco will begin proactively distributing warning stickers by mail to customers who have been shipped a chassis within the affected serial number range. Each of the identified customers will receive one set of stickers for each affected chassis they were shipped. If you have not been provided a set of stickers by May 24, 2004 and believe you have a WS-C6513 chassis which may be at risk, please send an email to FN29400-Stickers@cisco.com to request a replacement set of warning stickers for your chassis. In your email, please be sure to include the following information:\r<br>\r<br>      Name\r<br>      Shipping Address\r<br>      WS-C6513 Serial Number(s)\r<br>      Number of warning sticker sets required\r<br>NOTE: Customers who purchased an affected chassis directly from Cisco will be shipped a set of stickers automatically, with no customer action required. Customers who have purchased a suspect chassis from a 3rd party vendor or channel partner may need to contact Cisco via the email at FN29400-Stickers@cisco.com, in order to receive a set of stickers. \r<br>\r<br>NOTE: AS customers will be proactively contacted by their respective AS engineers for WS-C6513 chassis upgrades.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/200/fn29400.html"
        },
        {
            "fieldNoticeId": 29407,
            "status": "P",
            "bulletinLastUpdated": "2006-02-07T15:16:54Z",
            "bulletinTitle": "FN - 29407 - WS-X6548-GE-TX Block of Eight Ports May Stop Transmitting - Linecard firmware fix",
            "bulletinFirstPublished": "2004-05-10T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "A block of eight ports may stop transmitting packets on a WS-X6548-GE-TX.",
            "background": "A timing conflict may occur on the WS-X6548-GE-TX that can result in a block of eight ports failing to transmit data. \r\nThis problem is caused by slight timing variations between the flow control PLDs and the interposers on the board.  This problem is independent of the Supervisor running in the system.\r\n\r\nHW Versions 4.0 through 9.0 are affected. Anything above HW version 9.0 is NOT affected. Any bank of 8 ports can be affected. \r\n\r\nA software utility has been developed which customers can use to correct this timing issue.",
            "problemSymptoms": "This problem manifests itself as the block of eight ports not passing traffic.",
            "workaround": "Customers can use a software utility to correct this problem. The software utility <b>(epld-6548getx-swupdate-1.hZ)</b> is located here (normal Hybrid/CatOS Catalyst 6500/6000 CatOS System Software area):\r\n\r\nhttp://www.cisco.com/cgi-bin/tablebuild.pl/cat6000-sup\r\n\r\n\r\nPlease see below for instructions on using the utility.\r\n\r\n<b>For Customers running CatOS: </b>\r\n<pre>1. Verify that you are running CatOS version 8.2(2) or above if you have a Voice Daughterboard installed. <i>If you are not running this version, please upgrade to be able to use this utility. </i> Boards without Voice Daughterboards can run the utility with any CatOS version.\r\n2. Copy the Software Utility 'epld-6548getx-swupdate-1.hZ' to slot0.\r\n3. Verify the image has been copied successfully.\r\n4. To begin utility, use the following command: <b>download epld slot0:epld-6548getx-swupdate-1.hZ 'slot_number'</b>\r\n5. Please read Warning message and type <b>Y</b> to continue.\r\n6. Please read Warning message and type <b>Y</b> to upgrade device.\r\n7. The linecards in the slot number specified will automatically be updated.\r\n<b>Note:</b> <i>If slot_number is not specified, the utility will search the system and all affected linecards will be upgraded.</i></pre>\r\n\r\nFor a detailed example of the upgrade and instructions on verifying a successful upgrade, please refer to the <b>Upgrade Instructions</b> section below. \r\n\r\n\r\n<b>For Customers running IOS:</b>\r\n<pre>1. Verify that you are running IOS version 12.2(18)SXD or above. <i>If you are not running this version, please upgrade to be able to use this utility. </i> \r\n2. Copy the Software Utility 'epld-6548getx-swupdate-1.hZ' to bootflash.\r\n3. Verify the image has been copied successfully.\r\n4. <font color=red><b>***IMPORTANT*** -></font> You must disable service heartbeats:\r\n     config t\r\n     no service hearbeat\r\n     end\r\n</b>\r\n5. To begin utility, use the following command: <b>upgrade epld slot 'slot_number' file sup-bootflash:epld-6548getx-swupdate-1.hZ</b>\r\n7. The linecards in the slot number specified will automatically be updated.\r\n8. <font color=red><b>***IMPORTANT*** -></font> You must re-enable service heartbeats:\r\n     config t\r\n     default service heartbeat\r\n     end\r\n\r\nFor a detailed example of the upgrade and instructions on verifying a successful upgrade, please refer to the <b>Upgrade Instructions</b> section below.",
            "hardwareLevels": "",
            "upgradeProgram": "",
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/200/fn29407.html"
        },
        {
            "fieldNoticeId": 29412,
            "status": "P",
            "bulletinLastUpdated": "2005-11-01T15:18:21Z",
            "bulletinTitle": "Configuration Not Cleared From Manufacturing On Spares Catalyst WS-X4013+= and WS-X4515=",
            "bulletinFirstPublished": "2004-03-31T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "O",
            "problemDescription": "Spare units of Supervisor II+ (WS-X4013+=) and spare units of Supervisor IV (WS-X4515=) were shipped from Cisco Manufacturing without test configurations erased prior to shipment. Only spares units are affected.",
            "background": "Cisco has discovered that certain spare units of Supervisor II+ (WS-X4013+=) and spare units of Supervisor IV (WS-X4515=) had been shipped from manufacturing without test configurations removed. This resulted in the affected units containing configuration settings which may not be appropriate for production network use. These settings should be changed at time of installation.",
            "problemSymptoms": "The symptoms of the units loaded with incorrect test scripts are as follow:\r<br>\r<br>Â· VLANs are defined\r<br>Â· Static MAC addresses are defined\r<br>Â· Spanning Tree Protocol is turned off in VLAN1 by default\r<br>Â· CDP is DISABLED by default\r<br>\r<br>Example\r<br>Output of Â¿show runÂ¿ command for units affected by this problem resembles the following\r<br>(items affected and in-line comments are highlighted in red):\r<br>Switch>en\r<br>Switch#term len 0\r<br>Switch#sh run\r<br>Building configuration...\r<br>Current configuration : 8695 bytes\r<br>!\r<br>version 12.1\r<br>no service pad\r<br>service timestamps debug uptime\r<br>service timestamps log uptime\r<br>no service password-encryption\r<br>service compress-config\r<br>!\r<br>hostname Switch\r<br>!\r<br>boot system flash bootflash:cat4000-i9s-mz.121-19.EW1.bin\r<br>logging console errors\r<br>!\r<br>vtp mode transparent\r<br>default VTP mode should be set to server\r<br>!\r<br>ip subnet-zero\r<br>!\r<br>no spanning-tree vlan 1,100-115\r<br>(STP should not be disabled by default for any VLAN)\r<br>!\r<br>interface GigabitEthernet1/1\r<br>switchport access vlan 100\r<br>switchport mode access\r<br>(Uplink port should not be pre-defined to a VLAN, or in switchport mode access)\r<br>no cdp enable\r<br>(CDP should not be disabled by default)\r<br>!\r<br>interface GigabitEthernet1/2\r<br>switchport access vlan 115\r<br>switchport mode access\r<br>no cdp enable\r<br>!\r<br>interface FastEthernet2/1\r<br>no cdp enable\r<br>! interface FastEthernet2/2\r<br>no cdp enable\r<br>!\r<br>interface Vlan1\r<br>no ip address\r<br>!\r<br>ip classless\r<br>no ip http server\r<br>!\r<br>!\r<br>no cdp run\r<br>(CDP should not be disabled by default)\r<br>!\r<br>line con 0\r<br>stopbits 1\r<br>line vty 0 4\r<br>login\r<br>!\r<br>mac-address-table static 0011.2233.4401 vlan 100 interface GigabitEthernet1/1\r<br>mac-address-table static 0011.2233.4402 vlan 115 interface GigabitEthernet1/2\r<br>(Static MAC address should not be on the config by default)   \r<br>",
            "workaround": "Please follow the process outlined below to correct:\r<br>\r<br>Â· In CLI, execute a Â¿write eraseÂ¿command\r<br>Â· Reload the switch to clear existing configuration settings\r<br>Â· Answer Â¿yesÂ¿ when asked by the system if it is OK to proceed since there will be a change in configurations\r<br>\r<br>Specific items in the configurations can also be corrected one at a time. As an example, the following configuration commands can be executed individually to correct the pre-set items given in the example in the last section:\r<br>\r<br>config t\r<br>spanning-tree vlan 1,100-115\r<br>vtp mode server\r<br>cdp run\r<br>no mac-address-table static 0011.2233.4401 vlan 100 interface\r<br>GigabitEthernet1/1\r<br>no mac-address-table static 0011.2233.4402 vlan 115 interface\r<br>GigabitEthernet1/2\r<br>interface GigabitEthernet1/1\r<br>no switchport access vlan 100\r<br>no switchport mode access\r<br>interface GigabitEthernet1/2\r<br>no switchport access vlan 115\r<br>no switchport mode access\r<br>interface range gig1/1 - 2 , interface fa 2/1 - 48 , (etc.... matching the linecards/ports in the chassis.... can only enter 5 ranges in this command)\r<br>cdp enable\r<br>",
            "hardwareLevels": "",
            "upgradeProgram": "",
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/200/fn29412.html"
        },
        {
            "fieldNoticeId": 29536,
            "status": "P",
            "bulletinLastUpdated": "2006-04-18T11:14:52Z",
            "bulletinTitle": "FN - 29536 - Enhanced FlexWAN line cards may get power-cycled by the supervisor, due to Switch-module Configuration Prototcol keepalive failures - Replace Hardware",
            "bulletinFirstPublished": "2004-08-10T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "<BLOCKQUOTE>\r\n<b>Only Enhanced FlexWAN line cards with the Serial Numbers detailed below are affected by this problem.</b>\r\n\r\nEnhanced FlexWAN line cards may get power-cycled by the supervisor, due to Switch-module Configuration Prototcol (SCP) keepalive failures.\r\n\r\nThis problem does not affect the supervisor and is independent of the type of supervisor or IOS software release\r\nthat is running on the supervisor. Please refer to the <a href=\"http://www.cisco.com/univercd/cc/td/doc/product/core/cis7600/iosrns/index.htm\">IOS Software Release Notes </a> to determine IOS software support for the Enhanced\r\nFlexWAN.\r\n\r\nAs of approximately April 12th 2004 new products that were manufactured under Engineering Change Order (ECO) E077521 \r\nor Deviation D073348 are guaranteed to be free of this problem. \r\n\r\nTo identify the hardware version or deviation location please refer to the 'How to Identify Hardware Levels' section of this Field Notice.\r\n</BLOCKQUOTE>",
            "background": "<blockquote>\r\nAn issue was discovered in the Enhanced FlexWAN that causes the failure of data transfer between the\r\ntemperature sensor and the CPU. Environmental variables will continue to read correctly up until the failure occurs.\r\n\r\nWhen the failure occurs the CPU of the line card is consumed waiting for a response from the temperature sensor hence\r\ncausing the line cards failure to respond to SCP keepalives from the supervisor. As a result the supervisor detects that the\r\nline card is unresponsive and attempts to power cycle the line card.\r\n</blockquote>",
            "problemSymptoms": "<BLOCKQUOTE>\r\nEnhanced FlexWAN line cards may get power-cycled by the supervisor due to SCP keepalive failures. The supervisor resets the Enhanced Flexwan module with the following messages on the SP/RP console:\r\n\r\n<b>%OIR-6-REMCARD: Card removed from slot[dec],interfaces disabled\r\n\r\n%OIR-6-REMCARD: Card removed from slot[dec], interfaces disabled\r\n\r\n%OIR-SP-3-PWRCYCLE: Card in module [dec], is being power-cycled off (Module not responding to Keep Alive polling)  \r\n</b>\r\n\r\nIf you are running <b>12.2(17D)SXB1 or above </b> the crashinfo file on the line card will record the following error message:\r\n\r\n<b>%ENVM-2-TEMP_SENSOR_READFAIL: Failed to access the Temperature sensor on the line card. Resetting the line card.</b>\r\n\r\nWhen the line card boots up after the reset the temperature sensor access will now be disabled on the line card and the following error message will appear on the RP:      \r\n\r\n<b>%ENVM-3-TEMP_SENSOR_DISABLED: Access to Temperature sensor on module in slot [dec] is disabled </b>\r\n\r\nFor further information on the error messages please refer to DDTS <a href=\"http://www.cisco.com/cgi-bin/Support/Bugtool/onebug.pl?bugid=CSCee33103&Submit=Search\">CSCee33103</a>.\r\n</BLOCKQUOTE>",
            "workaround": "<blockquote>\r\n<b><u> Workaround:</u></b>\r\n\r\n    There is no known work around for this issue.\r\n\r\n<b><u> Solution:</u></b>\r\n\r\nCisco recommends a fix-on-fail strategy for this problem.\r\n\r\nAs of approximately April 12th 2004 new products that were manufactured under Engineering Change Order (ECO) E077521 \r\nor Deviation D073348 are guaranteed to be free of this problem. \r\n\r\nService Logistics has known-good inventory at this time. The standard RMA process and delivery times are in effect.\r\n\r\nNote: Products that fall within the serial number range listed below are NOT affected by this problem if they have ECO E077521 or Deviation D073348 applied.\r\n</blockquote>",
            "hardwareLevels": "",
            "upgradeProgram": "",
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/200/fn29536.html"
        },
        {
            "fieldNoticeId": 29736,
            "status": "P",
            "bulletinLastUpdated": "2005-10-24T13:59:23Z",
            "bulletinTitle": "XENPAK-10GB-ER Replacement Program",
            "bulletinFirstPublished": "2004-05-14T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "XENPAK-10GB-ER / XENPAK-10GB-ER=, manufacturing Part No. <b>800-24557-01</b>, has been found to have a mechanical tolerance issue which may cause connector pin misalignment between the XENPAK and the Catalyst 6500 line card/Catalyst 3750 switch, when the XENPAK is installed in the line card/switch or removed from the line card/switch.  This misalignment can short the connector pins, which may potentially cause the connector to fail, to melt, or to burn.\r\n&nbsp;",
            "background": "During internal testing Cisco identified a mechanical tolerance issue with the XENPAK-10GB-ER, manufacturing Part No. 800-24557-01, which may cause connector pin misalignment between the XENPAK and the device it is installed in.",
            "problemSymptoms": "There are three main symptoms:\r\n\r\n1) The misalignment can reset the Catalyst 6500 line card or the Catalyst 3750 switch upon insertion. \r\n\r\n2) The misalignment can cause the pads on the XENPAK printed circuit board to disintegrate. \r\n\r\n3) The misalignment can short the connector pins, which can potentially cause the connector to fail, to melt, or to burn during the insertion of the XENPAK into the line card/switch or removal of the XENPAK from the line card/switch. Some smoke may be emitted for a brief period, but this does not pose a fire hazard.",
            "workaround": "There is no field workaround for this issue. Customers should replace the XENPAK-10GB-ER / XENPAK-10GB-ER=, manufacturing Part No. <b>800-24557-01</b>.  Please request a replacement by using the regular RMA process.\r\n\r\n<BR><BR>When you receive the replacement XENPAK please follow the steps when replacing the Xenpak in your system:<BR><BR><BR><b><font color = blue><u> When using the XENPAK with Catalyst 6500</u></font></b><BR><BR><BR>1.\tRemove the line card from the switch without removing the affected XENPAK from the line card.<BR><BR>2.\tRemove the affected XENPAK from the line card<BR><BR>3.\tInsert the new XENPAK in the line card.<BR><BR>4.\tInsert the line card in the switch. <BR><BR>5.\tReturn the defective XENPAK to Cisco.<BR><BR><BR><BR><b><font color = blue><u> When using the XENPAK with Catalyst 3750 </u></font></b><BR><BR><BR>1. Save all your settings.<BR><BR>2. Power off the switch. If used in a Stack, the other switches in the stack do not need to be powered off.<BR><BR>3. Remove the affected XENPAK from the switch.<BR><BR>4. Insert the new XENPAK in the switch.<BR><BR>5. Power ON the switch.<BR><BR>6. Return the defective XENPAK to Cisco.<BR>\r\n&nbsp;",
            "hardwareLevels": "",
            "upgradeProgram": "",
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/200/fn29736.html"
        },
        {
            "fieldNoticeId": 61240,
            "status": "P",
            "bulletinLastUpdated": "2005-09-23T12:45:20Z",
            "bulletinTitle": "A Serial EEPROM Value May Be Configured Incorrectly On Some WS-X6748-GE-TX Linecards",
            "bulletinFirstPublished": "2004-08-03T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "Some WS-X6748-GE-TX linecards may incorrectly display a power consumption value of -5.86A rather than a correct value of -7.00A.",
            "background": "A series of WS-X6748-GE-TX linecards were inadvertently released to the field with a Serial EEPROM which was programmed with an incorrect power consumption value.  Engineering Change Order (ECO) E076782 was implemented to correct this problem in future WS-X6748-GE-TX builds, and an EEPROM update software image has been released to update affected linecards in the field.",
            "problemSymptoms": "Affected WS-X6748-GE-TX linecard will display an incorrect power consumption value when either the <b>show idprom module [slot]</b> (IOS) or <b>show sprom </b> (CatOS) commands are executed.  Below are output examples of both the IOS and CatOS commands.  \r\n\r\n<pre><b>Cisco IOS Software:</b>\r\n  Router# <b>show idprom module 4</b>\r\n  IDPROM for module #4\r\n    (FRU is 'CEF720 48 port 10/100/1000mb Ethernet')\r\n    OEM String = 'Cisco Systems'\r\n    Product Number = 'WS-X6748-GE-TX'\r\n    Serial Number = 'SAD01234567'\r\n    Manufacturing Assembly Number = '73-9098-02'\r\n    Manufacturing Assembly Revision = '03'\r\n    Hardware Revision = 0.903\r\n    Current supplied (+) or consumed (-) = <i>-5.86A   !--- Should read -7.00A</i>\r\n    \r\n  <font color=blue><i>!--- Important output in italics</font color=blue></i>\r\n \r\n<b>Cisco CatOS Software:</b>\r\n  Console> (enable) <b>show sprom 3</b>\r\n  Common block:\r\n   Block Signature : 0xabab\r\n   Block Version   : 3\r\n   Block Length    : 160\r\n   Block Checksum  : 0x150b\r\n   EEPROM Size     : 512\r\n   Block Count     : 2\r\n   FRU Major Type  : 0x6003\r\n   FRU Minor Type  : 0x3ef \r\n   OEM String      : Cisco Systems\r\n   Product Number  : <i>WS-X6748-GE-TX</i>\r\n   Serial Number   : SAD01234567\r\n   Part Number     : <i>73-9098-02</i>\r\n   Part Revision   : 02   \r\n   Mfg Deviation   :  \r\n   H/W Version     : 0.902\r\n   Mfg Bits        : 0\r\n   Engineer Use    : 0\r\n   snmpOID         : 9.5.1.3.1.1.2.1007\r\n   Power Consump   : <i>-586     !--- Should read -700</i>\r\n   RMA Code        : 0-0-0-0  \r\n   CLEI            :\r\n\r\n   [Remaining Output Removed...]\r\n   \r\n   <i><font color=blue>!--- Important output in italics</font color=blue></i> </pre>",
            "workaround": "In order to ensure that all WS-X6748-GE-TX linecards in the field are properly updated with the correct power consumption value, Cisco has developed a software image to update these values without the need for an RMA or product replacement.  This EEPROM update image can be executed on the Supervisor720 of any Catalyst 6500 Switch containing one or more WS-X6748-GE-TX linecards.  The EEPROM update software image is designed for one time use, and will not replace your current IOS or CatOS image.  After executing the EEPROM update, the original software image must be restored on the Supervisor720.  \r\n\r\nThe upgrade procedure includes downloading an EEPROM update image, copying that image to system flash, booting the system to ROMMON, executing the EEPROM update image, and then restoring the system's previous IOS or CatOS image. Once this process has been successfully completed, the linecard should report the correct power consumption value.\r\n\r\n<i><b>Note:</b> This procedure is service impacting, and as such, will require a scheduled downtime in which the Catalyst switch can be taken offline and booted into ROMMON mode.</i>\r\n\r\n\r\n<b>Step 1:</b> Download the WS-X6748-GE-TX EEPROM update image via the link below:\r\n\r\n <a href=\"http://www.cisco.com/cgi-bin/Software/Tablebuild/doftp.pl?ftpfile=cisco/lan/catalyst/6000/supervisor/sprom-sup720-6748getx-swupdate-1.hZ&app=Tablebuild&status=showC2A&swtype=FCS&software_products_url=%2Fcgi-bin%2Ftablebuild.pl%2Fcat6000-sup&isChild=&appName=&tbtype=cat6000-sup\">sprom-sup720-6748getx-swupdate-1.hZ</a>\r\n\r\n<b><i>Note:</b> This image must only be run from the active Supervisor while it is in ROMMON. If a standby Supervisor is present, it will need to be physically removed from the system for the duration of the upgrade procedure.</i>\r\n\r\n<b>Step 2:</b> Establish a direct console connection to the active Supervisor module using a standard Cisco console cable (rolled RJ45). Telnet and SSH connections CANNOT be used during this procedure, as these features will be disabled once the system is booted into ROMMON during <b>Step 6</b>.\r\n\r\n<b>Step 3:</b> Copy the EEPROM Update image onto the system flash or a removable flash device installed in the system. This process is the same as that used to copy any image onto a Cisco flash device. For more information on this procedure, please refer to either the Cisco IOS Software document entitled <a href=\"http://www.cisco.com/en/US/products/sw/iosswrel/ps1835/products_configuration_guide_chapter09186a00800c6c63.html#wp1000872\">Loading and Maintaining System Images</a> or the Cisco CatOS document entitled <a href=\"http://www.cisco.com/en/US/products/hw/switches/ps700/products_configuration_example09186a0080116ff0.shtml#pre3\">Upgrading Software Images on Catalyst 6000/6500 Series Switches</a>.\r\n\r\n\r\n<b>Step 4a:</b> Record the name and location of the current software image running on the system. This can be accomplished by issuing one of the following commands and witting down the output indicated in italics.\r\n\r\n<pre><b>Cisco CatOS:</b>\r\n     Console> (enable) <b>show version | include System Boot Image File</b>\r\n     System Boot Image File is <i>'[device]:[System-image-name]'</i>\r\n\r\n     <font color=blue><i>!--- Important output in italics</i></font color=blue>\r\n\r\n<b>Cisco IOS:</b>\r\n     Router# <b>show version | include System image</b>\r\n     System image file is <i>\"[device]:[System-image-name]\"\r\n\r\n     <font color=blue>!--- Important output in italics</i></font color=blue> </pre>\r\n<b>Step 4b:</b> Record the current configuration register value by issuing one of the following commands, and witting down the output indicated in italics.\r\n\r\n<pre><b>Cisco CatOS:</b>\r\n     Console> (enable) <b>show version | include Configuration register</b>\r\n     System Configuration register is <i>0x2\r\n     \r\n     <font color=blue>!--- Important output in italics</i></font color=blue>\r\n\r\n<b>Cisco IOS:</b>\r\n     Router# <b>show version | include Configuration register</b>\r\n     Configuration register is <i>0x2102\r\n\r\n     <font color=blue>!--- Important output in italics</i></font color=blue> </pre>\r\n<b>Step 4c:</b> Record the current amount of power available in the system by issuing one of the following commands, and writing down the output indicated in italics.\r\n\r\n<pre><b>Cisco CatOS:</b>\r\n     Console>(enable) <b>show environment power | include Remaining</b>\r\n     Remaining Power in the System: <i>476.70</i> Watts (11.35 Amps @42V)\r\n\r\n     <font color=blue><i>!--- Important output in italics</i></font color=blue>\r\n            \r\n<b>Cisco IOS:</b>\r\n     Router# <b>show power available</b>\r\n     system power available =  <i>265.86</i> Watts ( 6.33 Amps @ 42V)\r\n\r\n     <font color=blue><i>!--- Important output in italics</i></font color=blue> </pre>\r\n<b>Step 5:</b> Set the configuration register so that upon reload, the system will boot into ROMMON.\r\n\r\n<pre><b>Cisco CatOS:</b>\r\n     Console> (enable) <b>set boot config-register 0x0</b>\r\n\r\n<b>Cisco IOS:</b>\r\n     Router# <b>configure terminal</b>\r\n     Router#(config) <b>config-register 0x0</b>   \r\n     Router#(config) <b>exit</b> </pre>\r\n<b>Step 6:</b> At this point in the process the original system image should be saved to a valid flash device, and the system image name/location, configuration register, and available power values should be recorded or logged in a safe place. Once each of these tasks is complete, it is safe to reload the system so that it can boot into ROMMON mode.\r\n\r\n<pre><b>Cisco CatOS:</b>\r\n     Console> (enable) <b>reset</b>\r\n\r\n<b>Cisco IOS:</b>\r\n     Router# <b>reload</b> </pre>\r\n<b><i>Note:</b> If at any point during the reload process you are prompted to save your configuration file, do so, or you will lose any configuration changes made since the last save.</i>\r\n\r\n\r\n<b>Step 7:</b> Once the system has been reloaded, if you do not see a ROMMON prompt, press the 'Enter' key a couple of times. Once the ROMMON prompt appears you will need to execute the EEPROM update image in order to update the power consumption value of the WS-X6748-GE-TX. Issue the following command to begin the EEPROM update:\r\n\r\n<pre><b>Syntax:</b>\r\n     rommon 1 > <b>boot [device]:sprom-sup720-6748getx-swupdate-1.hZ</b> </pre>\r\n<b>Step 8:</b> Once the update image has been executed you will be presented with the following system prompt:\r\n\r\n<pre>     Enter power available in the system: _</pre>\r\nAt the prompt you should enter the numerical value you recorded in <b>Step 4c</b>.  This value represents the amount of available power in the system (in watts).  If, after entering the power value, you are presented with an error message, please follow the instructions in that error message before continuing to <b>Step 9</b>.  If the update executes successfully and without any errors, simply continue on to <b>Step 9</b>.\r\n\r\n\r\n<b>Step 9:</b> The previously running system image must now be reloaded, using the image identified in <b>Step 4a</b>.\r\n\r\n<pre><b>Syntax:</b>\r\n     rommon 1 > <b>boot [device]:[system-image-name from Step 4a]</b> </pre>\r\n<b>Step 10:</b> Once the system is back online change the config-register back to its original value, as noted in <b>Step 4b</b>.\r\n\r\n<pre><b>Cisco CatOS:</b>\r\n     Console> (enable) <b>set boot config-register [value from Step 4b]</b>\r\n\r\n<b>Cisco IOS:</b>\r\n     Router# <b>config terminal</b>\r\n     Router#(config) <b>config-register [value from Step 4b]</b>\r\n     Router#(config) <b>exit</b> </pre>\r\n<b>Step 11:</b> Power up the standby Supervisor, if present.\r\n\r\n\r\n<b>Example:</b>\r\nBelow is sample output from the successful execution of the EEPROM update image.  Please note, in this example WS-X6748-GE-TX linecards are installed in slots 1 and 9:\r\n\r\n<pre>  rommon 1 > boot disk0:sprom-sup720-6748getx-swupdate-1.hZ\r\n   string is disk0:sprom-sup720-6748getx-swupdate-1.hZ\r\n\r\n   Uncompressing file: <truncated #######>\r\n\r\n   SR71K Interface (600 MHz)\r\n\r\n\r\n   System Power On Diagnostics\r\n   DRAM Size ....................512 MB\r\n   NVRAM Size ...................2048KB\r\n   Level2 Cache .................Present ( 512 KB)\r\n   Level3 Cache .................Present (2048 KB)\r\n\r\n   Boot image: disk0:sprom-sup720-6748getx-swupdate-1.hZ\r\n   eobc_init_if: unit = 1  okay\r\n   Enter power available in the system: 2325.54\r\n\r\n   Updating module 1 SPROM 1 ....\r\n   Module 1 SPROM 1 has been updated.\r\n\r\n   Updating module 9 SPROM 1 ....\r\n   Module 9 SPROM 1 has been updated.\r\n   \r\n   **************************************\r\n   SPROMs in 2 modules have been updated.\r\n   **************************************\r\n   System Bootstrap, Version 7.7(1)\r\n   Copyright (c) 1994-2003 by cisco Systems, Inc.\r\n   Cat6k-Sup720/SP processor with 524288 Kbytes of main memory\r\n\r\n   rommon 1 ></pre>\r\n<b>New Product Shipment Status</b>\r\nAs of approximately January 1, 2004, WS-X6748-GE-TX linecards manufactured under Engineering Change Order (ECO) E076782 are guaranteed to be free of this defect.  \r\n\r\n<b>RMA Product Shipment Status</b>\r\nProduct shipped from Service Logistics RMA Depots may still exhibit this problem. To ensure that a replacement part is NOT affected by this problem, please request that any RMA placed for a WS-X6748-GE-TX is processed as \"Manufacturing New\".  Please note that replacements fulfilled through this process typically take 3 business days or more to arrive on-site, therefore service level agreements will not apply.",
            "hardwareLevels": "",
            "upgradeProgram": "",
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/610/fn61240.html"
        },
        {
            "fieldNoticeId": 61876,
            "status": "P",
            "bulletinLastUpdated": "2005-12-06T15:53:40Z",
            "bulletinTitle": "uBR10k Chassis RF shielding update for PRE2 Processor Use",
            "bulletinFirstPublished": "2004-11-09T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "Upgrading uBR10012 chassis [-02 or earlier] using ESR-PRE2 processor board may result in EMI emissions exceeding Class B standard for some individual units. This condition is not harmful to the ESR-PRE2 board or uBR10k chassis, but may result in excessive RF emissions in some ranges. Installation of the upgrade kit [53-2514-01] will resolve this condition.\r\n\r\nNote: An ESR chassis does not need to be upgraded to use the PRE2. The upgrade kit WILL NOT work in an ESR chassis and can cause clearance issues.",
            "background": "Cisco testing of the ESR-PRE2 processor board in older uBR10k chassis has revealed that the processor board does not meet the CISCO manufacturing EMI emission margins for Class B at certain frequencies. A field modification to RF containment materials is available in kit form to upgrade older chassis to compliance.\r\n\r\nuBR Chassis TAN 800-09026-02 will version to 800-09026-03 to indicate that the ECO E079961 changes are incorporated. \r\n\r\nThe new CLEI code for the upgraded chassis is IPMFK10ERA.\r\n\r\nPCN [Number TBD] documents this change for service provider customers. \r\n\r\nOnly uBR10k chassis with a version number of -02 or earlier should be upgraded. \r\n\r\nESR10k is not affected.",
            "problemSymptoms": "RF emissions that have the potential to be outside of Class B spec in certain frequency ranges. Symptoms detection is difficult without the aid of sensitive RF measuring equipment and a stable test environment. \r\n\r\nNo effects are expected to be directly visible in customer networks.",
            "workaround": "Workaround:\r\nThere is no workaround\r\n\r\nSolution:\r\nField upgrade uBR chassis [version -02 or -01] with uBR10k RF kit 53-2514-01 with RF suppression material at specific locations on the chassis as indicated in kit documentation.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/610/fn61876.html"
        },
        {
            "fieldNoticeId": 62042,
            "status": "P",
            "bulletinLastUpdated": "2006-07-20T11:01:58Z",
            "bulletinTitle": "FN - # 62042 - WS-C3750G-16TD-E/-S: Hardware failure, system reboots, lose network connectivity - Replacement Required",
            "bulletinFirstPublished": "2005-07-18T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "Customers using Cisco's Catalyst WS-C3750-16TD-E and -S Switches may experience intermittent system reboots, loss of network connectivity and system functionality (including console port access) or an inability to power up, due to an overstressed transistor.",
            "background": "Switch failures have exposed a deficiency related to the overstressing of a transistor device on the WS-C3750G-16TD-E and -S switches. This deficiency results in a shorter operational life for the unit, although full lifespan durations vary widely.",
            "problemSymptoms": "Initial indications of pending failure would be:\r\n\r\n1. Switch spontaneously reboots during high traffic periods. \r\n2. Switch is unable to boot up. \r\n3. Switch LEDs do not illuminate when unit is powered on. \r\n\r\nWhen the unit fails, the system will become non-functional resulting in a loss of network connectivity.",
            "workaround": "<b><u>Workaround</b></u>\r\nThere is no workaround for this problem. \r\n\r\n<b><u>Solution</b></u>\r\nFor customers experiencing this failure, the solution is to replace the affected unit with the regular RMA process (Return Material Authorization). \r\n\r\nPlease first confirm that your WS-C3750G-16TD-E/S switch is affected by this problem by referring to the instructions listed in Section 'How to Identify Affected Hardware'. Once this is confirmed, please order a hardware replacement using the standard RMA process.",
            "hardwareLevels": "",
            "upgradeProgram": "",
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/620/fn62042.html"
        },
        {
            "fieldNoticeId": 62091,
            "status": "P",
            "bulletinLastUpdated": "2006-12-01T08:11:33Z",
            "bulletinTitle": "FN 62091 MGX , Faceplate EMI changes on AXSM-16-155-XG, AXSM-4-2488-XG, SMF-4-2488-SFP, MGX-XM60",
            "bulletinFirstPublished": "2005-06-30T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "On the 8850/B and the 8950 chassis', certain configurations of AXSM-XG and the SMF fail EMC FCC and/or CE-Mark EMC testing. The XM60 card fails only when used in combination with the AXSM-XG cards listed above.",
            "background": "EMI Compliance testing identified specific cards and configurations that need mechanical changes to be compliant.",
            "problemSymptoms": "There is no visible failure symptom for EMI non-compliance. There is no affect on adjacent CE-Mark equipment.\r\n\r\nThe MGX-XM60 is non compliant ONLY when used in combination with either the AXSM-16-155-XG or the AXSM-4-2488-XG.",
            "workaround": "Workaround:\r\nThere is not workaround\r\n\r\nSolution:\r\nTo ensure the products are FCC and CE compliant, RMA the following products when the following conditions exist:\r\n\r\nAXSM-16-155-XG (manufactured prior to 08-June-2005)\r\nAXSM-4-2488-XG (manufactured prior to 08-June-2005)\r\nSMF-4-2488-SFP (manufactured prior to 27-May-2005)\r\nMGX-XM60 <B>ONLY</B> when used in combination with either the AXSM-16-155-XG or the AXSM-4-2488-XG. (MGX-XM60 manufactured prior to 27-May-2005)\r\n\r\nTo identify the TAN/CLEI numbers associated with the manufacture of these products, refer to the instructions below on \"How to Identify Hardware Levels\". \r\n\r\n\r\nNew products that were manufactured under Engineering Change Orders (ECOs) E081668 and E082077 and E082018 are guaranteed to be free of this problem. Refer to \"How to Identify Hardware Levels\" below for instructions on how to view the version and deviation of in-service product. \r\n\r\nProduct shipped from Service Logistics may still exhibit this problem. To ensure an RMA replacement is NOT affected by this problem, request an RMA coded as shown below: \r\n\r\nService Level: Mfg New - 3rd Bus Day NON BILLABLE \r\nFailure Class: Administrative Request \r\nFailure Code: Field Notice Alert \r\n\r\nNote: Replacements fulfilled through this process typically take 3 business days or more to arrive on-site, therefore service level agreements do not apply to RMAs coded as shown above.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/620/fn62091.html"
        },
        {
            "fieldNoticeId": 62344,
            "status": "P",
            "bulletinLastUpdated": "2007-10-09T12:40:47Z",
            "bulletinTitle": "FN#62344 - C3750G-24/48PS & C3560G-24/48PS Switches May Exhibit Early Life Failures Due to a Suspected Faulty Power Supply, RMA required",
            "bulletinFirstPublished": "2006-08-22T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "The switch may experience an early-life failure due to suspected faulty power supply used in certain serial numbers of the switches listed in the Section \"Product Affected\" in this Field Notice. The switch will stop functioning if this problem occurs.",
            "background": "Only those switches with matching Serial Number of the switch and Serial Number of the power supply are affected by this issue.\r\n\r\n<Menu><LI type = \"square\">For the list of affected switch Serial Numbers, please follow the link in section \"Affected Serial Numbers\"<LI type = \"square\">As far as the power supply Serial Number, only those with the prefix <b>\"PAJ\"</b> in the power supply Serial Numbers are affected.</menu>Please refer to section \"How to Identify Hardware Levels\" for an example of a show command output from an affected switch.",
            "problemSymptoms": "The switch stops functioning, as if the power source were removed from the unit.",
            "workaround": "<b><u>Workaround</b></u>\r\nThere is no workaround for this problem. \r\n\r\n<b><u>Solution</b></u>\r\nThe solution is to replace the affected switches.  Please process a standard Return Material Authorization (RMA) to replace the affected switches. \r\n\r\n<u>Note</u><Menu><LI type = \"square\">Please ensure that you take out the SFP modules before returning the defective product.<LI type = \"square\">Service level agreements do not apply to replacements which are fulfilled through this process.</Menu>",
            "hardwareLevels": "",
            "upgradeProgram": "",
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/620/fn62344.html"
        },
        {
            "fieldNoticeId": 62346,
            "status": "P",
            "bulletinLastUpdated": "2006-05-12T15:06:15Z",
            "bulletinTitle": "FN# - 62346 - 7600-SIP-400 may drop bursty egress traffic - upgrade FPD Image",
            "bulletinFirstPublished": "2006-04-20T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "&nbsp;&nbsp;&nbsp;&nbsp; 7600-SIP-400 may exhibit packet loss on the egress interfaces, Cisco has diagnosed that this is more prevalent with bursty traffic patterns. Packet loss on the egress interfaces may result in loss of routing protocol neighbor adjacency, routes etc. Cisco has released an Field Progammable Gate Array (FPGA) upgrade to resolve the halt in packet forwarding on the 7600-SIP-400 linecard. The FPGA fix was first made available in Field Progammable Device (FPD) images for 12.2(18)SXF3 and 12.2(18)SXE5. All product shipped from Cisco Manufacturing contains the updated FPD image. \r\n\r\nNote: For those customers that use Common Language Equipment Identifier (CLEI) codes for traceability, the CLEI code has changed from IPUIAPBRAA to IPUIAZ6RAA.\r\n\r\n<font color=\"#FF0000\">&nbsp;&nbsp;&nbsp;&nbsp;<b>Cisco recommends that all 7600-SIP-400 linecards should be upgraded to the latest FPD image, even if they are not currently seeing the problem.</b> Cisco Best Practice is to load the FPD Image Package corresponding to the IOS version running on the system. In specific situations such as a Field Notice, customers can use the <a href=\"http://www.cisco.com/en/US/products/hw/routers/ps368/module_installation_and_configuration_guides_chapter09186a008044013c.html#wp1067029\">Manual Upgrade SIP FPD Image Procedure </a> to avoid this contingency. </font>\r\n   \r\nUse the following block diagram to determine what action is required.\r\n\r\n<IMG SRC=\"http://www-tac.cisco.com/Support_Library/field_alerts/fn62346_iwlpu1.gif\"><br><br><br>",
            "background": "Engineering analyzed failing 7600-SIP-400 linecards and discovered a problem which was traffic pattern dependant. The failure involved\r\na device on the linecard getting into a locked state such that packet forwarding halted and packets were being dropped. The locked\r\nstate has only been observed on traffic internally designated as \"low priority\" while \"higher priority\" traffic continued to flow.\r\n\r\nThis problem is also being tracked under the ddts CSCsc68250, this can be viewed using the Cisco Bug Toolkit located here:\r\n<a href=\"http://www.cisco.com/kobayashi/support/tac/tools.shtml\">http://www.cisco.com/kobayashi/support/tac/tools.shtml</a>",
            "problemSymptoms": "Customers may experience packet loss, to attribute the packet loss specifically to this problem the Bonham FPGA counters need to be monitored. \r\n\r\nCisco has seen the locked state occur when the Low Priority (LP) buffer drops [<font face=\"Courier New\" size=\"2\"><b>Pkt buf LP pkt drops] </b></font>&nbsp;are \r\n      incrementing and the Low Priority (LP) Buffer Packets [<font face=\"Courier New\" size=\"2\"><b>PKT BUF    LP Packets] </b></font><u>&nbsp;are not</u> incrementing. \r\n\r\nUse the following procedure to check the Bonham FPGA counters. \r\n\r\nConnect to the 7600-SIP-400= using the command <font face=\"Courier New\" size=\"2\">'attach [slot#]'</font> \r\n        <blockquote> \r\n          <p><font face=\"Courier New\" size=\"2\" color=\"#FF0000\">CISCO7609#attach 5<br>\r\n            Entering CONSOLE for slot 5<br>\r\n            Type &quot;^C^C^C&quot; to end this session\r\n            SIP-400-5>\r\n            SIP-400-5> enable\r\n            SIP-400-5#</font></p>\r\n        </blockquote>\r\n\r\nOnce logged into the 7600-SIP-400, check the Bonham FPGA counters using the command <font face=\"Courier New\">'<font size=\"2\">show platform hardware bonham counters | inc Pkt buf|PKT BUF</font>'</font> \r\n        <blockquote> \r\n<font face=\"Courier New\" size=\"2\"color=\"#FF0000\">SIP-400-5#<b>show platform hardware bonham counters | inc Pkt buf|PKT BUF</b><br>\r\n<b>PKT BUF HP Packets (offset 0x050C)&nbsp;&nbsp;&nbsp;137809 <BR>\r\nPKT BUF LP Packets (offset 0x0510) 4691549512<br>\r\nPkt buf HP pkt drops (offset 0x0534) 0 <br>\r\nPkt buf LP pkt drops (offset 0x0538) 576528\r\n</b></font><font size=\"2\"><b> \r\n            </b>&nbsp; </font><font face=\"Courier New\" size=\"2\"> SIP-400-5#</font></p>\r\n        </blockquote>\r\nCisco engineers have only seen the Low Priority Packets exhibit this problem. However it is possible that the High Priority (HP) buffers may exhibit these symptoms therefore both sets of counters should be observed for a couple of cycles.",
            "workaround": "<u>Workaround:</u>\r\nReload the module\r\n\r\n<u>Solution:</u>\r\n\r\nThe new version of FPGA for the Bonham Switch FPGA is version 0.29 and was first made available in the following FPD images: \r\n<blockquote> c7600-fpd-pkg.122-18.SXF3.pkg\r\n c7600-fpd-pkg.122-18.SXE5.pkg\r\n</blockquote>\r\n<font color=\"#FF0000\"> Note: If you are running an SXE IOS image you should use the SXE5 FPD package (c7600-fpd-pkg.122-18.SXE5.pkg). If you are running an SXF IOS image you should use the SXF3 FPD package (c7600-fpd-pkg.122-18.SXF3.pkg). </font>\r\n\r\nTo obtain this software please go to the Software Center on CCO (<a href=\"http://www.cisco.com/public/sw-center/sw-ios.shtml\">http://www.cisco.com/public/sw-center/sw-ios.shtml</a> )and follow the IOS Upgrade Planner \r\nto select your 'platform' and associated FPD Image from either  12.2.18-SXF3 or 12.2.18-SXE5.\r\n\r\n<font color=\"#FF0000\">FPD Image Packages can be upgraded automatically or manually. The FPD automatic upgrade feature only searches for the FPD Image Package file\r\n that is the same version as the Cisco IOS release being used by the system. For example, if the system is running Cisco IOS Release 12.2(18)SXE5, then the system will search for the FPD image package file (c7600-fpd-pkg-122-18SXE5.pkg). Cisco recommends that in specific situations such as a Field Notice,\r\n customers can use the <a href=\"http://www.cisco.com/en/US/products/hw/routers/ps368/module_installation_and_configuration_guides_chapter09186a008044013c.html#wp1067029\">Manual Upgrade SIP FPD Image Procedure </a> to get around this contigency on the Cisco IOS version matching. </font>\r\n\r\nNote: All new product being shipped, contains the upgraded FPD image.\r\n\r\nTo upgrade the 7600-SIP-400, you will need to run the following CLI command, commonly refered to as the Manual FPD Upgrade Procedure:\r\n<blockquote><font face=\"Courier New\" size=\"2\" color=\"#FF0000\">'upgrade hw-module slot &lt;slot&gt; file &lt;filespec&gt;'</font>\r\n    where:    slot     = slot containing SIP400 card filespec = URL of FPD package file.  It can be on disk0:,ftp, tftp, etc\r\n\r\nFor example, if it is on disk0:\r\n    upgrade hw-module slot 5 file disk0:c7600-fpd-pkg.122-18.SXF3.pkg\r\n</font> </blockquote>\r\n\r\nSpecific examples of using this command are available in the <a href=\"http://www.cisco.com/en/US/products/hw/routers/ps368/module_installation_and_configuration_guides_book09186a00802109bf.html\"> Cisco 7600 Series Router SIP, SSC, and SPA Software Configuration Guide</a> under the section titled  <a href=\"http://www.cisco.com/en/US/products/hw/routers/ps368/module_installation_and_configuration_guides_chapter09186a008044013c.html#wp1067029\"> Manually Upgrading SIP and SPA FPD Images.</a>\r\n\r\nIt should only take a few minutes to upgrade the FPGA and the 7600-SIP-400 will automatically get rebooted with the new Bonham Switch FPGA image. \r\n\r\n You can use the following CLI command the verify that the Bonham Swtich FPGA version has upgraded:\r\n<blockquote> <font face=\"Courier New\" size=\"2\">show hw-module slot <slot> fpd </font>\r\n</blockquote>\r\nAfter the upgrade, it should look like this (without SPA's installed):\r\n<IMG SRC=\"http://www-tac.cisco.com/Support_Library/field_alerts/fn62346_iwnun2.jpg\"><br>\r\n<b><u>Note:</u> No IOS changes are required to use the new FPGA version.</b>\r\n\r\nIf you would like some further information on upgrading FPD images, please refer to the following documentation:\r\n<a href=\"http://www.cisco.com/univercd/cc/td/doc/product/core/cis7600/76sipspa/sipspasw/76fpdspa/76fpd.htm\">http://www.cisco.com/univercd/cc/td/doc/product/core/cis7600/76sipspa/sipspasw/76fpdspa/76fpd.htm </a>",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": "Cannot verify work-around since inventory commands to check for FPGA fix are not available.  Manual verification will be required.",
            "url": "http://www.cisco.com/en/US/ts/fn/620/fn62346.html"
        },
        {
            "fieldNoticeId": 62488,
            "status": "P",
            "bulletinLastUpdated": "2008-06-16T12:27:21Z",
            "bulletinTitle": "FN# 62488 WS-C4948-10GE may reset due to multibit ECC error ",
            "bulletinFirstPublished": "2007-06-05T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "The WS-C4948-10GE fixed configuration switch models may reset due to a multibit ECC error on the SDRAM memory.",
            "background": "Cisco has found that the above fixed configuration models have a potential to experience SDRAM degradation. This could result in switch reloads. In advanced circumstances when SDRAM has degraded extensively, the switch could reload and hang on reboot. Factors which influence the extent of SDRAM degradation are the length of time the switch has been in operation along with network traffic patterns that affect SDRAM access. The extent of degradation is not easily quantifiable.",
            "problemSymptoms": "The degradation of SDRAM is a slow process over an extended period of time. Marginal SDRAM degradation can be noted when a switch reloads unexpectedly and leaves behind a multibit-ecc error signature in the crashdump file (See CSCsf14520 for detailed information). Severe SDRAM degradation can be noted when the switch fails to boot and hangs in the process of loading IOS. In such scenarios, while connected to console reset the unit and if system hangs after several hash prompts \"###########\" the problem would be identified.",
            "workaround": "Only WS-C4948-10GE fixed configuration switches with the below Serial numbers AND Hardware Revision numbers are vulnerable.  Please follow the following steps to identify if your switches are affected:\r\n\r\n<b>STEP 1)</b> Check the WS-C4948-10GE Serial Number:\r\na)   Lower than and equal to JAx1008xxxx\r\nb)  JAx1014xxxx to JAx1022xxxx\r\nc) JAx1025xxxx \r\nd) JAx1039xxxx\r\n(where x at any location in the Serial Number can represent any letter or number)\r\n\r\n<b>STEP 2)</b> If Serial Number does not match the values above then the WS-C4948-10GE is not affected.  If the \r\nSerial Number does match please go to STEP 3.\r\n\r\n<b>STEP 3)</b> Check the WS-C4948-10GE to see if it has a vulnerable Hardware Revision number:\r\na) 1.0, 1.1, 1.2\r\nb) 2.0, 2.1, 2.2, 2.3\r\nc) 3.0, 3.1, 3.2\r\n\r\n<b>STEP 4)</b> If both the Serial Number and Hardware Revision number match the values above please use the standard RMA process to order replacement parts. After receiving the replacement switch please return affected unit to Cisco. \r\n    \r\n<font color = red><b>Units that do not meet both the Serial number AND Hardware Revision detailed above are not vulnerable.</b></font>\r\n\r\n<font color = red> <b>NOTE: When replacing units which are affected by this field notice with upgrade units please keep the original power-supplies, 10GE-X2 modules, and power cables so that they can be used in the upgrade units. </b> </font>\r\n\r\nNote to TAC: When using the standard RMA process to replace these units please use the code ARFN (Administrative Request Field Notice) in the \"Failure Code\" field as shown below and put the Field Notice # 62488 in the \"Failure Description\" field:\r\n\r\n<IMG SRC=\"http://www-tac.cisco.com/Support_Library/field_alerts/fn62488_k228oo.bmp\"><br><br><br>",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/620/fn62488.html"
        },
        {
            "fieldNoticeId": 62535,
            "status": "P",
            "bulletinLastUpdated": "2009-04-03T09:01:33Z",
            "bulletinTitle": "FN# 62535 - NPE-G2, Incompatibility With Lower-Revision VXR Series Chassis With  Specific Port Adaptors - RMA required",
            "bulletinFirstPublished": "2007-05-02T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "<p style=\"margin-top: 0; margin-bottom: 0\">NPE-G2 processors manufactured under the above noted assembly and revision numbers have been found to have compatibility issues with specific revisions of Cisco 7204VXR and 7206VXR chassis and the above noted Port Adaptors.&nbsp; A limited number of chassis manufactured beyond the above noted assembly and revision numbers may also be subject to the compatibility issue.</p><p style=\"margin-top: 0; margin-bottom: 0\">&nbsp;</p><p style=\"margin-top: 0; margin-bottom: 0\">All three (3) of the following conditions must be present for the compatibility issues to occur: </p><p style=\"margin-top: 0; margin-bottom: 0\">&nbsp;</p><table border=\"0\" width=\"64%\" id=\"table1\" cellspacing=\"0\" cellpadding=\"0\"><tr><td width=\"24\" align=\"left\" valign=\"top\">1.</td><td align=\"left\">The revision of the NPE-G2 used is noted in the &quot;Products Affected&quot; section above.&nbsp; </td></tr><tr><td width=\"24\" align=\"left\" valign=\"top\">2.</td><td align=\"left\">At least one (1) of the Port Adaptors noted in the &quot;Products Affected&quot; section is plugged into the chassis.&nbsp; </td></tr><tr><td width=\"24\" align=\"left\" valign=\"top\">3.</td><td align=\"left\">An earlier-revision Cisco 7200VXR series chassis is used (refer to the &quot;How to Identify Hardware Levels &quot; section for more details).</td></tr></table><p style=\"margin-top: 0; margin-bottom: 0\">&nbsp;</p><p style=\"margin-top: 0; margin-bottom: 0\">This field notice does not apply if any one (1) of these three (3) conditions is not present.</p>",
            "background": "<p>The above noted revisions of the NPE-G2 have been found to be incompatible with earlier revision Cisco 7204VXR and 7206VXR chassis when used in conjunction with specific port adaptors (noted above).&nbsp; The affected NPE-G2 processors were manufactured with a PCI bridge component that is not compatible with the PCI bridge component used in the earlier revision 7204VXR and 7206VXR chassis.&nbsp; The PCI bridge component used in the affected chassis has been found to manipulate PCI data transactions to the PCI bridge on the NPE-G2 in such a way that the data transactions can become corrupted.&nbsp; This data corruption will lead to a failure of the port adaptor and a possible system crash.</p><p>This issue mostly affects the noted revisions of the NPE-G2 processor when installed in 7200 VXR series chassis manufactured under the above noted top assembly numbers (TAN) and hardware revision number ranges (2.7 and below).&nbsp;&nbsp; A limited number of chassis with TAN and hardware revisions above 2.7 are also affected.&nbsp; An IOS command is available to verify if the suspect chassis is affected with this issue.&nbsp; Most of the affected chassis were shipped prior to (approximately) February 2004.</p>",
            "problemSymptoms": "<p>Problem symptoms associated with this issue include line protocol flaps and output drops on the affected Port Adaptors.&nbsp; Excessive CPU utilization and router crashes have also been observed. The following example shows output of the &quot;show controllers&quot; command on the PA-MC-2T3+ port adaptor. Malformed packets at the &quot;Freedm FIFO&quot; buffer is a typical symptom that has been observed with this issue</p>\r\n<pre><u><b><font face=\"Times New Roman\" size=\"3\">Example of Malformed Packets on the Freedm FIFO Buffer of the PA-MC-2T3+</font></b></u></pre>\r\n<pre>Router#show controllers</pre>\r\n<pre><i><b><font face=\"Times New Roman\" size=\"2\">[Output Omitted for Brevity]</font></b></i></pre>\r\n<pre>2CT3+ SW Controller 3/0\r\n  ROM ver 0x10000, h/w ver 0.2.2, f/w ver 2.5.1, FREEDM rev 1\r\n  T3 linestate is Up, T1 linestate 0x0BE1F5BA, num_active_idb 21\r\n  Buffer pool size 640, particle size 512, cache size 640, cache end 107/89\r\n  Rx desctable 0x38552FA0, shadow 0x4C13A98, size 512, spin 128\r\n    rx queue 0x38566000, cache 0x38566000, fq base 0x38566800\r\n    rdq base 0x38566000, host_rxrdqr 0x385663D0, host_rxfqw 0x38566C08\r\n  Tx desctable 0x38554FE0, shadow 0x4C03A64, size 4096, spin 256\r\n    tx queue 0x38568000, cache 0x38568000\r\n  IDB type=0x16, status=0x0, fastsend 0x0\r\n    host_txrdqw 2523, fq base 0x3856C000, host_txfqr 0x3856F5C4\r\n  dynamic txlimit threshold 4096\r\n  TPD cache 0x4C14A00, size 4096, cache end 4059/4059, underrun 0\r\n  RPD cache 0x4C142CC, size 448, cache end 0\r\n  Freedm fifo 0x4BF4148, head ptr 0x4BF4AA8, tail ptr 0x4BF593C, reset 0\r\n<b>  Freedm fifo</b> corrupted count = 0, <b>Malformed packets = 5400975  \t\t<font color=\"#FF0000\">&lt;-----Malformed Packets at Freedm fifo</font></b>\r\n  PCI bus 6, PCI shared memory block 0x38550644, PLX mailbox addr 0xE0840040\r\n  FREEDM devbase 0xE0800000, PLX devbase 0xE0840000\r\n  Rx overruns 0, Tx underruns 0, tx rdq count 36\r\n  Tx bad vc 0\r\n  unprov_partial_packet 0\r\n  Firmware clock reliability 11/10\r\n  FREEDM err: cas 0, hdl 0, hdl_blk 0, ind_prov 0, tavail 0, tmac busy 0, rmac busy 0\r\n         rxrdq_wt 0xF5, rxrdq_rd 0xF4, rxsfq_wt 0x302, rxsfq_rd 0x313</pre><p><i><b><font face=\"Times New Roman\" size=\"2\">[Output Omitted for Brevity]</font></b></i></p>",
            "workaround": "<p>There is no workaround for this issue.&nbsp; Replacement of the NPE-G2 Network Processing Engine is required.</p><p>NPE-G2 should be replaced using standard RMA process.&nbsp;</p>",
            "hardwareLevels": "",
            "upgradeProgram": "",
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/620/fn62535.html"
        },
        {
            "fieldNoticeId": 62537,
            "status": "P",
            "bulletinLastUpdated": "2007-10-02T13:30:04Z",
            "bulletinTitle": "\"EXPIRED\"  FN - # 62537  Loose latch on some of the GLC-SX-MM.  Customer can request replacement units.",
            "bulletinFirstPublished": "2006-10-11T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "A small number of GLC-SX-MM SFPs may have a latch issue due to which the SFPs could be removed from the SFP cage with very little force and therefore poses a risk of accidental removal from the cage during system operation.",
            "background": "Tooling changes caused the latch dimension not matching to the original specs.",
            "problemSymptoms": "Some of the GLC-SX-MM SFP units may not latch when inserted into the cage.  These SFP units could be removed from the SFP cage with little to no force and without pulling down the bail.  These units pose a risk of accidental removal from the cage during system operation.",
            "workaround": "There is no workaround for this issue.  Customer can use the standard RMA process to request the replacement parts.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/620/fn62537.html"
        },
        {
            "fieldNoticeId": 62570,
            "status": "P",
            "bulletinLastUpdated": "2008-03-11T15:29:03Z",
            "bulletinTitle": "FN # 62570, WS-C3750G-48TS-E, WS-C3750G-48TS-S Printed Circuit Assembly Defect, HW Replacement Required",
            "bulletinFirstPublished": "2007-03-15T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "\"Barrel Cracking\" in the via holes of the Printed Circuit Assembly (PCA) of WS-C3750G-48TS-E and WS-C3750G-48TS-S could potentially threaten the reliability, or shorten the life of the affected switches.",
            "background": "A via hole is a plated hole on the PCA that is not used to attach components, but serves as inter-layer connections.\r\n\r\n\"Barrel cracking\" describes the situation when the plating inside a via hole is cracked. Barrel cracking, whether partial or complete, results in different layers of the PCA not properly connected to each other, and hence the reliability of an affected switch is compromised.\r\n\r\nOnly those switches with matching switch system serial numbers are affected by this issue. For the list of affected switches, please follow the link in section \"Affected System Serial Numbers\".",
            "problemSymptoms": "There is no unique, signature symptom for this defect. Rather, the failed symptoms associated with via-hole defect are numerous. \r\n\r\nExamples of failed symptoms in this case include, but not limited to, loss of traffic, Power-On Self Test (POST) failure when booting up, systems not booting up at all, or certain ports not working properly, etc.",
            "workaround": "Fix on Failure (RMA the switch).  Use the standard RMA process to order replacement.\r\n\r\n<b><u>Notes to TAC</b></u>: Please RMA only switches with affected SN, specified in this field notice.   When using the standard RMA process to replace these units please use the code ARFN (Administrative Request Field Notice) in the \"Failure Code\" field as shown below and put the Field Notice # 62570   in the \"Failure Description\" field : \r\n\r\n<IMG SRC=\"http://www-tac.cisco.com/Support_Library/field_alerts/fn62570_jxc46a.bmp\"><br><br><br>",
            "hardwareLevels": "",
            "upgradeProgram": "",
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/620/fn62570.html"
        },
        {
            "fieldNoticeId": 62606,
            "status": "P",
            "bulletinLastUpdated": "2006-12-13T18:15:28Z",
            "bulletinTitle": "FN# 62606 - Catalyst 6000 Active Supervisor Engine 720 crashes due to an EOBC Jam created by the Online Insertion of a second Supervisor Engine 720 - Software Upgrade required",
            "bulletinFirstPublished": "2006-12-12T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "S",
            "problemDescription": "The Supervisor Engine 720 may restart after a second Supervisor Engine 720 is inserted in the chassis. The Supervisor Engine crash occurs if the Ethernet Out of Band Channel (EOBC) gets jammed during the online insertion process.\r\n<UL>\r\n<LI>This problem occurs in 6500 non-E and 7600 series chassis running affected Cisco IOS software versions.\r\n<LI>This problem occurs when the hardware version of both Supervisor Engines are 5.2 or greater.\r\n<LI>Initially, the problem may not occur. However, once the problem occurs, it may recur during all subsequent online insertions.\r\n</UL>\r\n<b>Note:</b>\r\nTo identify hardware version please refer to <b>How to Identify Hardware Levels</b> Section",
            "background": "An EOBC jam is created by the online insertion (OIR) of standby Supervisor Engine 720 of hardware rev 5.2 when the active Supervisor Engine 720 is also of hardware rev 5.2, in a non-E chassis.\r\n\r\n<b>Note:</b>\r\nFor affected IOS versions please refer to <b>Cisco IOS Versions Affected</b> Section.",
            "problemSymptoms": "Inserting a second Supervisor Engine 720 in a Non-E chassis may cause the active supervisor to crash with EOBC JAM error. The following error message will be displayed.\r\n\r\n<pre><b>Error Message:</b>\r\n\r\nRouter>\r\n00:20:27: %SYS-SP-3-LOGGER_FLUSHING: System pausing to ensure console debugging\r\noutput.\r\n\r\n00:20:27: %EOBC-SP-2-EOBC_JAM: EOBC channel is jammed.  Attempting to diagnose\r\nthe source of the problem and recover if possible.\r\n00:20:27: %OIR-SP-6-CONSOLE: Changing console ownership to switch processor\r\n</pre>",
            "workaround": "Please upgrade IOS software to the following IOS versions accordingly:\r\n<UL>\r\n<LI>12.2(18)SXD07a or later versions.\r\n<LI>12.2(18)SXE06a or later versions.\r\n<LI>12.2(18)SXF06 or later versions.\r\n<LI>12.2(33)SRA01 or later versions.\r\n</UL>",
            "hardwareLevels": "",
            "upgradeProgram": "",
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/620/fn62606.html"
        },
        {
            "fieldNoticeId": 62610,
            "status": "P",
            "bulletinLastUpdated": "2007-03-06T16:37:56Z",
            "bulletinTitle": "FN# 62610 - ONS-SE-G2F-LX(=) Incompatability Issue Recall",
            "bulletinFirstPublished": "2007-03-07T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "The problem vendors SFP has a mechanical bug which \r\ncauses the device to get stuck once plugged into the \r\n15454-GE-XP= card. \r\nIf a customer has a spare Excelight device and tries to plug it onto the 15454-GE-XP= card, the SFP will get stuck.\r\n\r\n<B>NOTE:</B> The latest revision of the Excelight SFP does not have the issue.",
            "background": "During the mechanical qualification test for release 8.0 and the 15454-GE-XP= card, it was found that the 10-2273-01 (ONS-SE-G2F-LX=) supplied by Excelight gets stuck into the 15454-GE-XP card cage.",
            "problemSymptoms": "The problem only appears when the Excelight 10-2273-01 SFP is plugged into the 15454-GE-XP= card.",
            "workaround": "These SFP's cannot be reworked; They will need to be returned for replacement through the normal RMA process.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": "SFP only impacted if plugged into the 15454-GE-XP= card.  Automation is not checking the parent card, so manual verification will be required to see if the SFP is plugged into this specific card.",
            "url": "http://www.cisco.com/en/US/ts/fn/620/fn62610.html"
        },
        {
            "fieldNoticeId": 62710,
            "status": "P",
            "bulletinLastUpdated": "2007-03-15T07:58:36Z",
            "bulletinTitle": "FN# 62710 CRS-1: Manually Downgrading below the Minimum ROMMON levels will render the boards inoperable. See CRS-1 Software/Firmware Compatibility Matrix for Recommended ROMMON levels.",
            "bulletinFirstPublished": "2007-03-15T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "Some CRS-1 boards have been manually downgraded in the field to a ROMMON level that was lower than the minumum required ROMMON level for that board. Manually downgrading below the minimum ROMMON level for a board will render the board inoperable, and it will need to be RMA'd.",
            "background": "Boards which have shipped from Cisco (from Manufacturing or from the Depots) will have a ROMMON version that will either be at the minimum required level for that particular board, or it will be higher than the minimum required level.\r\n\r\nThere have been instances in customer networks where boards have been manually downgraded below the minimum required ROMMON level. Downgrading a board below the minimum ROMMON version for a given board (or version of a board) will render the board inoperable. Downgrading a board below the shipping ROMMON level will regress some fixes and enhancements. \r\n\r\nIf ROMMON is downgraded below the minimum version, field reprogramming will not be possible, and the board will need to be RMA'd.  \r\n\r\n<B>Do not manually downgrade below the minimum ROMMON level on any CRS-1 boards, as it will render the boards inoperable.</B>",
            "problemSymptoms": "Sample error messages after downgrading ROMMON below the minimum level on an MSC:\r\n\r\n\r\n        RP/0/RP1/CPU0:Jan 16 00:44:55.553 : exec[65760]: %MGBL-LIBPARSER-6-HIDDEN_COMMAND : This command has been deprecated: 'show ip interface brief ' \r\n\r\n        RP/0/RP0/CPU0:Jan 16 00:48:23.154 : oir_daemon[273]: %PLATFORM-OIRD-5-OIRIN : OIR: Node 0/4/SP inserted  \r\n        RP/0/RP1/CPU0:Jan 16 00:48:38.000 : shelfmgr[314]: %PLATFORM-SHELFMGR-3-NO_PLIM : Can not power on node 0/4/SP due to absence of PLIM  \r\n\r\n        RP/0/RP1/CPU0:Jan 16 00:49:14.204 : oir_daemon[273]: %PLATFORM-OIRD-5-OIRIN : OIR: Node 0/PL4/SP inserted  \r\n        RP/0/RP1/CPU0:Jan 16 00:49:30.000 : shelfmgr[314]: %PLATFORM-MBIMGR-7-IMAGE_VALIDATED : 0/4/SP: MBI tftp:/disk0/hfr-os-mbi-3.2.3.CSCsd63325-1.0.0/sp/mbihfr-sp.vm validated \r\n\r\n        RP/0/RP1/CPU0:Jan 16 00:50:39.506 : shelfmgr[314]: %PLATFORM-MBIMGR-7-IMAGE_VALIDATED : 0/4/CPU0: MBI tftp:/disk0/hfr-os-mbi-3.2.3.CSCsd63325-1.0.0/lc/mbihfr-lc.vm validated \r\n\r\n        RP/0/RP1/CPU0:Jan 16 00:52:45.142 : shelfmgr[314]: %PLATFORM-MBIMGR-7-IMAGE_VALIDATED : 0/4/SP: MBI bootflash:mbis/hfr-os-mbi-3.2.3.CSCsd63325-1.0.0/012dee822d7af69ccbba2556bac04014/mbihfr-sp.vm validated \r\n\r\n        SP/0/4/SP:Jan 16 00:52:54.936 : init[65541]: %OS-INIT-7-MBI_STARTED : total time 7.361 seconds \r\n        SP/0/4/SP:Jan 16 00:53:07.298 : init[65541]: %OS-INIT-7-INSTALL_READY : total time 19.753 seconds \r\n        SP/0/4/SP:Jan 16 00:56:41.790 : alphadisplay[100]: %PLATFORM-ALPHA_DISPLAY-6-CHANGE : Alpha display on node 0/4/SP changed to          in state default  \r\n\r\n        SP/0/4/SP:Jan 16 00:56:49.167 : alphadisplay[100]: %PLATFORM-ALPHA_DISPLAY-6-CHANGE : Alpha display on node 0/4/SP changed to BRINGDOWN in state default",
            "workaround": "Solution: \r\n\r\n<B>Do not manually downgrade below the minimum ROMMON level on any CRS-1 boards, as it will render the boards inoperable.</B> \r\n\r\nAlso, it is highly recommended that ROMMON levels aren't downgraded below the level that ships out from Cisco. There is a risk that downgrading ROMMON on a board will regress some fixes and enhancements. \r\n\r\nRMA any boards which have been manually downgraded and rendered inoperable.\r\n\r\nUse the following Failure Class & Failure Code in the RMA request form:\r\n\r\nFailure Class: Administrative Request \r\nFailure Code: Field Notice Alert \r\n\r\nUse the following Table to identify minimum ROMMON levels:\r\n\r\n<a href=\"http://www.cisco.com/web/Cisco_IOS_XR_Software/index.html\">CRS-1 Software/Firmware Compatibility Matrix</a>\r\n\r\nNOTE: This table also lists the recommended minimum ROMMON level to upgrade to (for boards and for IOS-XR Releases).",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/620/fn62710.html"
        },
        {
            "fieldNoticeId": 62725,
            "status": "P",
            "bulletinLastUpdated": "2008-10-09T23:24:48Z",
            "bulletinTitle": "FN# 62725 - 7300-NSE-100, 7304-NPE-G100, C7200-I/O, C7200-I/O-2FE/E, C7200-I/O-GE+E, CISCO7301, NPE-G2, NPE-G1, uBR7200-NPE-G1 Unable To Read CF or PCMCIA ATA Flash Disk - Data Loss or System Boot Hang - Replace Flash Card - RMA Required",
            "bulletinFirstPublished": "2007-04-26T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "<p>The PCMCIA ATA Flash Disks and Compact Flash (CF) modules used in specific Cisco products may contain a Manufacturing defect which reduces reliability of the Flash device.&nbsp; Some Cisco 7200, Cisco uBR7200 and Cisco 7300 series network processing engines and I/O cards may contain a suspect Flash device that may not be able to access stored files on the Flash disk. Some Cisco 7301 routers may also contain a suspect Flash device. The router may fail to reboot if it relies on an IOS image stored on the Flash device. <br><br>A portion of the Network Processing Engines and routers manufactured between May 2005 and October 2006 may have shipped with an affected PCMCIA ATA Flash disk or Compact Flash (CF) module from the specific component lots. Refer to the &quot;How to Identify Hardware Levels&quot; section for Flash disk identification information.&nbsp; Refer to the &quot;Serial Number Range&quot; section for serial number bounding information.<br><br>The failure condition would be observed during a power cycle, reload event or during a write event such as a crash file dump. Systems will be unable to pass traffic in the failed state.<br><br>The affected Network Processing Engines and Routers do not allow ROMMON upgrades via software and therefore the affected Flash devices are recommended for replacement. <br><br><b>NOTE 1 - The Network Processing Engine or Router itself is not defective; this issue is only related to the removable Flash Disk cards.</b> <br><br><b>NOTE 2 - As customers may remove and re-use Flash Cards, the affected cards shipped with these products may have been re-used in different Cisco products. Please exercise caution when re-using Flash cards and visually check them against the Identification Section data provided.</b></p>",
            "background": "<p>This issue affects a specific subset of the PCMCIA ATA Disks and Compact Flash cards that were installed in specific Cisco routers manufactured between May 2005 and October 2006. Cards shipped individually as spares over that same time span may also contain one of the affected units. <br><br>This issue has been linked to a component manufacturing problem. The root cause was identified and appropriate steps taken to resolve the problem.<br><br>Product impact varies due to different flash memory access methodologies and use patterns. Some products may be able to mitigate the potential effect by re-writing affected memory areas at specific intervals. This feature does not work with all products, so please check work around section for availability and specific instructions.</p>",
            "problemSymptoms": "<p>The problem symptom is typically seen during a system reload or cold start. Under normal circumstances a router's PCMCIA card or Compact Flash card could contain Cisco IOS software, configurations or other files necessary for system boot or operation. These files are accessed by the router during the boot sequence to reach an operating state. <br><br>In the problem state, the router is unable to access the contents of the Flash disk. When the problem occurs, the system is prevented from accessing directory information stored on the Flash disk. This type of error occurs in the controller of the Flash disk. Data stored on the Flash disk should be intact but may not be accessible. The router may indicate the state with a message log below. The router will be unable to read the contents of the Flash disk that were previously read or written to. <br><br>The output below shows the system log or terminal monitor message when the router is unable to read the Flash disk contents. <blockquote>\r\n<pre>%Error opening slot0:/ (No device available)</pre></blockquote><p><br>The router may stop the boot sequence and remain at a ROM Monitor (ROMmon) prompt as seen below. </p><blockquote>\r\n<pre>Readonly ROMMON initialized  \r\n<BR>boot: cannot open &quot;flash:&quot;  \r\n<BR>boot: cannot determine first executable file name on device &quot;flash:&quot;  \r\n<BR>cxxxx processor with xxxxxx Kbytes of main memory Main memory is configured to 64 bit mode with ECC enabled   \r\n<BR>Readonly ROMMON initialized  \r\n<BR>rommon 1 &gt;</p></blockquote><p><b>NOTE 3 - The Router will be unaffected and continue to run with a failed Flash disk. Only read/write access such as a logfile write to the flash disk or a router reboot will cause the problem symptom to become evident.</b> </p>",
            "workaround": "<p style=\"margin-top: 0; margin-bottom: 0\"><b>Workaround</b> <br>There is no workaround available for Flash disks used in the affected network processing engines or routers. <br><br><b>Solution</b> <br>Customers owning products which are affected by the problem described in this field notice should replace the product with a like product using the standard RMA process.<br><br>Exchange a failed PCMCIA Flash disk or Compact Flash (CF) module with a known good disk and IOS image. Replacement of the Flash card at the next scheduled maintenance window is recommended to prevent a possible reboot hang on router restart.<br><br>Although an upgrade program had previously been provided to replace potentially affected but otherwise working product, the upgrade program is now over and Cisco will only replace product still fall into the parameters defined below. The standard RMA process should be used to replace failed product.</p><p style=\"margin-top: 0; margin-bottom: 0\">&nbsp;</p><p style=\"margin-top: 0; margin-bottom: 0\">For the 7300-NSE-100 and 7304-NPE-G100, both internal and external Compact Flash (CF) modules should be checked using the process described in the &quot;How to Identify Hardware Levels&quot; section.<br><br>&nbsp;</p><p style=\"margin-top: 0; margin-bottom: 0\"><b>Installation Instructions</b></p><p style=\"margin-top: 0; margin-bottom: 0\">PCMCIA ATA Flash Disk or Compact Flash (CF) module installation in a Cisco 7200 Series and uBR7200 Series products: http://cco/en/US/products/hw/routers/ps341/products_quick_start09186a00801e5279.html#wp40088</p><p style=\"margin-top: 0; margin-bottom: 0\">&nbsp;</p><p style=\"margin-top: 0; margin-bottom: 0\">Compact Flash (CF) module installation in a Cisco 7301 router:&nbsp; http://cco/en/US/products/hw/routers/ps352/products_quick_start09186a00801e5248.html#wp42463</p><p style=\"margin-top: 0; margin-bottom: 0\">&nbsp;</p><p style=\"margin-top: 0; margin-bottom: 0\">Compact Flash (CF) module installation in a Cisco 7304 Series product:&nbsp; http://cco/en/US/products/hw/routers/ps352/products_quick_start09186a00800a4ad5.html#wp67413</p><p style=\"margin-top: 0; margin-bottom: 0\">&nbsp;</p><p style=\"margin-top: 0; margin-bottom: 0\">The following diagram shows the locations of the internal Compact Flash (CF) module on the 7300-NSE-100 and 7304-NPE-G100.</p><p style=\"margin-top: 0; margin-bottom: 0\">&nbsp;</p><p style=\"margin-top: 0; margin-bottom: 0\"><img border=\"0\" src=\"http://www-tac.cisco.com/Support_Library/field_alerts/fn62725_jgt9ev.jpg\" width=\"690\" height=\"549\"></p>",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/620/fn62725.html"
        },
        {
            "fieldNoticeId": 62775,
            "status": "P",
            "bulletinLastUpdated": "2007-03-28T13:44:43Z",
            "bulletinTitle": "FN -  62775 -  Cisco Wireless Services Module (WiSM), WS-SVC-WISM-1-K9, Controller firmware storage space compact flash has a data retention problem ",
            "bulletinFirstPublished": "2007-03-29T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "The compact flash (CF) contained on controllers in a WISM (WS-SVC-WISM-1-K9) module may contain a defect preventing access to the Compact Flash during boot and may cause a boot failure following a power cycle or reload. \r\n\r\nDuring a failed state, the controllers will be unable to boot into service. Cisco is providing a Compact Flash replacement kit.",
            "background": "The Compact Flash modules were installed in WISM controllers manufactured until November 2006. \r\n\r\nThis issue has been linked to a Compact Flash vendor manufacturing process. The root cause was identified and appropriate steps taken to resolve the issue.",
            "problemSymptoms": "This issue is typically seen during a system reload or cold start. Under normal circumstances a controllerÂ¿s Compact Flash could contain Cisco IOS software, configurations or other files necessary for system boot or operation. These files are accessed by the controller during the boot sequence to reach an operating state. \r\n\r\nWhen the controller experiences this failure, the controller is unable to access the contents of the Compact Flash. This failure occurs internally on the Compact Flash. \r\n\r\nData stored on the Compact Flash should be intact but may not be accessible.",
            "workaround": "The Compact Flash should be replaced through the normal TAC RMA process as a Â¿HW Manufacturing New, 3 day businessÂ¿ RMA. \r\n\r\nCisco has released a Compact Flash upgrade kit (WS-CFUPGKIT-WISM=), software pre loaded version on flash, 3.2.171.6, that resolves the scenario described in the Problem Symptom section of this field notice. \r\n\r\nThe following instructions are divided into 4 sections:\r\n\r\n1. How to Identify and validate product for this field notice\r\n\r\n2. Recommendation before replacing the compact flash\r\n\r\n3. Instructions on how to replace the compact flash\r\n\r\n4. Recovering image version and configuration\r\n\r\nNOTE: Download and open the following link to your laptop if all connectivity to www.cisco.com will be interrupted during this procedure. \r\n\r\nThis link provides you with instructions on saving configurations and restoring configurations and upgrading the controller.\r\n http://www.cisco.com/univercd/cc/td/doc/product/wireless/control/c44/dep.pdf\r\n\r\nHow to Identify and validate product for this field notice:\r\n\r\n1. Confirm Serial number range: \r\n\r\nWISM controller has a serial number (mfg date) of equal or earlier than SAD1042XXXX (SADYYWWXXXX, 10 for YY is 2006, WW is build week, and XXXX is an alpha numeric counter. \r\n\r\n2. Confirm Cisco Part Number of Compact Flash \r\n\r\nNOTE: This procedure on affected controllers could trigger the symptom and prevent the controller from going into operation after inspection. \r\n\r\nFollow the Recommendation before Replacing Your Compact Flash section before continuing with this procedure.\r\n\r\nPower down and remove the WiSM module from the catalyst 6500 chassis (see special note below). \r\n\r\nRemove the Compact Flash from controller and verify that the Cisco Part Number of Compact Flash is 17-8039-04. \r\n\r\n3. Confirm Make and Date Code of Compact Flash \r\n\r\nInspect that the Compact Flash Prefix (A) begins with Â¿CCFÂ¿, and Manufacturing Production Code (B) is equal to or less than \"060727\". \r\n\r\nManufacturing Code Locations \r\nLocation A - Manufacturing Part Number Prefix \r\nLocation B - Manufacturing Production Code \r\n\r\n<IMG SRC=\"http://www-tac.cisco.com/Support_Library/field_alerts/fn62602_jcsse7.gif\">\r\n\r\n\r\nRecommendation before replacing the Compact Flash\r\n\r\n1. Verify the current software code version on the WISM from the Monitor web page or CLI.\r\nFrom the command line (via the console or SSH)\r\n\r\n(Hostname) >show sysinfo\r\n\r\nManufacturer's Name.............................. \r\nProduct Name..................................... \r\nInformation................................ \r\nVersion..................................... 3.2.171.6\r\n\r\n \r\n2. Cisco recommends that you backup both configurations on the two (2) controllers to an external TFTP server before replacing their Compact Flash.\r\n\r\nThe Backup and Restore operations for a ControllerÂ¿s configurations can be performed from either from the controller itself or from WCS. \r\n\r\nSee Figure (92) \r\nThese Controller Configuration Backup and Restore instructions cover backing up the configuration from the controller itself or by using the WCS. \r\n\r\nNOTE: Always verify that the configuration backup file is on the external device.\r\n\r\nhttp://www.cisco.com/en/US/products/ps6366/prod_technical_reference09186a00806cfa96.html#wp1064769\r\n\r\n3. If the controller is currently running a version of 4.0 codes, ensure that a copy of the software is available for download to the controller after replacing the compact flash.\r\n\r\nInstructions on how to replace the compact flash \r\n\r\nFollow these steps to replace a compact flash card in your WiSM module: \r\n\r\nStep 1: Power off the WiSM unit from the command prompt on the Supervisor 720. \r\n\r\nEnter this Command to power off the unit: \r\nno powers enable module mod \r\n\r\nNote: Shutdown might require several minutes. \r\n\r\nStep 2: The Status LEDs should be off and not orange if the power is off. \r\n\r\nStep 3: Remove the WiSM from the Catalyst 6500 chassis.\r\n\r\nStep 4: Use the Torx wrench provided with  the Upgrade Kit provided from Cisco to remove the screw that secures the compact flash covers on the front of the unit (see figure 1 below). \r\n\r\n<IMG SRC=\"http://www-tac.cisco.com/Support_Library/field_alerts/fn62602_jc39wu.gif\">\r\n\r\n\r\nStep 5: Remove the compact flash cover. Be careful not to let the EMI shielding slip off the cover. \r\n\r\nStep 6: Using your thumb and forefinger, pull the compact flash card out of the slot. \r\n\r\nStep 7: With the Cisco logo label side facing upwards, insert the new compact flash. \r\n\r\nStep 9: Replace the screw and secure the cover. \r\n\r\nStep 10: Re insert the WiSM back to the catalyst 6500 chassis and attach a console cable to the first WLC.\r\n\r\nRecovering Image Version and Configuration\r\n \r\nThis section is divided into 2 parts: version 3.2 recovery procedures and 4.0 recovery procedures.\r\n\r\nPlease see the appropriate instructions.\r\n\r\nIf the WiSM was running a version of 3.2 code (such as 3.2.171.6 in the example above)\r\n\r\nStep 1: Proceed through the setup script and configure the operational parameters for the controller. The controller will reboot at the end of the setup script.\r\n\r\nStep 2: After the WLC reboots, restore the configuration back to the WLC using the instructions in the following link.\r\n\r\nhttp://www.cisco.com/en/US/products/ps6366/prod_technical_reference09186a00806cfa96.html#wp1064769\r\n              \r\nStep 3: Cisco recommends that you save the configuration and reboot.\r\n\r\n\r\nIf your WISM blade is operating version 4.x code (such as 4.0.179.11)\r\n\r\nStep 1: Proceed through the setup script and configure the operational parameters for the controller except enter a non-routable AP manager ip address (e.g. 2.2.2.2). \r\n\r\nThis will prevent the APs from joining the controller and downloading the 3.2 version of code. The controller will reboot at the end of the setup script.\r\n\r\nStep 2: After the WLC reboots, upgrade the WLC to version 4.0 software following the instructions in the link.\r\n\r\nhttp://www.cisco.com/en/US/products/ps6366/prod_technical_reference09186a00806cfa96.html#wp1063900.\r\n\r\nStep 3: Reboot the WLC; so that the WLC loads the version 4.0 software.\r\n\r\n\r\nStep 4: After the WLC reboots, restore the configuration back to the WLC using the instructions in the following link\r\n\r\nhttp://www.cisco.com/en/US/products/ps6366/prod_technical_reference09186a00806cfa96.html#wp1064769\r\n              \r\nStep 5: Cisco recommends that you save the configuration and reboot.",
            "hardwareLevels": "",
            "upgradeProgram": "",
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/620/fn62775.html"
        },
        {
            "fieldNoticeId": 62787,
            "status": "P",
            "bulletinLastUpdated": "2008-06-30T16:28:35Z",
            "bulletinTitle": "FN# 62787 - Safety Notice - Potential Manufacturing Issue on Switches and Redundant Power Supplies",
            "bulletinFirstPublished": "2007-04-23T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "O",
            "problemDescription": "Although there has not been a reported safety incident, Cisco is aware of a potential safety issue that can be caused by a welded nut breaking free inside the switch and Redundant Power Supply (RPS).\r\n\r\nTightening the mounting screws used to secure the power supply or blower module to the switch or the RPS can lead to a welded nut on the interior to the switch or RPS breaking free from the chassis sheet metal.  A risk of electric shock may exist if the chassis is not properly grounded and the loose nut comes in contact with the power supply line-in and chassis.",
            "background": "This problem could be initiated by the separation of the weld nuts in the mounting screw assemblies that are used to secure the power supplies to the switches and the RPS. Several improperly welded mounting nuts were found, when their associated power supply or RPS mounting screws were tightened, resulting in their weld nuts breaking free inside the units.\r\n\r\nThe following series of events can result in a safety issue:\r\n<menu><LI type=square>The affected switches or RPS are connected to the power source.\r\n<LI type=square>The unit does not have a proper connection to earth ground.\r\n<LI type=square>A welded nut breaks free when the power supply mounting screws are tightened.\r\n<LI type=square>The nut enters the power supply assembly and lodges between the AC line-in of the power supply and the chassis, creating a short-circuit. Without a proper ground, the chassis will become electrically energized.\r\n<LI type=square>At this point, any contact with the chassis or the mounting rack, if not properly grounded, could result in an electric shock.</menu>This problem involves only switches that run AC power. In addition, only switches with certain switch system serial numbers and version ID of \"VO1\" are affected by this issue. For the list of affected switches, please follow the link in the <b><u>Affected System Serial Numbers</b></u> section.\r\n\r\nLikewise, only RPS with certain serial numbers a version ID of \"V01\" are affected by this issue. For the list of affected RPS, please follow the link in the <b><u>Affected System Serial Numbers</b></u> section.",
            "problemSymptoms": "A loose weld nut condition cannot be detected by visual inspection.  A unit with a weld nut that has broken free can be detected when one attempts to tighten a power supply or blower mounting screw. Such a screw will not engage the missing weld nut and it will not be possible to completely tighten the screw. Units in operation may be affected by this problem without showing any signs of malfunction.",
            "workaround": "<b><u>Workaround</b></u>:\r\nThe solution is to replace the affected switches and RPS. Use the standard RMA process to order replacement.\r\n\r\n<b><u>Notes to TAC</b></u>: Please RMA only switches with affected SN, specified in this field notice.   When using the standard RMA process to replace these units please use the code ARFN (Administrative Request Field Notice) in the \"Failure Code\" field as shown below and put the Field Notice # 62787   in the \"Failure Description\" field : \r\n\r\n<IMG SRC=\"http://www-tac.cisco.com/Support_Library/field_alerts/fn62570_jxc46a.bmp\"><br><br><br>\r\n\r\n<b><u>Solution</b></u>: \r\nThe solution is to replace the affected switches and RPS. \r\n\r\n</menu>Until a replacement is secured from Cisco, the user can continue to use an impacted switch if it is already installed and operational and all of the following conditions are met:\r\n\r\n1)  The switch is already mounted in a customer rack.\r\n2)  The mounting screws on the power supply or blower have not been un-tightened or retightened.\r\n3)  The unit is properly grounded.\r\n\r\nIf the switch has not yet been installed, do not continue with installation. Instead, use Standard RMA to get a replacement.\r\nCustomers should not try to alter any mounting screws, on any suspect units, whether the unit is currently rack mounted or still in its original shipping container.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/620/fn62787.html"
        },
        {
            "fieldNoticeId": 62823,
            "status": "P",
            "bulletinLastUpdated": "2007-06-14T11:44:09Z",
            "bulletinTitle": "FN # 62823, ONS-XC-10G-S1 XFP Y Cable Protection Does Not Work Properly with a Specific Brand of XFP",
            "bulletinFirstPublished": "2007-06-14T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "The ONS-XC-10G-S1 XFPs used on the MSTP 10GE TXPs with P/N 10-2012-01 and S/N starting with ECL shows an anomalous behavior in Y-cable configuration.",
            "background": "Testing has shown the device 10-2012-01 (with S/N starting with the letters ECL) failed the switch test on a Y-cable configuration exceeding the allowed switching time. \r\n\r\nThis issue only impacts the 15454 MSTP TXP when used in a Y-cable protection configuration. These disruptions were seen/detected by way of control plane protocols (Layer 3- BGP specifically) losing neighbor relationships and reporting a problem via SYSLOG & SNMP.",
            "problemSymptoms": "The total time of intervention of the Y cable protection should be in the order of 50 msec. \r\nThe parts affected are unable to allow meeting this specification.",
            "workaround": "Cisco offers to replace the defective parts on failure if they are being used in a Y-cable environment. \r\nIn this case, the customer is invited to return the defective (ECL) 10-2012-01 XFP's for replacement. \r\nCisco will replace the components with a compliant version of the 10-2012-01 or the new P/N 10-2012-02 version of the part (Both ECL and OTN serial numbers are good).",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/620/fn62823.html"
        },
        {
            "fieldNoticeId": 62832,
            "status": "P",
            "bulletinLastUpdated": "2008-09-11T16:07:58Z",
            "bulletinTitle": "FN# 62832 - Power on Failure on Some  ASA5505 (Adaptive Security Appliances) Systems",
            "bulletinFirstPublished": "2007-08-10T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "Cisco has identified an issue where some Cisco ASA 5505 units fail to power on after a powercycle or during normal operations. When the failure occurs, the units become unresponsive and are unable to recover from the failure. A majority of Cisco ASA 5505 units do not exhibit this problem. The ones that do exhibit this problem have been seen to do so from within the first 30 days of installation.",
            "background": "A higher than normal failure rate was observed on a single component from one supplier. Cisco stopped using the component from this supplier as soon as the problem was identified. This component is sourced from multiple suppliers and therefore majority of Cisco ASA 5505 units are not affected by this problem.",
            "problemSymptoms": "When this problem occurs, there is no console connection, LED or any other electronic activity. The unit becomes completely unresponsive.",
            "workaround": "Cisco recommends a fix-on-fail strategy for this problem. \r\n\r\nAs of approximately June 01, 2007 new products that were manufactured under Engineering Change Order (ECO) E088917 are guaranteed to be free of this problem. Refer to \"How to Identify Hardware Levels\" below for instructions on how to view the version of in-service product.\r\n\r\nCustomers should first verify if your ASA5505(s) are affected by this problem. The Serial Number Validation Tool under \"How to Identify the Hardware Levels\" section of this field notice can be used to verify if your ASA 5505(s) are affected. \r\n\r\nIf your Cisco ASA5505(s) are affected, Service Logistics has known-good inventory at this time. The standard RMA process and delivery times are in effect.\r\n\r\nUse the linked Serial Number Validation Tool to verify if your ASA 5505(s) are affected. \r\n\r\nNote: Products that fall outside the affected serial number range are NOT affected.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/620/fn62832.html"
        },
        {
            "fieldNoticeId": 62840,
            "status": "P",
            "bulletinLastUpdated": "2008-02-04T16:35:22Z",
            "bulletinTitle": "FN# 62840 X2-10GB-LX4 may go into disable mode due to a design issue ",
            "bulletinFirstPublished": "2007-07-05T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "Certain X2-10GB-LX4 may occasionally go into a disable state randomly causing the link to go down.",
            "background": "Cisco has discovered that the above X2-10GB-LX4 from a particular vendor have a potential to go into a disable mode. This could result in the link going down.",
            "problemSymptoms": "One of the following symptoms may be seen on affected units:\r\n1.) The link does not come up at all \r\n2.) It takes a long time (5-15 minutes) for the link to come up \r\n3.) Link comes up but then goes down after some time",
            "workaround": "<u>Solution</u>\r\nCustomer can use the normal RMA process to order a replacement part. \r\nCISCO TAC: When using the standard RMA process to replace these units please use the code ARFN (Administrative Request Field Notice). \r\n\r\n<IMG SRC=\"http://www-tac.cisco.com/Support_Library/field_alerts/fn62840_jvjdif.bmp\"><br><br><br>",
            "hardwareLevels": "",
            "upgradeProgram": "",
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/misc/FN62840.html"
        },
        {
            "fieldNoticeId": 62851,
            "status": "P",
            "bulletinLastUpdated": "2007-07-27T15:07:49Z",
            "bulletinTitle": "FN #62851, 15454E-CC-FTA, The Fan Tray Was Shipped With Incorrect EEPROM Information",
            "bulletinFirstPublished": "2007-07-31T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "A limited number of ETSI Fan Tray have been Shipped With Incorrect EEPROM Information.",
            "background": "Manufacturing incorrectly programmed the EEPROM information at the factory.\r\nThe incorrect information programmed into the EEPROM was the equipment ID. \r\n\r\nPlease double check that all other information is correct, in particular the 800- code, PID, VID and \"FAN=4;\" in the extra info section of the EEPROM are consistent with the PCAMAP.",
            "problemSymptoms": "The MEA alarm is raised on the FAN TRAY on the 15454E equipment.\r\n\r\nThe MEA Alarm in this case was due to the incorrect EQUIPMENT ID being programmed. \r\n\r\nOther alarms might arise if other parameters, or the extra info in the EEPROM are incorrect. \r\n\r\nNOTE: The Fan Fail alarm and FTA red led stay on when only one Battery is connected.",
            "workaround": "The EEPROM can be reprogrammed in the field, but you may want to RMA the FTA as the unit was not really designed to be field upgradeable.\r\nIf you decide to do the upgrade in the field the information is listed below.\r\n\r\nEEPROM UPDATE\r\n\r\nFor best results, please check that both Batteries are connected to the shelf (BAT A and BAT B).\r\n\r\nPlease proceed as per the following steps:\r\n1. Connect the PC to the same Network domain as the shelf control Card (TCC).\r\n2. Telnet the TCC connected to the FTA-CC to be updated\r\n- type:\r\n   ¿aipModifyEeprom 5¿\r\n- Insert Equipment ID ¿0x1101¿ for ETSI 48V, ¿0x1102¿ for ETSI 60V, ¿0x1103¿ for ANSI\r\n- Type \"Enter\" key\r\n- Type again the \"Enter\" key in order to skip the update of the remaining EEPROM fields\r\n- Wait a few seconds after typing \"Enter\" key of the last field.\r\n \r\n- Type \"aipDisplayEeprom 5\" in order to check the equipment ID field has been updated\r\n\r\nShould any write failure occur, please repeat the procedure.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/620/fn62851.html"
        },
        {
            "fieldNoticeId": 62892,
            "status": "P",
            "bulletinLastUpdated": "2007-09-17T08:54:05Z",
            "bulletinTitle": "FN # 62892, ONS-XC-10G-S1= , Wrong ECI Bar Code on Excelight XFP",
            "bulletinFirstPublished": "2007-09-17T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "Several batches of parts were shipped with the early assigned Cisco ¿dummy¿ ECI barcode instead of the released assigned barcode.\r\nThe early barcode is a place holder that starts with the numbers \"123456\". This barcode may, or may not be human readable, but it does not have the correct barcode information on the XFP.",
            "background": "It was found that the ECI Bar Code may not be human readable by the end customers.\r\nThis is an optional code requirement from Telcordia, and may, or may not be used for tracking purposes.",
            "problemSymptoms": "If a customer is trying to record the BAR code information, the code will not be the correct one, and the customer will see a dummy value (12345.",
            "workaround": "There is no workaround for this defect.\r\nIf the customer is concerned by the issue, they may return the XFP for a new one.\r\n\r\nAll XFP's will be RMA'ed and sent out directly through Manufacturing.\r\nThe RMA's may take 2 weeks or more for full processing.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/620/fn62892.html"
        },
        {
            "fieldNoticeId": 62977,
            "status": "P",
            "bulletinLastUpdated": "2019-01-25T00:00:00Z",
            "bulletinTitle": "FN62977 - ESR and uBR10k - PRE2 - Defective Ethernet Transceiver on limited build of boards - Replace on Failure",
            "bulletinFirstPublished": "2007-12-12T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "",
            "background": "",
            "problemSymptoms": "",
            "workaround": "",
            "hardwareLevels": "",
            "upgradeProgram": "",
            "caveat": null,
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/629/fn62977.html"
        },
        {
            "fieldNoticeId": 63128,
            "status": "P",
            "bulletinLastUpdated": "2009-05-11T14:14:22Z",
            "bulletinTitle": "FN - 63128 - X2-10GB-SR - Laser of X2-10GB-SR may remain off after reload on ME-4924-10GE, WS-C4928-10GE and WS-C4948-10GE - Replace X2-10GB-SR",
            "bulletinFirstPublished": "2008-06-12T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "On ME-4924-10GE, WS-C4928-10GE and WS-C4948-10GE switches, the laser transmitter of a subset of X2-10GB-SR modules may remain off after a software crash or when the reload command is invoked. This is due to a firmware bug in the X2 modules and this problem is exposed only on three switches, ME-4924-10GE, WS-C4928-10GE and WS-C4948-10GE. <b><u> This problem does not occur on any other platforms or switches.</u></b>",
            "background": "The affected X2 modules are from one particular vendor. The root cause of the problem is a minor firmware bug in the affected X2 modules that activates the module's laser eye safety mechanism. This safety mechanism shuts off the transmitter laser if the module's reset pin is held high for more than 5 seconds. ME-4924-10GE, WS-C4928-10GE and WS-C4948-10GE hold the X2 modules in reset more than 5 seconds when a reload command is invoked or after the switch recovers from a software crash. This problem does not occur when the aforementioned switches are power-cycled.",
            "problemSymptoms": "After a software crash or when the reload command is invoked on the identified switches, the transmitter of the affected X2 modules remains off and does not turn back on causing the link to stay down. Issuing \"shutdown\" and \"no shutdown\" on the port will not bring the link back up. The link will not come up without manual intervention described in the workaround section.  \r\n\r\nAfter the switch comes back online, messages similar to the following will be displayed on the console: \r\n\r\n*May  5 09:06:15.267 UTC: %LINEPROTO-5-UPDOWN: Line protocol on Interface TenGigabitEthernet1/49, changed state to down\r\n*May  5 09:06:15.267 UTC: %LINEPROTO-5-UPDOWN: Line protocol on Interface TenGigabitEthernet1/50, changed state to down",
            "workaround": "Workaround : The affected X2 modules will recover after the module is removed and re-inserted or when the switch is power cycled.  \r\n\r\nSolution\r\nThe permanent solution for this problem is to replace the affected X2 modules used on ME-4924-10GE, WS-C4928-10GE  and WS-C4948-10GE switches.    \r\n\r\n\r\nAlthough an upgrade program had previously been provided to replace potentially affected but otherwise working product, the upgrade program is now over and Cisco will only replace product which has actually failed. The standard RMA process should be used to replace failed product.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/631/fn63128.html"
        },
        {
            "fieldNoticeId": 63132,
            "status": "P",
            "bulletinLastUpdated": "2019-01-22T00:00:00Z",
            "bulletinTitle": "FN63132 - MDS9000 - Potential DIMM Memory issue in small number of DS-X9530-SF2-K9 supervisor cards manufactured between September 2007 and February 2008. - Replace on Failure",
            "bulletinFirstPublished": "2008-07-10T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "Cisco has been made aware of a limited number of Supervisor-2 modules (DS-X9530-SF2-K9), manufactured between September 2007 to February 2008, that may intermittently experience a Device-4 error caused by an ECC Memory error  (Error Correcting Code).  This error will cause the Supervisor module to randomly switchover.\r\n\r\nSome Supervisor-2 modules (DS-X9530-SF2-K9) with Serial Numbers within the range <B> JAE1136xxxx </B>to <B> JAE1209xxxx </B>may be affected.",
            "background": "Cisco has determined the root cause to be infrequent DIMM errors caused by the printed circuit board design of a particular DIMM vendor. The printed circuit board design from this particular DIMM vendor may introduce a marginal memory timing condition whereby an infrequent read timing violation would occur under certain DIMM activity conditions. This violation would result in an ECC memory error (a Device 4 Error). Based upon this determination, the risk profile to customers who have Supervisor 2 modules with affected DIMMs, and in the interest of preventing further failures, Cisco is recommending that affected DIMMs are replaced.\r\n\r\nCisco builds with multiple DIMM vendors; only one of these secondary vendors has this condition accounting for a small percentage of affected Supervisor 2 modules manufactured between September 2007 to February 2008.",
            "problemSymptoms": "On Supervisor 2 modules with the affected DIMM, the Supervisor may randomly fail due to a Device 4 Error.\r\n\r\nIf the following message is displayed when you issue the <B>\"show system reset-reason\"</B> CLI command, the Supervisor 2 module will need the DIMM to be replaced by contacting the Cisco TAC and requesting a replacement DIMM per this Field Notice.\r\n<FONT SIZE=-1 FACE=\"courier\"> \r\nswitch# show system reset-reason\r\n----- reset reason for Supervisor-module 5 (from supervisor in slot 5)---\r\n\r\n1) No time\r\n   Reason: Unknown\r\n   Service:\r\n   Version: 3.2(2c)\r\n\r\n2) At 69022 usecs after Fri Jun 6 12:57:39 2008\r\n   Reason: Supervisor Device Error\r\n   Service: SUP Device-4 err\r\n   Version: 3.2(2c)\r\n</FONT>",
            "workaround": "Cisco recommends the replacement of all affected DIMMs in the field. To do this, Cisco will provide the m9500-sup2dimm-gplug-mz.3.4.1.bin utility to electronically verify the affected DIMM on Supervisor 2 modules.To replace the DIMMs, do the following:A. Identify affected DIMMB. Request replacement for affected DIMMC. Replace the original DIMMFollow the detailed steps in the following sections to complete these procedures.A - Identify Affected DIMMAffected DIMMs can be identified by the following methods:Identifying Affected DIMMs Using Fabric Manager Release 3.4(1z)Running the m9500-sup2dimm-gplug-mz.3.4.1.bin UtilityInspecting the DIMMsIdentifying Affected DIMMs Using Fabric Manager Release 3.4(1z)Fabric Manager Release 3.4(1z) is a special release distributed only to identify affected DIMMs in Supervisor 2 modules across your fabric. The utility discovers affected DIMMs in all Supervisor 2 modules in your fabric and generates a report indicating all affected DIMMs.Note - Users installing Fabric Manager must have full administrator privileges to create user accounts and start services. Users should also have access to all ports. These are the ports used by Fabric Manager Server and the PostgreSQL database: 1098, 1099, 4444, 4445, 8009, 8083, 8090, 8092, 8093, 514, 5432.Fabric Manager Release 3.4(1z) is included in the m9500-sup2dimm-gplug-mz.3.4.1.bin.zip file. To obtain Release 3.4(1z), go to the following URL:  http://www.cisco.com/cgi-bin/tablebuild.pl/mds-utilitiesA CCO account is required to download the file. Click on m9500-sup2dimm-gplug-mz.3.4.1.bin.zip to download the zip file to your computer and unzip the file. The DIMM Utility folder is created. The folder contains 3 items: the MDS9000-FM-CD-3.>m9500-sup2dimm-gplug-mz.3.4.1.bin standalone utility, and the DIMMutility.pdf.Installation Pre-RequisitesBrowser RequirementInstallation requires Windows Internet Explorer 6.x and 7.0. Internet Explorer 7.0 is not supported on Windows 2000 SP4.Java RequirementWhen you connect to the server for the first time, Fabric Manager checks to see if you have the correct Sun Java Virtual Machine version installed on your workstation. Fabric Manager looks for version 1.5(x) during installation. If required, install the Sun Java Virtual Machine software.Note - You can run CiscoWorks on the same PC as Fabric Manager, even though the Java requirements are different. When installing the later Java version for Fabric Manager, make sure it does not overwrite the earlier Java version required for CiscoWorks. Both versions of Java can coexist on your PC.PostgreSQL RequirementOn Windows, remote Fabric Manager Installations or upgrades should be done through the console using VNC or through the Remote Desktop Client (RDC) in console mode (ensuring RDC is used with the /Console option). This is vitally important if the default PostgreSQL is used with Fabric Manager, as this database requires the local console for all installations and upgrades.Installing Fabric Manger Release 3.4(1z)You can create an installation CD or you can run the installation from the MDS9000-FM-CD-3.4.1z folder.To run the installation on Windows from the MDS9000-FM-CD-3.4.1z folder, do the following:Step 1 - Double-click install_windows.htm.Step 2 - Click the Install Management Software link.Step 3 - Choose Management Software > Cisco Fabric Manager in the left navigation pane. You may need to allow blocked content in order to install Fabric Manager.Step 4 - Click the Installing Fab>Step 5 - Click the FM Installer link. Click OK. It may take a couple of minutes for the Fabric Manager installation window to open.You see the welcome to the management software setup wizard message in the Cisco Fabric Manager Installer window shown in Figure 1-1. Step 6 - Click Next to begin the installation.Step 7 - Check the I accept the terms of the License Agreement check box and click Next.You see the Install Options dialog box shown in Figure 1-2. Step 8 - Click the radio button for either:a. Fabric Manager Server (Licensed) to install the server components for Fabric Manager Server.b. Fabric Manager Standalone to install the standalone version of Fabric Manager. (Recommended installation)Note - You should verify that the Fabric Manager Server hostname entry exists on the DNS server, unless the Fabric Manager Server is configured to bind to a specific interface during installation.Note - Fabric Manager Standalone is a single application containing Fabric Manager Client and a local version of Fabric Manager Server bundled together. Fabric Manager Standalone allows you to discover and monitor the immediate fabric.Step 9 - (For Fabric Manager server installation) Select an installation folder on your workstation for Fabric Manager. On Windows, the default location is C:\\Program Files\\Cisco Systems\\MDS 9000. On a UNIX (Solaris or Linux) machine, the installation path name is /usr/local/cisco_mds9000 or>$HOME/cisco_mds9000, depending on the permissions of the user doing the installation.Step 10 - Click Next. You see the Database Options dialog box shown in Figure 1-3. Step 11 - Click the radio button for either Install PostgreSQL or Use existing DB to specify which database you want to use.If you choose Install PostgreSQL, accept the defaults and enter a password. The PostgreSQL database will be installed.Note - If you choose to install PostgreSQL, you must disable any security software you are running, as PostgreSQL may not install certain folders or users. Note - Before you install PostgreSQL, remove the cygwin/bin from your environment variable path if Cygwin is running on your system.Step 12 - If you select Use existing DB, click the radio button for either PostgreSQL 8.1/8.2 or Oracle10g.Step 13 - Click Next in the Database Options dialog box.You see the User Options dialog box shown in Figure 1-4. Step 14 - Enter a user name and password and click Next.You see the Authentication Options dialog box shown in Figure 1-5. Step 15 - Choose an authentication mode (Local, RADIUS, TACACS or MDS) and click Next.Note - When the MDS radio button is selected, the FM authentication uses the user database in the switch for authentication.Step 16 - Click Verify to test your login if you choose RADIUS or TACACS.You see the Configuration Options dialog box for Fabric Manager Standalone shown in > Step 17 - Check the FC Alias and SNMPv3 check boxes as desired and click Install if you are installing Fabric Manager Standalone.You see the Configuration Options dialog box for Fabric Manager Server shown in Figure 1-7.  Step 18 - Select the local interface, web server port or fm server port and check the FC Alias and SNMPv3 check boxes as desired and click Install if you are installing Fabric Manager Server.Note - You can change the FM Server Port number, to a port that is not used by any other application.Note - You should verify that the Fabric Manager Server hostname entry exists on the DNS server, unless the Fabric Manager Server is configured to bind to a specific interface during installation.Note - If you check the Use HTTPS Web Server check box, the Web Server Port field is grayed out and the default port is 443.Note - If you select a specific IP address during installation and change the server host IP address, you must modify the following two files which are all located in the $INSTALL/conf directory. Change server.bindaddrs to the new IP address in the server.properties file and change wrapper.app.parameter.4 to the new IP address in the FMServer.conf file.Step 19 - You see the installation progress in the Cisco Fabric Manager Installer window.Once the installation is finished, you see an installation completed message in the Cisco Fabric Manager Installer window shown in Figure 1-8.Note - If you installed Fabric Manager Standalone, you can choose to launch Fabric Manager or Device Manager by checking the Launch Fabric Manager or Launch Device Manager check boxes.Step 20 - Create a desktop shortcut & Launch Fabric Manager now.Step 21 - Enter the Fabric Manager Server Username and Fabric Manager server password that you assigned. Click LoginStep 22 - Enter the seed switch IP address, username, and password. Insure that SNMPv3 is checked and select the appropriate Auth-Privacy authentication shown in Figure 1-9. Step 23 - Click Discover. A verification of the discovered fabric is displayed. Click OK. The Control Panel window is displayed shown in Figure 1-10. Step 24 - Select the device and click Open. The Fabric Manager window displays the fabric.Step 25 - Select Tools > DIMM Report.... to run the DIMM utility report shown in Figure 1-11. The DIMM Check Report window is displayed shown in Figure 1-12. Step 26 - Select the Cisco MDS switches in your fabric.Step 27 - Enter the directory where the report will be saved. Click Run shown in Figure 1-13.Step 28 - Click Close shown in Figure 1-14. Running the m9500-sup2dimm-gplug-mz.3.4.1.bin UtilityThe m9500-sup2dimm-gplug-mz.3.4.1.bin utility will run on SAN-OS Release 3.x running on Supervisor 2 modules. Pictures of the affected DIMM are in the \"How to Visually Inspect DIMMs\" section of this Field Notice. The visual inspection method is recommended for Supervisors that are offline.To download and run the m9500-sup2dimm-gplug-mz.3.4.1.bin utility using the CLI, do the following:  Step 1 -  Go to the following URL  MDS Utilities  (http://www.cisco.com/cgi-bin/tablebuild.pl/mds-utilities) Click  m9500-sup2dimm-gplug-mz.3.4.1.bin.zip  to download the utility to your computer.Step 2 - Unzip the file and save to your local computer.Step 3 - Copy the utility to a tftp server.  Step 4 - Copy the utility from the tftp server to the Cisco MDS 9000 Family switch.An example of the CLI command used to copy the utility from the tftp server to the active Supervisor 2 module is:switch#copy tftp://192.68.55.22/m9500-sup2dimm-gplug-mz.3.4.1.binbootflash:m9500-sup2dimm-gplug-mz.3.4.1.binTrying to connect to tftp server......TFTP get operation was successfulswitch#Step 5 - Copy the m9500-sup2dimm-gplug-mz.3.4.1.bin utility to the standby Supervisor 2 module.switch#copy bootflash:m9500-sup2dimm-gplug-mz.3.4.1.binbootflash://sup-standby/m9500-sup2dimm-gplug-mz.3.4.1.binStep 6 - Run the utility on the active Supervisor 2 module by issuing the following commands. The utility will be removed from the active Supervisor 2 module d>Be sure to type the command correctly. You can not use the Tab key to auto-expand the command.switch#load bootflash:m9500-sup2dimm-gplug-mz.3.4.1.binLoading plugin version 3.4(1)###############################################################Warning: debug-plugin is for engineering internal use only!For security reason, plugin image has been deleted.###############################################################Name: switch, Serial Number : JAE11528POD, DEVICE-4 : FAIL DIMMO INFOJedec-ID : 0x7fJedec-ID(cont): 0xa8Part Number : CIS00-21077-325MFDIMM1 INFOJedec-ID : 0x7fJedec-ID(cont): 0xa8Part Number : CIS00-21077-325MFThe utility output will indicate a \"PASS\" or \"FAIL\" status for the DIMM on the Supervisor 2 module. If you see a FAIL status, follow the procedure to order the DIMM replacement using the form at the end of this document.Step 7 - Run the utility on the standby Supervisor by issuing the following commands. Use the  \"show module\"  command first to identify the standby Supervisor moduleswitch# show module Mod Ports Module-Type Model Status--- ----- -------------------------------- ------------------------------1 32 1/2 Gbps FC Module DS-X9032 ok2 16 1/2 Gbps FC Module DS-X9016 ok4 8 IP Storage Services Module DS-X9308-SMIP ok5 0 Supervisor/Fabric-2 DS-X9530-SF2-K9 active *6 0 Supervisor/Fabric-2 DS-X9530-SF2-K9 ha-standby9 8 IP Storage Services Module DS-X9308-SMIP okMod Sw Hw World-Wide-Name(s) (WWN)--- -------------- ------ --------------------------------------------------1 3.2(2c) 1.0 20:01:00:05:30:00:63:9e to 20:20:00:05:30:00:63:9e2 3.2(2c) 1.0 20:41:00:05:30:00:63:9e to 20:50:00:05:30:00:63:9e4 3.2(2c) 2.0 --5 3.2(2c) 1.6 -- 6 3.2(2c) 1.4 -- 9 3.2(2c) 5.1 -- Mod MAC-Address(es) Serial-Num --- -------------------------->Step 8 - Attach to the standby Supervisor module.switch#attach module 6 http://www.cisco.com/tac  Copyright (c) 2002-2007, Cisco Systems, Inc. All rights reserved.The copyrights to certain works contained herein are owned by other third parties and are used and distributed under license.Some parts of this software may be covered under the GNU Public License or the GNU Lesser General Public License. A copy of each such license is available at http://www.gnu.org/licenses/gpl.html and http://www.gnu.org/licenses/lgpl.htmlStep 9 - Run the utility on the standby Supervisor module. The utility will be removed from the Supervisor module during the process of running the load command.Be sure to type the command correctly. You can not use the Tab key to auto-expand the command.switch(standby)#load bootflash:m9500-sup2dimm-gplug-mz.3.4.1.bin Loading plugin version 3.4(1)###############################################################Warning: debug-plugin is for engineering internal use only!For security reason, plugin image has been deleted.###############################################################Name: fcb11c04, Serial Number : JAE120782Z8, DEVICE-4 : PASS DIMMO INFOJedec-ID : 0x7fJedec-ID(cont): 0x94Part Number : SG5726485D8D0CLSD2DIMM1 INFOJedec-ID : 0x7fJedec-ID(cont): 0x94Part Number : SG5726485D8D0CLSD2Output Showing Affected and Unaffected Supervisor 2 ModulesThis section shows the output of affected and unaffected Supervisor 2 modules.Affected Supervisor 2 ModuleThe following is an example showing an affected module. This module needs to be replaced.switch# load bootflash:m9500-sup2dimm-gplug-mz.3.4.1.binLoading plugin version 3.4(1)###############################################################Warning: debug-plugin is for engineering internal use only!For security reason, plugin image has been deleted.###############################################################Name: switch, Serial Number : JAE11528POD, DEVICE-4 : FAIL DIMMO INFOJedec-ID : 0x7fJedec-ID(cont): 0xa8Part Number : CIS00-21077-325MFDIMM1 INFOJedec-ID : 0x7fJedec-ID(cont): 0xa8Part Number : CIS00-21077-325MFUnaffected Supervisor 2 ModuleThe following is an example showing an unaffected DIMM. This DIMM does not need to be replaced.switch(standby)# load bootflash:m9500-sup2dimm-gplug-mz.3.4.1.binLoading plugin version 3.4(1)###############################################################Warning: debug-plugin is for engineering internal use only!For security reason, plugin image has been deleted.###############################################################Name: fcb11c04, Serial Number : JAE120782Z8, DEVICE-4 : PASSDIMMO INFOJedec-ID : 0x7fJedec-ID(cont): 0x94Part Number : SG5726485D8D0CLSD2DIMM1 INFOJedec-ID : 0x7fJedec-ID(cont): 0x94Part Number : SG5726485D8D0CLSD2How to Visually Inspect the DIMMsHow to Identify Affected DIMMsThe images below show examples of the two different DIMM labels used by the vendor. These two labels identify the affected DIMMs that need to be replaced.Figure 1 shows the first of two watermarks on the affected DIMMs.Figure 2 shows the second watermark of the affected DIMMs.Figure 3 shows the close-up of the watermark label identifying affected DIMMs.Figure 1 - Affected DIMMs and 1st Watermark typeFigure 2 - Affected DIMMs and 2nd Watermark typeFigure 3 - DIMMs Close-up Image of Figure 2 Showing the Watermark Beneath the Serial NumberB. Request Replacement DIMMsIf you are a Reseller supported customer, contact your Reseller to obtain DIMM replacements (Product ID: DS-DIMM1=). If you are not a Reseller supported customer, please contact the Cisco TAC and reference this FN to order your replacement DIMMs.Each replacement DIMM order contains 2 DIMMS (which is sufficient for 1 Supervisor). Please place your replacement order based on the quantity of the Supervisors affected.Note - Please use the SN of the Supervisor when requesting replacement DIMMs.C. Replacing DIMMsAfter receiving the replacement DIMMs, follow the instructions in this section to remove the Supervisor 2 module from the chassis and replace the DIMMs. Ensure the module you are removing is the Standby Supervisor. If both Supervisors are affected, please replace the DIMM on the Standby first. If the active Supervisor is affected, please follow the instruction below.How to place your active supervisor in Standby modeIdentify the Supervisor-2 module that needs the DIMM's replaced and ensure it is the standby supervisor via the show module command. If the supervisor is the active supervisor you will need to perform the system switchover command to make the current active Supervisor come up in Standby mode. Make sure the Standby Supervisor is in \"ha-standby\" by repeating the show module command before starting the replacement steps.Example of systems switchover command shown below:switch# system switchover Note - Prior to replacing DIMM's in Cisco MDS 9509 and 9506 Directors, shut down the crossbar switching fabric functionality in the Supervisor module by using the ?out-of-service module slot? command (where slot refers to the slot number for the Standby Supervisor-2 module where the integrated crossbar is located).Example of out-of-service module slot command shown below:switch# out-of-service module xwhere x = the standby supervisor slotCaution - When handling switch components, wear an ESD strap and handle modules by the carrier edges only. An ESD socket is provided on the chassis. For the ESD socket to be effective, the chassis must be grounded either through the power cable, the chassis ground, or metal-to-metal contact with a grounded rack.Click  here for demonstration video of the steps listed below.Step 1 - Make sure the Supervisor is in standby modeStep 2 - Attach a grounding strapStep 3 - Disconnect any network interface cables (for example, the Console cable and the Ethernet cable) attached to the module.Step 4 - Loosen the two captive screws on the left and right side of the module.Step 5 - Remove the standby supervisor from the chassis as follows:5a. Place your thumbs on the left and right ejector levers and simultaneously rotate the levers outward to unseat the module from the backplane connector.5b. Grasp the front edge of the module and slide the module partially out of the slot. Place one hand under the module to support the weight of the module. Do not touch the module circuitry.Step 6 - Place the module on an antistatic mat or antistatic foam.Step 7 - Attach a grounding strap to the module.Step 8 - Identify the DIMM on the module. The position of the DIMM is in the front-right side of the module.Step 9 - Remove the DIMM by pressing the left and right side levers outward. Always replace both DIMMs on the Supervisor.Step 10 - Install the new DIMM and then press inward until the left and right side levers snap into place.Step 11 - Insert the Supervisor 2 module back into the chassis.Step 12 - Press the left and right-side ejector levers inward.Step 13 - Tighten the two captive screws on the left and right side of the module.Step 14 - Reconnect any interface cables that were disconnected in Step 2.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": "Only some of the boards in the serial number range are affected.  No automated matching of the DIMMs has been done.  Only matching against the supervisor module PID and the serial number.  Follow the procedures in the Field Notice to identify which of these supervisors have affected DIMMs.",
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/631/fn63132.html"
        },
        {
            "fieldNoticeId": 63153,
            "status": "P",
            "bulletinLastUpdated": "2008-10-30T13:45:26Z",
            "bulletinTitle": "FN 63153 : Cisco 38XX Router may fail to boot due to change in ROMmon erase time",
            "bulletinFirstPublished": "2008-08-19T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "The bootflash in specific Cisco routers may exhibit a defect, resulting in a timing error, which could cause a boot failure from ROMmon. Cisco is providing a ROM Monitor (ROMmon) update that resolves this scenario.\r\n\r\nExpected failure rate at room temperature is 1.4%.",
            "background": "A new bootflash device for the C3800 ROMmon was introduced resulting in timing error causing ROMmon boot failures. The new ROMmon has an increased erase time. New ROMmon code was developed to work with this increased erase time.",
            "problemSymptoms": "Cisco 3800 fails to boot up and the following error is seen on the console log:\r\n\r\nSystem Bootstrap, Version 12.4(13r)T, RELEASE SOFTWARE(fc1)\r\nTechnical Support: http://www.cisco.com/techsupport\r\nCopyright (c) 2006 by cisco Systems, Inc.\r\n\r\nRommon primary and backup variables are invalid...\r\n\r\nWarning: monitor nvram area is corrupt ... using default values\r\n\r\namd_flash_cmd: timeout on erase sector command\r\nenvironment checksum failed\r\n\r\namd_flash_cmd: timeout on erase sector command\r\nenvironment checksum failed",
            "workaround": "New ROMmon code has been released that is compatible to the longer erase time introduced. It can be down loaded from Cisco.com/Support/Download Software by customers with access to Software Downloads.\r\n\r\nScroll down to the <a href=\"http://tools.cisco.com/support/downloads/go/PlatformList.x?sftType=IOS%20ROMMON%20Software&mdfid=280673497&treeName=Routers&mdfLevel=Model&url=null&modelName=Cisco%203800%20Series%20Routers&isPlatform=N&treeMdfId=268437899\">Cisco ROMMON Upgrade</a> heading, follow the \"3800 Platform\" link and select 12.4(13r)T10.\r\n \r\nThe actual URL is as follows:\r\nhttp://tools.cisco.com/support/downloads/go/PlatformList.x?sftType=IOS%20ROMMON%20Software&mdfid=280673497&treeName=Routers&mdfLevel=Model&url=null&modelName=Cisco%203800%20Series%20Routers&isPlatform=N&treeMdfId=268437899\r\n \r\n========= ROMmon Upgrade Procedure =========\r\n\r\n1. Locate the new rommon: /tftpboot/images/STI/release_1\r\n \r\n2. Configure router to connect to TFTP server, make sure TFTP server can be pinged.\r\n \r\n3. Collect the rommon info before the upgrade by using <b>show rom-monitor</B> under IOS\r\n \r\n4. Upgrade secondary rommon with <b>upgrade rom-monitor file tftp://...</B> command under IOS\r\n \r\n5. After the upgrade, the router will be reloaded automatically. If the config register is 0x0, then the route will go to the rommon prompt. Otherwise, the router will boot up IOS, and go to the router prompt.\r\n \r\n6. After the upgrade, the new rommon in secondary rommon will be automatically set to current rommon. You can verify the upgrade result by\r\n    using <b>showmon</B> under rommon prompt\r\n    or using <b>show rom-monitor</B> under IOS\r\n \r\n7. If the new rommon failed to work, then you need to use the readonly rommon. You can specify readonly as current rommon by \r\n    using <b>rommon-pref readonly</B> under rommon prompt\r\n    or using <b>upgrade rom-monitor preference readonly</B> under IOS\r\n \r\n8.  You also can backup secondary rommon to prior version you collected in step 3 by following the same procedure in 2-4 with the prior version rommon. (You need to copy the prior version rommon to a tftp directory) \r\n\r\nAs of approximately Jul. 29, 2008 new products that were manufactured under deviation D097818 are guaranteed to be free of this problem.",
            "hardwareLevels": "",
            "upgradeProgram": "",
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/631/fn63153.html"
        },
        {
            "fieldNoticeId": 63245,
            "status": "P",
            "bulletinLastUpdated": "2019-03-04T00:00:00Z",
            "bulletinTitle": "FN63245 - WS-CBS3110G-S,WS-CBS3110G-S-I,WS-CBS3120G-S,WS-CBS3120X-S,WS-CBS3125X-S,WS-CBS3130G-S,WS-CBS3130G-S-F,WS-CBS3130X-S,WS-CBS3130X-S-F Stacking Connector Might Experience Premature Failure Upon Insertion - Replace on Failure",
            "bulletinFirstPublished": "2009-09-16T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "A defect has been identified on the stacking connector. The cable connector on the blade products listed in the \"Products Affected\" section might break after a few insertions.",
            "background": "During the manufacturing process, the connector leads of the stacking connectors used on the affected blade products were improperly stressed, creating the potential for breakage with each re-connection to the stack connector.If the stacking feature of the product is not used, the problem will never be encountered.",
            "problemSymptoms": "This problem only affects the stacking connector. Potential problems range from no problems to intermittent problems to complete failure of the stacking feature.",
            "workaround": "Replace the affected hardware only if the serial number is identified as affected and the Version ID is V01.If you have Version ID V02 or greater, then the product is not affected.Refer to the \"How to Identify Affected Products\" section below for instructions on how to find the version of an in-service product.To replace an affected product, please contact the Cisco Technical Assistance Center (TAC) and reference this Field Notice.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/632/fn63245.html"
        },
        {
            "fieldNoticeId": 63251,
            "status": "P",
            "bulletinLastUpdated": "2019-03-04T00:00:00Z",
            "bulletinTitle": "FN63251 - Cisco Catalyst 3560V2 and 3750V2 Series Switches Have Redundant Power Supply Covers of Incorrect Size - Replace on Failure",
            "bulletinFirstPublished": "2010-12-17T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "The Redundant Power Supply (RPS) cover that is included in the accessory kit for the affected Cisco Catalyst 3560V2 and 3750V2 Series switches is the incorrect size. For customers who choose to mount the affected switches vertically, this might be a safety issue, as the RPS cover does not fit properly over the RPS connector. Without the proper RPS cover present over the RPS connector, it is possible for material to escape from within the switch.",
            "background": "All Cisco Catalyst 3560V2 and 3750V2 Series switches (except the DC Version) that shipped before June 5, 2009, are affected (includes all serial numbers LLL1323NNNN and earlier).",
            "problemSymptoms": "For the affected Cisco Catalyst 3560V2 and 3750V2 Series switches that are mounted vertically, the RPS cover does not fit properly over the RPS connector.",
            "workaround": "In order to determine whether a Cisco Catalyst 3560V2 or 3750V2 Series switch is affected, please use the Serial Number Validation (SNV) Tool.For affected products with serial numbers that are verified by the SNV Tool, please contact the Cisco Technical Assistance Center (TAC) and request a hardware replacement.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/632/fn63251.html"
        },
        {
            "fieldNoticeId": 63258,
            "status": "P",
            "bulletinLastUpdated": "2018-02-12T00:00:00Z",
            "bulletinTitle": "FN63258 - WLC 44xx Potential Power Failure - Replace on Failure",
            "bulletinFirstPublished": "2009-10-05T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "Cisco has observed that certain identified serial number of WLC 4400 series controllers may fail to boot on a subsequent power cycle.",
            "background": "Few 4400 series controllers that are built between November 2008 and March 2009 have experienced lower test during power cycles due to a bad part. Based on analysis performed by Cisco and the component supplier, we have found that only three percent of the total identified units are built during that period may fail over the life of the product if the product is power cycled frequently. The actual failure rate in the field in the last six months has been less than one percent.As of April 14th, new products that were manufactured under deviation D102201 or D102319 are free of this problem.Refer to \"How to Identify Affected Products\" below for instructions on how to view the deviation number of in-service product.",
            "problemSymptoms": "A small number of controllers that are identified by serial numbers may fail with symptom: \"No Power\".",
            "workaround": "1.If a unit with a redundant power supply fails, then the system will automatically revert to the backup. Unit will function properly without any problems.2.If a unit with a single power supply fails, then the power supply can be removed from that slot and replaced in the other slot. The unit should boot up and function properly.For instruction on changing power supply slot please refer to \"Quick Start Guide: Power Supplies for Cisco 4400 Series WLAN Controllers\" (Text Part Number: 78-17159-03).If a customer has a unit with an impacted serial number and they have not experienced a power supply failure, we recommend the customer continue to use the unit. Because the likelihood of a failure is low Cisco recommends a ?Fix on Failure? approach. (The UMPIRE Program for the affected units in place is complete, Please follow Standard Cisco RMA process if the user encounter this issue with a suspected unit)Use the linked Serial Validation Tool to verify if these products are affects:  * AIR-WLC4402-12-K9 * AIR-WLC4402-25-K9 * AIR-WLC4402-50-K9 * AIR-WLC4404-100-K9   Note: Products that fall within the affected serial number range are NOT affected by this problem if they have Deviation label D102201 or D102319 applied.",
            "hardwareLevels": "",
            "upgradeProgram": "",
            "caveat": null,
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/632/fn63258.html"
        },
        {
            "fieldNoticeId": 63313,
            "status": "P",
            "bulletinLastUpdated": "2018-06-11T00:00:00Z",
            "bulletinTitle": "FN63313 - 7600: Batch of WS-X6582-2PA Might Fail when Booting at a Low Temperature - Replace on Failure",
            "bulletinFirstPublished": "2010-09-03T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "A batch of WS-X6582-2PA cards in the 7600 platform may fail when booting under temperature below 15C. \r\n\r\nThe failure condition may manifest when the card is powered up (booted) for the first time. Cards in working mode are not expected to exhibit this failure.",
            "background": "Due to a delay in the early start up of the 1.2 voltage rails during the Power up sequence, a batch of WS-X6582-2PA cards in the 7600 platform have been shown to be prone to fail when booting under temperature below 15C. \r\n\r\nThe failure condition may manifest when the card is powered up (booted) for the first time. Cards in working mode are not expected to exhibit this failure.",
            "problemSymptoms": "WS-X6582-2PA cards on 7600 platform failed to boot up at low temperature. This problem happens only to new cards that have not been installed, or not in full operation. \r\n\r\nDetailed failure symptoms are: \r\n1)%OIR-SP-6-PWRFAILURE: Module 1 is being disabled due to power convertor failure 0x1 \r\n2)%C7600_PWR-SP-4-DISABLED: power to module in slot 1 set off (FRU-power failed) \r\n3)The card will not boot-up during the initial boot-up phase only. \r\n\r\nIf a card is in operation, this problem does not occur during any reboot cycle.",
            "workaround": "Cisco recommends replacing the affected WS-X6582-2PA cards identified as per table below. \r\n\r\n<TABLE BORDER='1' CELLPADDING='0' CELLSPACING='2'><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Card TAN or Part number</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Action</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Affected SN</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Card In Operation</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Potential failure</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Replace</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONTCOLOR='#000000'>73-9539-08_A0  and lower</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'><a href=\"http://serialnumbervalidation.com/63313\">Serial Number Checking Tool</a></FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Yes</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>No</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Yes</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Yes</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>73-9539-08_A0  and lower</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'><a href=\"http://serialnumbervalidation.com/63313\">Serial Number Checking Tool</a></FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Yes</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Yes</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>No</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Recommended</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>73-9539-09_A0  and higher</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>No Action required</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>No</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>NA</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>No</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>No</FONT></TD></TR></TABLE>",
            "hardwareLevels": "",
            "upgradeProgram": "",
            "caveat": null,
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/633/fn63313.html"
        },
        {
            "fieldNoticeId": 63315,
            "status": "P",
            "bulletinLastUpdated": "2019-01-31T00:00:00Z",
            "bulletinTitle": "FN63315 - CP-79XX IP Phones, Front Label May Fall off After a Given Period of Time - Replace on Failure",
            "bulletinFirstPublished": "2010-04-23T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "Cisco IP Phone front labels will peel off after a certain period of time.",
            "background": "Cisco has determined that one of our manufacturing suppliers may have a quality issue in the raw material for the labels on the Cisco IP Phone models listed above.",
            "problemSymptoms": "The label will peel off after a period of time. Customers may encounter this in as little as five days after placing the label on the Cisco IP Phone.",
            "workaround": "<B>Workaround</B>\r\nNone\r\n\r\n<B>Solution</B>\r\n\r\nCustomers who have IP Phones in the affected serial number range may order replacement labels at no cost.  To request the replacement labels, customers may call TAC and request replacement labels.\r\n\r\n<B>NOTE: Each label package (CP-7900-LABEL-50=) will contain 50 labels in total.</B>",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/633/fn63315.html"
        },
        {
            "fieldNoticeId": 63340,
            "status": "P",
            "bulletinLastUpdated": "2019-03-04T00:00:00Z",
            "bulletinTitle": "FN63340 - WS-C2960S-48FPS-L, WS-C2960S-48FPD-L Power Supply Defect - Replace on Failure",
            "bulletinFirstPublished": "2010-07-21T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "Root caused has been identified as defective linear regulator IC 803 impacting third party power supply vendor DC1021 and DC1022. The IC was purchased from open market not from a Semiconductor source and does not perform to  specification",
            "background": "The problem is related it single IC that randomly shuts down. The IC is a linear regulator for secondary side micro. When the IC shuts down, the micro loses control of power enable, sync FET gate enable, parallel/current share signal, protection function and orderly sequence of power train shut down. In the case of two units in the system, when one unit loses control of the power train, the two units will not have correct voltage matching (current share signal cannot operate correctly). The unit will lower voltage set point will sink current because output rectification uses sync FET. The sinking current or negative current will increas when FETs of both legs of transformers conduct together. When one set of FETS turn OFF, negative current in the inductor has no quick path to travel, energy in the inductor will cause avalanche of the FET. The avalanche energy significantly raises loss in sync FET leads to destruction of the FET as seen in the failed units. In case of the single unit, the unit will shut down, albeit not in orderly manner. Unit is not likely to be damaged in this case because there is no external source to provide energy to build up heat in the FET.",
            "problemSymptoms": "Power Supply Unit, have output reset (12 V toggle), A Green LED blinking. Then after Testing for a long time there will be no output voltage output and Red LED (fail) turns on.",
            "workaround": "Cisco is recommending to customers that are affected by this issue and can verify their Serial Number using the Serial Number Validation tool below, contact Cisco to replace the affected hardware.*NOTE*All RMA requests are to be sourced through Manafacturing not service.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/633/fn63340.html"
        },
        {
            "fieldNoticeId": 63361,
            "status": "P",
            "bulletinLastUpdated": "2018-02-12T00:00:00Z",
            "bulletinTitle": "FN63361 - 15454-OTU2-XP, 15454-10GE-XP and 15454-10GE-XPE: Possible mechanical interference issues with faceplates and certain heatpipes - Replace on Failure",
            "bulletinFirstPublished": "2010-11-30T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "Some 15454-OTU2-XP, 15454-10GE-XP and 15454-10GE-XPE cards assembled with faceplates and heatpipes by a certain vendor could have mechanical interference issues when plugging the last card into a fully equipped 15454, M2 or M6 chassis. The heatpipes assembled on some cards exceeds the maximum height and can interfere with adjacent cards.Improved heat-pipe assembly and new version faceplates are being released to provide a greater clearance during card insertion.",
            "background": "A Mechanical interference issue was highlighted at a customer with inserting the 15454-OTU2-XP line cards in the M6 chassis.This issue has been root caused to a specific vendor&#39;s heat-pipe assembled on some 15454-OTU2-XP, 15454-10GE-XP and 15454-10GE-XPE cards which exceeded the maximum height and can interfere with adjacent cards.Improved heat-pipe assembly and new version faceplates are being released to provide a greater clearance during card insertion",
            "problemSymptoms": "Mechanical interference issues may exists with certain 15454-OTU2-XP, 15454-10GE-XP and 15454-10GE-XPE line cards when plugging these unit into a fully equipped 15454, M2 or M6 chassis.",
            "workaround": "For affected units, there is no field workaround procedure identified. Improved heat-pipe assembly and new version faceplate are being released to provide a greater clearance during card insertion. For affected units in the field, Cisco recommends a fix-on-fail strategy for which units may be sent back for replacement using the normal RMA process.Specific units are identified by serial number. A serial number validation tool has been provided below to validate affected units. Units indentified as \"affected\" may be returned to Cisco for replacement/rework.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/633/fn63361.html"
        },
        {
            "fieldNoticeId": 63380,
            "status": "P",
            "bulletinLastUpdated": "2019-02-04T00:00:00Z",
            "bulletinTitle": "FN63380 - ASR9000 DC Power Module Replacement Recommended to Prevent Failure of PEM on Lightly Loaded Chassis - Replace on Failure",
            "bulletinFirstPublished": "2011-03-28T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "<ol>\r\n  <li>DC power module might fail during power-on in an Aggregation Services Router (ASR) 9000 chassis that operates under a low-load condition, or it might cause one or more adjacent power modules to fail if one component in the circuit fails. This issue can defeat the redundant power system in the ASR9000 chassis, and  result in a single point of failure. </li>\r\n  <li>Once a single DC power feed fails, the expected behavior is that the DC power module generates a power feed fail alarm and the power LED starts blinking in order to notify the user to take corrective action. The issue identified here is that the DC power module might take longer or it might not generate a power feed failure alarm or event (%PLATFORM-PWRMON-2-MODULE_FAILURE). Also, the power status LED might remain lit for a failed DC power feed. The power module continues to provide DC power to the router via the other working DC power feed and does not affect router functionality. </li>\r\n</ol>\r\n<strong>Note: </strong>The two symptoms described previously are not safety issues. \r\n    ASR9000 AC power modules are not affected.",
            "background": "<ol><li>Multiple power modules in a router convert battery power 48V DC to power line cards. Conversion is done by switching the DC power that passes through the Field Effect Transistor (FET) and controls the drive current to FET with a micro-controller at high speed or frequency.<br>\r\n      Incorrect FET drive settings in the power module firmware lead to current imbalance in low-load conditions. A <strong>low load</strong> condition is defined as any one power module sourcing (outputting) less than 10 ampere of current. This output can be determined if you monitor power module output with the use of a system CLI command. The condition is more likely to occur with frequent power cycles.<br>\r\n      In order to fix this issue, a new version (-02) of the DC power module has been implemented that includes:\r\n      <ol type=\"a\">\r\n        <li>A new version of the power module's internal firmware has been incorporated in order to correct the FET drive setting which led to a current imbalance in low-load condition. The power module firmware change is not field-upgradable. </li>\r\n        <li> Design enhancements have been made to the DC power module in order to improve long-term reliability by implementing changes that support the D-share model of load balancing.</p></li></ol></li>\r\n    <li>The ASR9000 router features two power input feeds (A and B) to each power module. In a few power breaker configurations, the input power feeds (either A or B) to multiple modules that are tied together at a common switch or breaker. If power is disrupted at the breaker to any one feed, the power failure detection and LED circuit do not discharge fast enough, which keeps the LED lit and prevents the power failure alarm.<br>\r\n      In order to fix this issue, a new version (-03) of the DC power module has been implemented that includes changes to the-02 version update to fix Issue 1 plus these changes:\r\n      <ol type=\"a\">\r\n        <li>Firmware update in order to change the DC PEM parameter setting.</li>\r\n        <li>The fix from -02 version to -03 also includes a HW design improvement.</li></ol></li></ol>\r\n<p>In summary, improvements to address Issue 1 are incorporated with TAN 341-0325-02 and newer versions. Improvements to address Issue 2 are incorporated with TAN 341-0325-03 and newer versions.</p>",
            "problemSymptoms": "<ol><li>One or more DC power module might not provide power to the ASR9000 router on power up.</li>\r\n  <li>After a single power feed failure, the <strong> %PLATFORM-PWRMON-2-MODULE_WARNING</strong> syslog alarm or event might not be generated, and/or the power LED might remain lit. There is no functional impact to the power module or router.</li></ol>\r\nHere is an example of the alarm or event with power feed B disrupted:\r\n<pre>RP/0/RSP0/CPU0:Apr 19 13:13:46.688 BST: pwrmon[289]: <br>\t\t%PLATFORM-PWRMON-2-MODULE_WARNING : Power-module 0/PM5/SP warning condition raised\r\nRP/0/RSP0/CPU0:Apr 19 13:13:46.688 BST: pwrmon[289]: <br>\t\t%PLATFORM-PWRMON-2-MODULE_WARNING_REASON : Power-module 0/PM5/SP warning condition reason: <br>\t\tModule feeder-B input voltage is missing or outside design limits </pre>",
            "workaround": "All 2KW (TAN:341-0325-01) and 1.5KW (TAN:341-0337-01) DC power modules shipped from February 2009 to January 31st 2011 might be subject to these failures. The replacement program is closed, and Cisco recommends that you replace all -01 versions of these power modules on failure.&nbsp;<br>\r\n\r\nFor customers with 2KW (TAN:341-0325-02) and 1.5KW (TAN:341-0337-02) DC power modules, Cisco recommends that you take no action at this time and replace only if the problem symptom observed is no power feed failure alarm or a power LED that remains lit for an extended time.&nbsp;<br>\r\n\r\nCisco ships 2KW (TAN:341-0325-03) and 1.5KW (TAN:341-0337-03) versions (or newer) to customers as part of the replacement. Version -02 and Version -03 DC power module can coexist in the same router.&nbsp;<br>\r\n\r\nUse the <strong>How To Identify Hardware Levels</strong> section of this document in order to locate the PID, serial number, and TAN/version of the power module. Use this table in order to identify suspect power module and corrective action.\r\n<table border=\"1\" cellpadding=\"0\" cellspacing=\"2\"><tr><th bgcolor=\"#DBDBDB\">Part Number or TAN</th><th bgcolor=\"#DBDBDB\">Steps</th><th bgcolor=\"#DBDBDB\">Action</th></tr>\r\n<tr>\r\n<td>341-0337-01 (1.5KW ASR9K DC power module)</td>\r\n<td><a href=\"http://serialnumbervalidation.com/63380\">Check Serial Number Validation tool</a></td>\r\n<td>If affected, replace on failure using Cisco Return Material Authorization (RMA) process.</td>\r\n</tr>\r\n<tr>\r\n<td>341-0325-01 (2KW ASR9K DC power module)</td>\r\n<td><a href=\"http://serialnumbervalidation.com/63380\">Check Serial Number Validation tool</a></td>\r\n<td>If affected, replace on failure with the Cisco RMA process.</td>\r\n</tr>\r\n<tr>\r\n<td>341-0337-02 (1.5KW ASR9K DC power module)</td>\r\n<td>No check required</td>\r\n<td>Action required only if no power feed fail alarm or event is generated and/or the power LED remains lit after the power feed failure. Follow Cisco RMA process. **</td>\r\n</tr>\r\n<tr>\r\n<td>341-0325-02(2KW ASR9K DC power module )</td>\r\n<td>No check required</td>\r\n<td>Action required only if no power feed fail alarm or event is generated and/or the power LED remains lit after the power feed failure. Follow Cisco RMA process.**</td>\r\n</tr>\r\n<tr>\r\n<td>341-0337-02 with Deviation D119654 or 341-0337-03 or higher (1.5KW ASR9K DC power module)</td>\r\n<td>No check required</td>\r\n<td>Not affected. No action required.</td>\r\n</tr>\r\n<tr>\r\n<td>341-0325-02 with Deviation D119654 or 341-0325-03 or higher (2KW ASR9K DC power module)</td>\r\n<td>No check required</td>\r\n<td>Not affected. No action required.</td></tr></table>\r\n <br>\r\n ** ASR9000 Router operation not affected.&nbsp;\r\n\r\n<strong>Note:</strong> If the SNV tool marks the power module as affected but with part number -02 with deviation D119654 or -03, the DC power module is good.&nbsp;<br>\r\nNo Cisco internal DC power module is allowed for replacement.\r\n\r\nFor information about how to replace the DC power module, refer to the <a href=\"http://www.cisco.com/en/US/docs/routers/asr9000/hardware/installation/guide/asr9kIGmaintaining.html#wp1166550\"> Removing and Replacing AC or DC Power component</a> section of the <a href=\"http://www.cisco.com/en/US/docs/routers/asr9000/hardware/installation/guide/asr9kIGmaintaining.html\">Cisco ASR 9000 Series Aggregation Services Router Hardware Installation Guide</a>.",
            "hardwareLevels": "",
            "upgradeProgram": "",
            "caveat": null,
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/633/fn63380.html"
        },
        {
            "fieldNoticeId": 63390,
            "status": "P",
            "bulletinLastUpdated": "2018-06-04T00:00:00Z",
            "bulletinTitle": "FN63390 - GSR PRP-2 Might Fail While in Operation after Extended Period of Time - Replace on Failure",
            "bulletinFirstPublished": "2011-03-21T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "PRP-2 board may fail in GSR Router while in operation for extended period of time. The failure symptoms may be several such as PRP-2 failure, switchover to standby PRP-2, router reload, traffic outage, or PRP-2 board in indeterminate state.",
            "background": "PRP-2 in GSR router is the central processor and performs various functions such as routing, traffic management, line card monitoring, and more. The PRP-2 board is made up of CPU, memory, controllers, FPGAs, and other active and discrete components. The FPGA on PRP-2 receives slightly higher voltage on the PLL VCC pins than recommended by the vendor, leading to electrical stress over the long term, reducing reliability of the device and eventually causing failure of PLL circuit and FPGA.\r\n \r\nThe FPGA converts processor bus to interface the IO devices such as Flash, NVRAM, compact disk, and memory and implements MBUS Mailbox functionality. Failure of FPGA PLL circuit leads to very slow heat up of the FPGA device over time resulting in logic lock-up condition thereby leading to PRP-2 board failure. Since the PLL circuit of FPGA is not used on PRP-2, no hard failure or symptom of the PRP-2 board can be predicted, the failures may manifest different ways due to logic lock-up condition of the FPGA.",
            "problemSymptoms": "PRP-2 board may fail in GSR Router while in operation for extended period of time. There may be several different failure symptoms such as PRP-2 failure, switchover to standby PRP-2, router reload, traffic outage, or PRP-2 board in indeterminate state.",
            "workaround": "PRP-2s shipped between March 2006 to November 2010 are suspect. PRP-2 boards shipped post November 2010 contain new PCB design to correct VCC_PLL ping voltage. Alternatively, refurbished PRP-2 boards shipped by Cisco service under RMA or upgrade program will not have the issue, since the issue is fixed by interposer adaptor. \r\n\r\nThis table helps you identify if PRP-2 board are suspect or good board.\r\n\r\n<TABLE BORDER='1' CELLPADDING='0' CELLSPACING='2'><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>TAN or Part number</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Steps</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Action</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>800-27058-09 and lower</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'><a href=\"http://serialnumbervalidation.com/63390/cgi-bin/index.cgi\"> Check Serial number </a></FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>If affected, follow the normal RMA process</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>800-27058-09 with Deviation D113342, D113851, D115209, D115427 </FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>No check required</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>PRP-2 is good, No replacement required</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>800-27058-11 and higher</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>No check required</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>PRP-2 is good, No replacement required</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>800-23469-xx(PRP-2 shipped prior March 2006)</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>No check required</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>PRP-2 is good, No replacement required</FONT></TD></TR></TABLE>\r\n**If TAN information is not available, use Serial Number Tool(SN Tool) to verify if board is affected. SN Tool is updated monthly.\r\n\r\n<B>Note:</B> PRP-2 with TAN 800-27058-11 are good boards ( not affected) even when the PRP-2 board falls within the serial number listed in tool as affected. PRP-2 boards shipped to customer with TAN 800-27058-09 and deviation D113342, D113851, D115209, D115427 are good boards (not affected). PRP-2 boards with TAN 800-27058-10 were not shipped to customer.\r\n\r\nThe replacement of PRP-2 is recommended during maintenance window. <B>Customer are requested to retain DIMM(Memory), PCMCIA Flash card as it will be needed for plugin to replacement PRP-2.</B>",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/633/fn63390.html"
        },
        {
            "fieldNoticeId": 63402,
            "status": "P",
            "bulletinLastUpdated": "2019-01-31T00:00:00Z",
            "bulletinTitle": "FN63402 - A batch of ME3800/ME3600 switch boxes in ME3800 platform have DC PS plastic cover missing - Replace on Failure",
            "bulletinFirstPublished": "2011-04-13T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "From November 2010 to mid-December 2010, ME3600/ME3800 switches were shipped without the plastic housing covering the DC terminal.  This plastic cover is a safety control to avoid shock hazard and bridging hazards. When the housing cover is not attached, there is a risk of electric shock if human contact occurs with the exposed DC terminal. There also is a risk these switches could experience an electric short that could cause performance interruption if the DC terminal is contacted (jewelry, other metals, etc.).  The plastic housing cover should be installed immediately on any ME3600/3800 switches for the affected units where such safety cover is missing.",
            "background": "The plastic housing was not installed on DC terminals of the ME-3600X-24FS-M; ME-3800X-24FS-M; and ME-3600X-24TS-M switches prior to shipment for the period November 2010 through mid-December 2010.  The production process has been updated to include installation of plastic housing covers on DC terminals of the ME3600/ME3800 switch boxes before shipment. We have not identified any other products that were shipped without the plastic housing cover.  Customers have been identified that purchased these switches during the impacted period, and, Cisco is shipping out the plastic housing covers to these customers to be installed in the field by Cisco channel partners who sold units that were missing this important safety control.",
            "problemSymptoms": "Please see the attached picture for the appearance of the plastic housing, and its position on the DC terminal.",
            "workaround": "Affected customers have been identified. Cisco is shipping out plastic housing to these customers, with instructions for the customer to install the plastic housing over the DC terminals in the field. Cisco does not recommend replacement(RMA) for these affected M3600/ME3800 boxes.  No action required by other customers with the same products.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": "Cisco doesn't recommend RMA for changing the plastic covering. Manual verification is needed to verify whether the DC plastic cover is missing or not, as there is no way to identify the non-vulnerable one.",
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/634/fn63402.html"
        },
        {
            "fieldNoticeId": 63405,
            "status": "P",
            "bulletinLastUpdated": "2019-10-25T00:00:00Z",
            "bulletinTitle": "FN63405 - CISCO18XX & CISCO28XX Might Fail to Boot After a Power Cycle - Replace on Failure",
            "bulletinFirstPublished": "2014-03-03T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "The CISCO18XX & CISCO28XX Series hardware (listed in the Products Affected section) might fail to boot up after a user action where the board requires a power cycle operation.",
            "background": "Cisco has been working with some customers on an issue related to memory components manufactured by a single supplier between 2005 and 2010. These memory components are widely used across the industry and are included in a number of Cisco products.Although the majority of Cisco products using these components are experiencing field failure rates below expected levels, some components may fail earlier than anticipated. A handful of our customers have recently experienced a higher number of failures, leading us to change our approach to managing this issue.While other vendors have chosen to address this issue in different ways, Cisco believes its approach is the best course of action for its customers. Despite the cost, we are demonstrating that we always make customer satisfaction a top priority. Customers can learn more about this topic at the Memory Component Issue web page.A degraded component will not affect the ongoing operation of a device, but will be exposed by a subsequent power cycle event. This event will result in a hard failure of the device, which cannot be recovered by a reboot or additional power cycle. For these reasons, additional caution is recommended for operational activities requiring the simultaneous power cycling of multiple devices. This issue has been observed most commonly on devices that have been in service for 24 months or more.",
            "problemSymptoms": "If the CISCO18XX & CISCO28XX Series hardware (listed in the Products Affected section) has been in continuous operation for approximately 24 months, then the hardware might fail to boot up due to memory failure during a power cycle event. This is caused by one or more of these actions:- Power cycle the entire product- Power cycle after installation or Software Upgrade- Manual or facility power interruptionNote: This issue does not affect boards while the boards are in operation. The board failure might occur after one or more of the actions listed are executed.The problem symptoms include these memory failure messages that might be observed on suspect routers:- Bad RAM- SDRAM ECC Error",
            "workaround": "For CISCO18XX Series hardware: Request Router RMA product through normal service channels. For CISCO28XX Series hardware: Request Memory RMA through normal service channels (Memory module replacement only). Please refer to this table for the appropriate Memory Product ID replacement:  NOTE: Routers may have multiple DIMMs. Please verify the individual DIMM slots using the command in the \"How to Identify Hardware Levels\" section of this Field Notice. Please refer to the Installing and Removing DRAM DIMMs section of the Cisco 2800 Series Hardware Installation Guide in order to replace the Memory modules on CISCO28XX Series routers. End of Support Date Normal SmartNet and warranty entitlement rules remain in place and are applied by the Cisco Technical Assistance Center (TAC) if you experience a failure in one of the products listed in the Field Notice. In other circumstances, such as out of warranty or out of contract, Cisco encourages you to raise your concern directly with your Cisco account team. Fix on Failure Replacement Guidelines: Request Return Material Authorization (RMA) product through normal service support channels. If you need assistance in order to determine which hardware part(s) might need replacement, consult the error messages documented in the Problem Symptom section.PIDEnd of Support NoticeEnd of Support DateCISCO1801W-AG-E/K9EOL678411/30/2014CISCO1802W-AG-E/K9EOL678411/30/2014CISCO1803W-AG-E/K9EOL678411/30/2014CISCO1812W-AG-E/K9EOL678411/30/2014CISCO1811/K9EOL707304/30/2016CISCO1811W-AG-B/K9EOL707304/30/2016CISCO1811W-AG-C/K9EOL707304/30/2016CISCO1811W-AG-N/K9EOL707304/30/2016CISCO1812-J/K9EOL707704/30/2016CISCO1812/K9EOL707704/30/2016CISCO1812W-AG-C/K9EOL707704/30/2016CISCO1812W-AG-J/K9EOL707704/30/2016CISCO1812W-AG-P/K9EOL707704/30/2016CISCO1841EOL724910/31/2016CISCO2821EOL723710/31/2016CISCO2851EOL723710/31/2016",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": "Automation is only checking Product ID.  Additional details can be found in the Field Notice.",
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/634/fn63405.html"
        },
        {
            "fieldNoticeId": 63416,
            "status": "P",
            "bulletinLastUpdated": "2019-04-05T00:00:00Z",
            "bulletinTitle": "FN63416 - DS-C9124 & DS-C9148 Have Incorrect MAC Programming - Replace on Failure",
            "bulletinFirstPublished": "2011-05-05T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "Some MDS 9124 and MDS 9148 units produced between Feb 13, 2011 and April 29, 2011 were programmed with incorrect MAC addresses.",
            "background": "The Cisco FMS software is currently dependent upon the OUI of the MAC address to recognize equipment as a Cisco device.  The affected systems were programmed with an OUI of \"64:00:f1\".",
            "problemSymptoms": "Cisco Fabric Manager and other protocols will not recognize a switch with an OUI of \"64:00:f1\" as a Cisco switch. A switch with an incorrect OUI will have the following issues: Traps will not be registered The switch will not be monitored or discovered properly Performance Manager will not collect stats from the switch The switch will not be included in various wizards including FCIP, Security Wizard, Upgrade wizard and the IOA wizard.The first 3 bytes of the MAC address are the OUI. Customers can identify if their switch is affected by issuing the command \"show sprom backplane 1  include \"MAC Address\". Look at the first 3 bytes of the MAC address to see if your device is affected.switch# show sprom backplane 1  include \"MAC Address\"MAC Addresses : 64-00-f1-01-ca-b2",
            "workaround": "Contact the TAC to replace the affected hardware via the standard RMA process.As of approximately May 01, 2011 new products are guaranteed to be free of this problem. Refer to \"How to Identify Hardware Levels\" below for instructions on how to view the version and deviation of in-service product.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/634/fn63416.html"
        },
        {
            "fieldNoticeId": 63430,
            "status": "P",
            "bulletinLastUpdated": "2019-02-04T00:00:00Z",
            "bulletinTitle": "FN63430 - UCS B440 MOSFET Failure Can Cause Overheated Components Leading to Blade Shutdown - Replace on Failure",
            "bulletinFirstPublished": "2011-07-12T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "Failure of a MOSFET power transistor on the blade server may cause the component to overheat and emit a short flash and may lead to board failure. In some circumstances this symptom may affect the other blades in the chassis by disrupting power flow.  Update 1: The firmware upgrade initially prescribed in this Field Notice has successfully detected component failures and shut down servers as expected. Since this upgrade was released, however, a MOSFET failure on a UCS B440 Blade Server has resulted in a second thermal event. Cisco has determined that a hardware modification to the UCS B440 Blade Server is appropriate. No other UCS hardware is affected. Although a UCS B440 Blade Server hardware replacement program was launched, this program is now over and a standard RMA will address the issue.  Update 2: The hardware version identification process has been updated to note a software defect preventing proper version display in UCSM.",
            "background": "A failure has been observed where a MOSFET power transistor failed in a manner that caused the MOSFET to overheat and emit a flash before failing. A firmware fix has been developed as a preventative measure for avoiding the overheating and flash event in case of failure.  There is no indication of a systemic issue with the MOSFET components, and the observed failure in the field is considered to be a random component failure. The firmware upgrade is intended to be a preventative measure to avoid shorted out components and any effects on other installed elements within the UCS chassis.  Update 1: The firmware upgrade initially prescribed in this Field Notice has successfully detected FET failures and shut down servers, preventing a potential thermal event. Since this upgrade was released, however, a FET failure on a UCS B440 Blade Server has resulted in a second incident as described above. No other UCS hardware was affected by this issue.  Update 2: The majority of UCS B440 Blade Servers affected by this issue have been addressed through direct contact by Cisco or an authorized Cisco partner and/or by the now closed upgrade program. Although Cisco has made every effort to proactively track down and replace affected hardware, defective units may still be deployed in the field.  Cisco customers with affected Blade Servers who have not yet taken advantage of the proactive replacement program can still obtain a replacement through the standard RMA ordering process.",
            "problemSymptoms": "There is no symptom during normal operation. If the MOSFET fails in a shorted mode, a flash may be emitted and it will lead to a system board failure.",
            "workaround": "Cisco recommends replacing UCS B440 M1 and UCS B440 M2 Blade Servers at hardware version level 01 with blades at version level 02 or later. Please see the section How to Identify Hardware Levels for instructions for determining whether a version 01 UCS B440 M1 or M2 Blade Server is installed. If running hardware version 01, you are eligible for replacement using the standard RMA process.  1. Open a Cisco TAC case. 2. Provide the version level information needed by TAC. See \"How to Identify Hardware levels\" section below. 3. Provide \"FN-63430\" as a reference number. 4. An RMA will be created and replacement part delivered.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/634/fn63430.html"
        },
        {
            "fieldNoticeId": 63442,
            "status": "P",
            "bulletinLastUpdated": "2013-06-21T17:45:06Z",
            "bulletinTitle": "FN 63442 - LSI RAID Controller Chip Potential Premature Failure - Hardware Replacement Required",
            "bulletinFirstPublished": "2011-09-21T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "",
            "background": "",
            "problemSymptoms": "",
            "workaround": "",
            "hardwareLevels": "",
            "upgradeProgram": "",
            "caveat": null,
            "url": "http://www.cisco.com/en/US/ts/fn/634/fn63442.html"
        },
        {
            "fieldNoticeId": 63451,
            "status": "P",
            "bulletinLastUpdated": "2019-03-28T00:00:00Z",
            "bulletinTitle": "FN63451 - ONS 15454-SA-HD, Chassis in secure mode - Replace on Failure",
            "bulletinFirstPublished": "2011-12-16T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "***** Note: The replacement program has expired on 10/31/12. Customers who experience this issue may use the regular RMA process for replacement *****Certain manufactured 15454-SA-HD chassis shipped with secure locked mode enabled. This mode blocks all communication to the TCC control card and prohibits configuration or status checking. These 15454-SA-HD chassis are identified by serial number.",
            "background": "Certain 15454-SA-HD chassis were incorrectly set to secure locked mode prior to shipping. These units have been identified by serial number. HistoryField Notice RevisionDateComments2.004-Apr-2014REVISION",
            "problemSymptoms": "If in secure locked mode, two separate IP addresses will exist for the node: one accessible from the front TCC2P/TCC3 card and the other accessible from the rear backplane interface. Once in secure locked mode, the user cannot change the setting to use a single IP address for the node.",
            "workaround": "There is no workaround procedure identified for this issue. Cisco recommends that customers with affected hardware replace their units.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/634/fn63451.html"
        },
        {
            "fieldNoticeId": 63463,
            "status": "P",
            "bulletinLastUpdated": "2017-10-12T00:00:00Z",
            "bulletinTitle": "FN63463 - WS-C49000M Missing Plate Covers for Power Supply 4900M-PWR-CVR= - Replace on Failure ",
            "bulletinFirstPublished": "2011-11-21T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "See Background Section.",
            "background": "A small number of Cisco orders for WS-C4900M product were shipped with missing power supply plate covers. In the event you need this part, please contact Cisco Systems, Inc. for a free replacement. It is recommended you always have plate covers on your equipment to provide adequate cooling.",
            "problemSymptoms": "All power supply bays that did not include a power supply at time of order should have received a plate cover installed over the open power supply bay.",
            "workaround": "There is no workaround (since the issue is a missing part).It is recommended you always have plate covers on your equipment to provide adequate cooling. In the event you need power supply plate covers, please contact Cisco Systems, Inc. for free replacements. The replacement part is 4900M-PWR-CVR=.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": "Only matching done for this Field Notice is on PID.  Manual verification will be required to determine if you are missing a plate cover.",
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/634/fn63463.html"
        },
        {
            "fieldNoticeId": 63476,
            "status": "P",
            "bulletinLastUpdated": "2018-05-30T00:00:00Z",
            "bulletinTitle": "FN63476 - Certain Catalyst 3560G and 3750G Switches Do Not Support Some Older IOS Versions - Software Upgrade Recommended",
            "bulletinFirstPublished": "2011-12-12T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "Due to hardware changes in the flash component of the Cisco Catalyst 3560G and 3750G switches, some older IOS versions are not supported on the affected hardware.",
            "background": "Due to supply constraints, Cisco was required to migrate to new flash components on its Catalyst 3560G and 3750G switches.  The switches, with the new flash, are compatible back to the 12.2(35)SE IOS release.",
            "problemSymptoms": "The affected Catalyst 3560G and 3750G switches are unable to use IOS versions prior to the 12.2(35)SE release.  If an IOS version prior to 12.2(35)SE is used on an affected 3560G or 3750G switch, the following error messages will be displayed during the boot process:intel_28f256j3_16x_write_bytes: command sequence errorflashfs[1]: writing to flash handle 0x254D8A0, device 0, offset 0x1600000, length 0x208: Operation Failedflashfs[1]: sector ptr: {0xB0, 0xE7}flash:/c3750_ucode_image.tar: No space left on deviceIn addition to displaying the above error messages, when the boot process is complete, the switch will appear to be running properly.  However, the flash will be inaccessible and, therefore, the switch will not be operational (see the following two sample outputs below).3560#dirDirectory of flash:/%Error opening flash:/ (Device or resource busy)32514048 bytes total (16258560 bytes free)-OR-3560#wr memBuilding configuration...nv_done: unable to open \"flash:/config.text.new\"nv_done: unable to open \"flash:/private-config.text.new\"nv_done: unable to open \"flash:/multiple-fs.new\"[OK]",
            "workaround": "Any Catalyst 3560G or 3750G switches within the Affected Serial Number Range provided in the table below are affected.  For the affected 3560G and 3750G switches, IOS versions prior to 12.2(35)SE cannot be used.  The recommendation is to upgrade to 12.2(55)SE4 and above.Affected PIDsAffected Serial Number RangeWS-C3560G-24PS-EFOC1536X198 and aboveWS-C3560G-24PS-SFOC1528372B to FOC15283737FOC1539V3RD and aboveWS-C3560G-24TS-EFOC1539Z2PH and aboveWS-C3560G-24TS-SFOC152816W3 to FOC152816X1FOC1534X4NW and aboveWS-C3560G-48PS-EFOC1537X3AD and aboveWS-C3560G-48PS-SFOC1528370C to FOC1528371EFOC1537X3ML and aboveWS-C3560G-48TS-EFOC1537V1C4 and aboveWS-C3560G-48TS-SFOC152816XF to FOC152816YAFOC1536X1ZR and aboveWS-C3750G-24PS-EFOC1545Z19A and aboveWS-C3750G-24PS-SFOC1531Y3TV to FOC1534Y3FUFOC1545X1N8 and aboveWS-C3750G-24PS-S-1FOC1545X1N8 and aboveWS-C3750G-24TS-E1UFOC1542Y25R and aboveWS-C3750G-24TS-S1UFOC1530Y03Y to FOC1534Y3FZFOC1542V3HF and aboveWS-C3750G-48PS-EFOC1542Y33J and aboveWS-C3750G-48PS-SFOC1532Y316 to FOC1532Y31GFOC1541V35G and aboveWS-C3750G-48TS-EFOC1542X1KD and aboveWS-C3750G-48TS-SFOC1534Y24E to FOC1534Y24GFOC1541V412 and aboveIf a non-supported IOS software image is installed on an affected Catalyst 3560G or 3750G switch, then please follow the \"Recovering from a Software Failure\" guidelines in the Catalyst 3560 Software Configuration Guide or Catalyst 3750 Software Configuration Guide on Cisco.com. Once a supported version of IOS is re-installed on the switch, it will operate normally.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/634/fn63476.html"
        },
        {
            "fieldNoticeId": 63493,
            "status": "P",
            "bulletinLastUpdated": "2020-08-22T00:00:00Z",
            "bulletinTitle": "FN63493 - CRS - Products Affected Might Fail to Boot Up After a Software Upgrade or Power Cycle - Replace on Failure",
            "bulletinFirstPublished": "2014-03-03T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "The Carrier Routing System (CRS) linecards (listed in the Products Affected section) might fail to boot up after a software upgrade or other user action where the board requires a power cycle operation.",
            "background": "Cisco has been working with some customers on an issue related to memory components manufactured by a single supplier between 2005 and 2010. These memory components are widely used across the industry and are included in a number of Cisco products.\r\n\r\nAlthough the majority of Cisco products using these components are experiencing field failure rates below expected levels, some components may fail earlier than anticipated. A handful of our customers have recently experienced a higher number of failures, leading us to change our approach to managing this issue.\r\n\r\nWhile other vendors have chosen to address this issue in different ways, Cisco believes its approach is the best course of action for its customers. Despite the cost, we are demonstrating that we always make customer satisfaction a top priority. Customers can learn more about this topic at <a href=\"http://www.cisco.com/go/memory\">Memory Component Issue</a> web page.\r\n\r\nA degraded component will not affect the ongoing operation of a device, but will be exposed by a subsequent power cycle event. This event will result in a hard failure of the device, which cannot be recovered by a reboot or additional power cycle. For these reasons, additional caution is recommended for operational activities requiring the simultaneous power cycling of multiple devices. This issue has been observed most commonly on devices that have been in service for 24 months or more.",
            "problemSymptoms": "If the CRS linecard (listed in the Products Affected section) has been in continuous operation for approximately 24 months, then the CRS hardware might fail to boot up due to memory failure during a power cycle event. This is caused by one or more of these actions:\r\n \r\n- Upgrade the software \r\n- Reload the entire product\r\n- Reload after installation  \r\n- Online Insertion Removal/Replacement (OIR) \r\n\r\n<b>Note:</b> This issue does not affect boards while the boards are in operation. The board failure might occur after one or more of the actions listed are executed. \r\n\r\nThe linecard symptoms vary by type of CRS linecard:\r\n\r\n- When <B>CRS-MSC-B</B> experiences a boot-up issue, the <b>admin show platform</b> command displays one line as shown here:\r\n \r\n<IMG SRC=\"http://www-tac.cisco.com/Support_Library/field_alerts/fn63493_n1orob.jpeg\"><br><br><br>\r\n\r\n<B>The previous output does not show CPUO.</B>\r\n\r\nIn a normal situation, the <b>admin show platform</b> command displays two lines for each Module Services Card (MSC).  \r\n\r\n<b>Note:</b> The user must have Admin Execute privilege to run the command.\r\n\r\n<IMG SRC=\"http://www-tac.cisco.com/Support_Library/field_alerts/fn63493_n1orqh.jpeg\"><br><br><br>\r\n\r\nBoth SP and CPU0 should display IOS XR RUN.\r\n\r\n- When <B>RP / RP-B</B> experiences this Memory module issue, the Memory module error message appears as shown in the console log as the RP boots up:\r\n\r\n<IMG SRC=\"http://www-tac.cisco.com/Support_Library/field_alerts/fn63493_n1orrw.jpeg\"><br><br><br>\r\n\r\n- For DRP-B, the error log is not available.\r\n\r\n- For SC-22GE, the error log is not available.",
            "workaround": "Normal SmartNet and warranty entitlement rules remain in place and will be applied by the Cisco TAC if you experience a failure in one of the products listed in the Field Notices. In other circumstances (e.g. out of warranty or out of contract), we'd encourage you to raise your concern directly with your Cisco account team.\r\n \r\nFix on failure Replacement Guidelines: Request RMA product through normal service support channels. \r\nIf you need assistance in order to determine which hardware part(s) might need replacement, consult the error messages documented in the Problem Symptom section.\r\n\r\nAll of the actions mentioned in this Workaround/Solution section require Admin Execute privileges and must be performed in a maintenance window. \r\n\r\nCRS linecards might not boot up for various reasons, one of which is the Memory module failure.\r\n\r\nIf the CRS linecards fail to boot up, use this table in order to identify if the CRS linecard might contain a suspect Memory module.\r\n\r\n<TABLE BORDER='1' CELLPADDING='0' CELLSPACING='2'><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>PID</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Action</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>PID Replacement</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Quantity</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>CRS-16-RP-B(=)</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Replace Memory Module on Failure</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>CRS-MEMORY-2G=</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>2</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>CRS-8-RP(=)</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Replace Memory Module on Failure</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>CRS-MEMORY-2G=</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>2</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>CRS-DRP-B-CPU(=)</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Replace Memory Module on Failure</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>CRS-MEMORY-2G=</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>4</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>CRS-FCC-SC-22GE(=)</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Replace Memory Module on Failure</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>CRS-MEMORY-2G=</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>1</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>CRS-MSC-B(=)</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Replace Memory Module on Failure</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>CRS-DIMM-2G=</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>1</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>CRS-FP40(=)</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Replace Memory Module on Failure</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>CRS-DIMM-2G=</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>1</FONT></TD></TR></TABLE>\r\n\r\nFix on Failure Replacement Guidelines: Request RMA product and memory modules through normal service support channels.\r\n\r\nEnd of Support PID:\r\n<TABLE BORDER='1' CELLPADDING='0' CELLSPACING='2'><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>PID</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>End of Support Notice</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>End of Support Date</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>CRS-MSC(=)</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'><a href=\"http://www.cisco.com/c/en/us/products/collateral/routers/carrier-routing-system/eol_c51_479098.html\">EOL6442</a></FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>29th June 2014</FONT></TD></TR></TABLE>\r\n\r\nSee <a href=\"http://www.cisco.com/en/US/partner/docs/routers/crs/memory/upgrade/dimm_crs.html\">CRS DRR DIMM Memory Upgrade</a> in order to replace the Memory modules on CRS boards.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": "Matching is based on PID Only.  Please see Field Notice for details about affected products.",
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/634/fn63493.html"
        },
        {
            "fieldNoticeId": 63521,
            "status": "P",
            "bulletinLastUpdated": "2019-03-19T00:00:00Z",
            "bulletinTitle": "FN63521 - ASA5500-X Appliance - Units shipped without default configuration - Configuration Change Recommended",
            "bulletinFirstPublished": "2012-09-12T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "ASA 5500-X security appliances that shipped from March 16, 2012 through June 11, 2012 contain the incorrect factory default configuration. This requires the user to follow special procedures for system initialization.",
            "background": "The ASA 5500-X appliances shipped from March 16, 2012 through June 11, 2012 were not loaded with the correct factory default configuration and must be initialized using special commands. The procedures contained in the Quick Start Guide are insufficient to properly initialize the affected units.",
            "problemSymptoms": "Users attempting to initialize the affected ASA 5500-X appliances using the Quick Start Guide will observe that the management 0/0 ports are in the down/down condition. In addition, ASDM for on box management is not accessible.",
            "workaround": "The factory default configuration can be applied using the following command:asa# config factory-default Note that the ASA 5515-X appliance does not support the command above due to Cisco bug ID CSCtz73669. The unit must be restored to the factory default configuration using the command series shown below.asa# config tclear config all!interface management0/0nameif managementip address 192.168.1.1 255.255.255.0security-level 100no shutdown!http server enablehttp 192.168.1.0 255.255.255.0 management!dhcpd address 192.168.1.2-192.168.1.254 managementdhcpd enable management!logging asdm informational",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": "Manual verification of workaround is required.",
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/635/fn63521.html"
        },
        {
            "fieldNoticeId": 63553,
            "status": "P",
            "bulletinLastUpdated": "2018-08-23T00:00:00Z",
            "bulletinTitle": "FN63553 - C7600 Might Fail to Boot Up after a Software Upgrade or Power Cycle - Replace on Failure",
            "bulletinFirstPublished": "2014-03-03T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "C7600 might fail to boot up after a software upgrade or other user action where the board requires a power cycle operation.",
            "background": "Cisco has been working with some customers on an issue related to memory components manufactured by a single supplier between 2005 and 2010. These memory components are widely used across the industry and are included in a number of Cisco products.\r\n\r\nAlthough the majority of Cisco products using these components are experiencing field failure rates below expected levels, some components may fail earlier than anticipated. A handful of our customers have recently experienced a higher number of failures, leading us to change our approach to managing this issue.\r\n\r\nWhile other vendors have chosen to address this issue in different ways, Cisco believes its approach is the best course of action for its customers. Despite the cost, we are demonstrating that we always make customer satisfaction a top priority. Customers can learn more about this topic at <a href=\"http://www.cisco.com/go/memory\">Memory Component Issue</a> web page.\r\n\r\nA degraded component will not affect the ongoing operation of a device, but will be exposed by a subsequent power cycle event. This event will result in a hard failure of the device, which cannot be recovered by a reboot or additional power cycle. For these reasons, additional caution is recommended for operational activities requiring the simultaneous power cycling of multiple devices. This issue has been observed most commonly on devices that have been in service for 24 months or more.",
            "problemSymptoms": "If the suspected hardware has been in operation for approximately 24 months, the product hardware might fail to boot up due to memory failure during a power cycle event. This is caused by one or more of these actions:\r\n\r\n-Upgrade the software\r\n-Reload the entire product\r\n-Reload after installation\r\n-Online Insertion Removal/Replacement (OIR) \r\n\r\n<b>Note:</b> This issue does not affect boards while the boards are in operation. The board failure might occur after one or more of the actions listed are executed.\r\n\r\nThe card symptoms observed are shown here:\r\n\r\nThe card fails to boot up. One of these symptoms might be observed in the syslog:\r\n\r\n*May 16 02:59:54.575: %PM_SCP-SP-1-LCP_FW_ERR: System resetting module 1 to \r\nrecover from error: Linecard received system exception\r\n\r\n\r\n*May 16 02:59:54.575: %OIR-SP-3-PWRCYCLE: Card in module 1, is being \r\npower-cycled Off (Module Reset due to exception or user request) \r\n\r\n\r\nAlternatively, the card might crash repeatedly with this error reported in the syslog:\r\n\r\n%EARL-DFC<n>-2-PATCH_INVOCATION_LIMIT: 10 Recovery patch invocations in the\r\nlast 30 secs have been attempted. Max limit reached\r\n\r\n\r\nOffline diagnostic test item ST4 captures the suspect memory chip.",
            "workaround": "Normal SmartNet and warranty entitlement rules remain in place and are applied by the Cisco Technical Assistance Center (TAC) if you experience a failure in one of the products listed in the Field Notice. In other circumstances, such as out of warranty or out of contract, Cisco encourages you to raise your concern directly with your Cisco account team. \r\n\r\nFix on Failure Replacement Guidelines: Request Return Material Authorization (RMA) product through normal service support channels.\r\n\r\nIf you need assistance in order to determine which hardware part(s) might need replacement, consult the error messages documented in the Problem Symptom section.\r\n\r\nFix on Failure Replacement Guidelines: Request Memory module on failure via RMA process. \r\n\r\nFor other Product Affected cards, request a spare PID through RMA process on failure.\r\n\r\nIn some C7600 cards, the memory module can be replaced in customer sites and are listed in the table below.<table border=\"1\"><tr><td><strong>PID</strong></td>\r\n    <td><strong>Action</strong></td>\r\n    <td><strong>PID Replacement</strong></td>\r\n    <td><strong>Quantity</strong></td>\r\n  </tr>\r\n  <tr>\r\n    <td rowspan=\"2\">7600-SIP-200(=)</td>\r\n    <td rowspan=\"2\">Replace  memory module on failure</td>\r\n    <td>MEM-SIP-200-512M=</td>\r\n    <td>1</td>\r\n  </tr>\r\n  <tr>\r\n    <td>MEM-SIP-200-1G=</td>\r\n    <td>1</td>\r\n  </tr>\r\n  <tr>\r\n    <td rowspan=\"2\">WS-X6582-2PA(=)</td>\r\n    <td rowspan=\"2\">Replace  memory module on failure</td>\r\n    <td>MEM-CC-WAN-512M=</td>\r\n    <td>2</td>\r\n  </tr>\r\n  <tr>\r\n    <td>MEM-CC-WAN-256M=</td>\r\n    <td>2</td>\r\n  </tr></table>\r\n\r\nSee <a href=\"http://www.cisco.com/c/en/us/td/docs/interfaces_modules/shared_port_adapters/install_upgrade/7600series/SIP-SSC-SPA-HW-Install/7600mov.html#wp1115536\">Memory Installation and Removal</a> for instructions to replace the Memory modules on this product.\r\n\r\nPlease Note: The below PIDs have reached the End of Support and Cisco will not be able to support any replacements.\r\n\r\n<TABLE BORDER='1' CELLPADDING='0' CELLSPACING='2'><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>PID</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>End of Support Notice</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>End of Support Date</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>7600-ES20-10G3C(=)</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>EOL6952</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>03/31/2016</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>7600-ES20-10G3CXL(=)</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>EOL6952</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>03/31/2016</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>7600-ES20-GE3C(=)</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>EOL6952</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>03/31/2016</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>7600-ES20-GE3CXL(=)</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>EOL6952</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>03/31/2016</FONT></TD></TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>7600-ES+2TG3C(=)</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>EOL7283</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>11/30/2016</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>7600-ES+2TG3CXL(=)</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>EOL7283</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>11/30/2016</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>7600-ES+4TG3C(=)</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>EOL7283</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>11/30/2016</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>7600-ES+4TG3CXL(=)</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>EOL7283</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>11/30/2016</FONT></TD></TR></TABLE>",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": "Automation doesn't support identifying memory DIMMs.  The products matching this field notice are only potentially vulnerable, as only the PID has been used for matching.",
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/635/fn63553.html"
        },
        {
            "fieldNoticeId": 63555,
            "status": "P",
            "bulletinLastUpdated": "2019-03-19T00:00:00Z",
            "bulletinTitle": "FN63555 - ASR1000: ASR1013/06-PWR-AC and ASR1013/06-PWR-DC Power Supplies Might Have Intermittent Failure During Operation - Replace on Failure",
            "bulletinFirstPublished": "2012-09-07T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "A defect has been identified in a subset of the ASR1013/06-AC(=) and ASR1013/06-DC(=) power supplies that can result in intermittent failure of a power supply unit.",
            "background": "Power supplies ASR1013/06-PWR-AC(=) and ASR1013/06-PWR-DC(=) shipped from June/2011to June/2012 may fail overtime due to a corrosion on the board-to-board connector.The ASR1000 product family has redundant power supplies, so the system will not have a functional failure until two power supply units within the same zone fail. Show commands, syslog messages, and SNMP traps are available to detect failures of individual power supply units so that they may be replaced in a timely manner in order to prevent a system down situation.Note: The ASR1000 power supply is a redundant system with integrated fans. The router will be fully functional if one of the power supplies fails. However, the power supply is required to be plugged in for the integrated fans in order to provide cooling for the system.",
            "problemSymptoms": "The end-user will see one or more of the power supplies in the system intermittently cycling off and on.  The problem may take many months to develop after the system has been installed and is operational.Customer can do the following to confirm that the PS is off or has failed:1. Check that the PS switch is turned on2. Check that the PS Vin is in the expected range (121V AC in the example below)3. Check the PS Vout value===========Router>show env summaryNumber of Critical alarms: 0Number of Major alarms: 0Number of Minor alarms: 0Slot Sensor Current State Reading---- ------ ------------- -------4 V1: VMA       Normal     1069 mV[... Other Sensors ...]P0    PEM Iout  Normal      12 AP0    PEM Vout  Normal      11 V AC   P1    PEM Vout  Normal       2 V AC  P1    PEM Vin   Normal       121 V AC P3    PEM Vout  Normal         0 V AC P3    PEM Vin   Normal         1 V AC P3    Temp: PEM Normal         21 CelsiusP3    Temp: FC  Fan Speed 65%  22 Celsius[... Other Sensors ...]?Router>=================",
            "workaround": "Request a Return Material Authorization (RMA) through your normal support process for fix on failure.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/635/fn63555.html"
        },
        {
            "fieldNoticeId": 63587,
            "status": "P",
            "bulletinLastUpdated": "2019-02-04T00:00:00Z",
            "bulletinTitle": "FN63587 - No Output from UCS B-Series DC Power Supply After Power Feed Interruption - Replace on Failure",
            "bulletinFirstPublished": "2013-03-04T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "Output power is not restored when the input power feed is interrupted on affected Unified Computing System (UCS) B-Series DC chassis power supplies.",
            "background": "Output power is not restored after the input feed of an affected UCS B-Series DC chassis power supply is removed and restored. The unit appears in UCS Manager as present, but the status is shown as Not Ok. This problem is due to a firmware issue in the power supply. The power supply firmware is not field-upgradeable, so affected power supplies should be replaced with updated units. Refer to Cisco bug ID CSCuc47311.",
            "problemSymptoms": "After input power feed is interrupted, the output power is not present, and the amber Fail Indicator LED is lit on the power supply.",
            "workaround": "Short term workaround: Reseat the power supply. Turn off the power to the individual power supply and loosen the retaining screws. Slide the power supply out a short distance until it unplugs from the backplane and wait 10 seconds. Then slide the power supply back into its slot, tighten the retaining screws, and turn the power back on.  Long term solution: Replace the power supply. The proactive replacement program for this Field Notice has been closed, however replacements can be acquired via standard RMA. If you require replacement power supplies for this issue, contact the Cisco Technical Assistance Center (TAC) and reference Field Notice 63587 when you request an RMA.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": "Matching for vulnerability is based on PID  only.  No Firmware automated check has been done.  Manual verification of Firmware will be required to determine actual vulnerability",
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/635/fn63587.html"
        },
        {
            "fieldNoticeId": 63604,
            "status": "P",
            "bulletinLastUpdated": "2018-05-30T00:00:00Z",
            "bulletinTitle": "FN63604 - ASR 9000/ASR 9001 - Some Enhanced Ethernet Line Cards Might Not Boot or Might Fail During Operation Due to Memory Error - Replace on Failure",
            "bulletinFirstPublished": "2013-02-06T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "Some ASR 9000 Series Aggregation Services Routers (ASR 9000) Enhanced Ethernet line cards and ASR 9001 chassis might not boot or might fail during operation with a memory error or a line card failure.",
            "background": "Cisco has identified two issues with a specific DIMM supplier.\r\n\r\n<B>Issue #1:</B> A batch of DIMM modules used on suspected hardware between June 2012 to August 2012. Based on field failure and Cisco's analysis, the current failure rate observed is low.\r\n\r\n<B>Issue #2:</B> A batch of DIMM modules used on suspected hardware between November 2012 to December 2012. Based on field failure and Cisco's analysis, this issue causes the boards to fail early in the lifecycle.\r\n\r\nNot all ASR 9000 hardware shipped in this period is affected. Use the Serial Number Validation Tool to verify suspect hardware. \r\n\r\nThe supplier has identified the manufacturing issue on the DIMM modules and implemented corrective actions.",
            "problemSymptoms": "The suspected ASR 9000 Enhanced Ethernet line cards and ASR 9001 chassis might not boot on power-up or might fail during operation with a memory error or hardware failure. These error messages might be seen for both issues.\r\n\r\n<B>Error message #1:</B>\r\n<IMG SRC=\"http://www-tac.cisco.com/Support_Library/field_alerts/fn63604_mh1g0f.jpg\"><br><br>\r\n\r\n<B>Error message #2:</B>\r\n<IMG SRC=\"http://www-tac.cisco.com/Support_Library/field_alerts/fn63604_mh1g9y.jpg\"><br><br><br>\r\n\r\n<B>Note:</B> No syslog or error message will be seen when the hardware has power-up or boot-up issues.",
            "workaround": "The suspected DIMM can be traced by the serial number of the ASR 9000 Enhanced Ethernet line card or the ASR 9001 chassis. The failure symptoms for each issue are the same, and the time to failure for each issue is different. Therefore, each issue is listed separately. \r\n\r\nUse this table to check for Issue #1 and Issue #2 and take appropriate actions.\r\n\r\n<TABLE BORDER='1' CELLPADDING='0' CELLSPACING='2'><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Description</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Check</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Check output</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>User Action</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Issue #1</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'><a href=\"http://serialnumbervalidation.com/63604\"> Check Serial Number Validation Tool - Issue#1</a></FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Affected or Not Affected</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>If affected:\r\nStep 1: Check the Top Assembly Number in the Products Affected section.</br>\r\nStep2: Fix on Failure. Use Cisco standard RMA process for replacement request </br></br>\r\nIf not affected, a replacement is not required.</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Issue #2</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'><a href=\"http://serialnumbervalidation.com/63604a\"> Check the Serial Number Validation Tool - Issue#2</a></FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Affected or Not Affected</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>If affected:\r\nStep 1: Check the Top Assembly Number in the Products Affected section.</br>\r\nStep2: Fix on Failure. Use Cisco standard RMA process for replacement request. </br></br>\r\nIf not affected, a replacement is not required.</FONT></TD></TR></TABLE>\r\n\r\n<B>Note:</B> The Serial Number Validation Tool is updated periodically. Not all serial numbers are affected. Check the serial number and the TAN to determine if hardware is good or affected.\r\n\r\nThe customer Service Level Agreement (SLA) does not apply for field notice  replacement requests.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/636/fn63604.html"
        },
        {
            "fieldNoticeId": 63628,
            "status": "P",
            "bulletinLastUpdated": "2018-05-21T00:00:00Z",
            "bulletinTitle": "FN63628 - UCSB-PSU-2500ACPL Power Redundancy Failure - Replace on Failure",
            "bulletinFirstPublished": "2013-07-12T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "Certain Unified Computing System (UCS)B-Series chassis power supplies have an issue which can cause shutdown when activated in a redundancy switchover. Affected units can be identified by the version and serial number format. Replacement of affected power supplies is recommended.",
            "background": "Affected power supplies have an issue which causes a transient overvoltage on the 3.3v bus upon power-up of parallel units which causes a reset. If the other power supplies in the active set cannot handle the required current, they will also be shut down. The resultant effect is a failure of power redundancy. This issue affects only version 01 and 02 power supplies with the serial number prefix \"AZS\". A modification has been implemented which changes a resistor value to prevent the overvoltage event on the 3.3v bus.",
            "problemSymptoms": "There are no symptoms exhibited during normal operation. If an affected unit is part of a redundant set, the chassis might completely shut down when a switchover is made. The amber failure indicator will light on power supplies which reset due to either the 3.3v issue or to overcurrent because of adjacent power supply shutdown.",
            "workaround": "Affected units should be replaced. The special ordering process originally associated with this Field Notice has been discontinued. Please use standard RMA process for any needed replacements.See the How to Identify Hardware Levels section for instructions on how to determine if your power supply is affected by this issue.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": "Deviation number not automatically checked and would need to be manually verified.",
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/636/fn63628.html"
        },
        {
            "fieldNoticeId": 63646,
            "status": "P",
            "bulletinLastUpdated": "2017-11-15T00:00:00Z",
            "bulletinTitle": "FN63646 - A9K-MPA-20X1GE - MPAs Might Fail to Power Up in Some ASR 9001 Slot 0 - Replace on Failure",
            "bulletinFirstPublished": "2014-08-01T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "Some A9K-MPA-20X1GE Modular Port Adapters (MPAs) with lower mechanical tolerance might fail to boot in some Slot 0 Aggregation Services Router (ASR) 9001s in the installation process or after replacement with a Return Material Authorization (RMA).",
            "background": "Some A9K-MPA-20X1GE MPAs have lower mechanical tolerance. When they are inserted into the ASR 9001 chassis Slot 0, the EMI gasket gets pushed under pressure. This leads to the EMI gasket shorting with the LED circuit and shows up as an MPA failure.\r\n\r\nThis issue impacts A9K-MPA-20X1GE MPAs manufactured from 01/02/2012 to 12/07/2012.",
            "problemSymptoms": "The failure may manifest in two forms:\r\n<ul><li>The ASR 9000 MPA (20X1G) does not power up in Slot 0 in the ASR 9001 (the left side bay when viewed from the front).</li>\r\n<li>The status LED does not glow and the console displays error messages as shown in the highlighted text.\r\n\r\n<IMG SRC=\"http://www-tac.cisco.com/Support_Library/field_alerts/fn63646_mmkmy7.jpg\">\r\n</li></ul>\r\n\r\nSometimes if you tighten or back the MPA jack screw, it might help to power on the green or amber LED. In this case, if you enter the <b>platform</b> command from the console it shows that the MPA is OK.\r\n\r\nIf another MPA (4X10G or 2X10G) is placed in Slot 0 it should come up fine.",
            "workaround": "Cisco recommends a fix-on-fail strategy for this issue.\r\n\r\nAs of approximately 12/06/2012, new products that were manufactured under Engineering Change Order (ECO) E113786 are free of this issue. Refer to the How to Identify Hardware Levels section for instructions on how to view the version and deviation of in-service product.\r\n\r\nService Logistics has good inventory at this time. The standard RMA process and delivery times are in effect. Create an RMA for the A9K-MPA-20X1GE ONLY when the issue is observed. Once a MPA inserted in Slot 0 fails, the failure is permanent and the MPA might not work in Slot 1 and an RMA is required.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/636/fn63646.html"
        },
        {
            "fieldNoticeId": 63649,
            "status": "P",
            "bulletinLastUpdated": "2017-10-25T00:00:00Z",
            "bulletinTitle": "FN63649 - CP-7942G, CP-7962G - LCD Screen Might Black Out - Replace on Failure ",
            "bulletinFirstPublished": "2013-05-24T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "A low voltage regulator located inside the phone which powers the LCD screen might fail, which causes the LCD screen to black out. This can occur after an unknown period of time, from hours to months, and depends on the working environment of the phone.\r\n\r\nThis issue exists in a known set of serial numbers of a specific version of the phones as indicated in the Products Affected section. This means <strong>two conditions</strong> must exist in order for a phone to be exposed to this issue:\r\n1. The 68- partnumber matches what is documented in the Products Affected table in the column under 'Top Assembly' and 'Part #'.\r\n2. The serial number of a phone must be recognized by the <a href=\"http://serialnumbervalidation.com/63649\"  target=\"_blank\">Serial Number Validation Tool</a>. Refer to the How to Identify Hardware Levels section for more information. \r\n\r\nIf one or both are not true for a particular phone, then it is NOT at risk for this issue and no action is necessary.",
            "background": "Cisco uses multiple suppliers to source the low voltage regulator that powers the LCD screen of the phone. One supplier provided Cisco with a batch of regulators whose internal components were susceptible to early failure, and these regulators were installed in a small batch of phones built in December 2012 and January 2013.\r\n\r\nCisco has since stopped using that supplier's voltage regulator in the phones.",
            "problemSymptoms": "The phone LCD blacks out. This occurs after an unknown period of time, from hours to months, and depends on the working environment of the phone.",
            "workaround": "Use the HW Upgrade Form provided below to replace affected phones. The affected phones have the same 68- part number as shown in the Products Affected section and have a serial number that is found in the Serial Number Validation Tool.  \r\n\r\n<strong>Note:</strong> Service level agreements do not apply when using the included HW Upgrade Program.",
            "hardwareLevels": "",
            "upgradeProgram": "",
            "caveat": null,
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/636/fn63649.html"
        },
        {
            "fieldNoticeId": 63689,
            "status": "P",
            "bulletinLastUpdated": "2019-02-04T00:00:00Z",
            "bulletinTitle": "FN63689 - Certain ECU Cards Might Experience Insertion Problems When Inserting Into the M6 Chassis - Workaround Provided",
            "bulletinFirstPublished": "2013-09-24T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "In some situations, the insertion of the 15454-M6-ECU or 15454-M6-ECU2 unit in the M6 chassis might require additional force; therefore, the software might not detect the units, because the back-plane connector does not completely engage with the mate that is mounted on the M6 chassis.",
            "background": "Cards that are built between March, 2013 and August, 2013 use a back-plane connector that might require a higher insertion force due to production variability. Once properly inserted, these cards work and behave properly, so no further actions are required. Cards manufactured outside of this time-frame are not impacted by this Field Notice.",
            "problemSymptoms": "The insertion of the unit is completed easily up to 2 mm (1/10 of an inch) of the complete seating. From this point, additional force might be required for the proper mating of the back-plane connectors. If this additional force is not applied, the unit does not install properly, and the software does not detect it.",
            "workaround": "As a workaround, apply more force in order to plug the unit into the chassis. In order to perform a functional sanity check, connect an RJ45 Fast Ethernet cable to the RJ45 port of a PC (not under the same Network IP domain). If the green LED indicator illuminates, the card is correctly plugged-in.Here is a picture with a comparison between a partial insertion versus a complete insertion,",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/636/fn63689.html"
        },
        {
            "fieldNoticeId": 63697,
            "status": "P",
            "bulletinLastUpdated": "2020-07-17T00:00:00Z",
            "bulletinTitle": "FN63697 - Protective Boot on Certain Network Cables Might Push the Mode Button and Cause an Unexpected Reset on the 48-Port Models of Cisco Catalyst 3650 and 3850 Series Switches - Workaround Provided",
            "bulletinFirstPublished": "2013-10-25T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "Certain types of snagless Ethernet cables have protective boots that extend too far forward and above the plastic latching tab. When this type of cable is installed in Port 1 of any 48-port model of the Cisco Catalyst C3650 or C3850 Series switches, the boot might press and hold the Mode button, which invokes Express Setup and reboots the system. (Reference Figures 1 through 3 for illustrations of the issue.)Note: This type of boot-cable can partially obscure port LEDs, air vents, and USB ports.Figure 1. Problematic Cable before Complete InsertionFigure 2. Problematic Cable Completely InsertedFigure 3. Problematic Cable Completely Inserted (side view)",
            "background": "Snagless Ethernet cables were developed many years ago in order to protect the plastic latching tab from becoming snagged, bent, or broken. There are various ways to achieve this goal, but the most common is to hide the tab under a plastic shroud or boot.  Numerous types of snagless cables are available. However, most are designed in such a way that the protective device is less prominent and/or held more tightly to the tab, which prevents the aforementioned drawbacks.",
            "problemSymptoms": "When Express Setup is inadvertently invoked by the protective boot of the cable, these messages are seen in the syslog:%SYS-7-NV_BLOCK_INIT: Initialized the geometry of nvram%EXPRESS_SETUP-6-CONFIG_IS_RESET: The configuration is reset and the system will now reboot%SYS-5-RELOAD: Reload requested by NGWC led process. Reload Reason: Reload command.%STACKMGR-1-RELOAD_REQUEST: 1 stack-mgr:  Received reload request for all switches, reason Reload command %STACKMGR-1-RELOAD: 1 stack-mgr:  Reloading due to reason Reload command.After this occurs, the device resets. The startup configuration is erased once the device enters Express Setup.",
            "workaround": "There are three options used in order to address this problem:Use a snagless cable with a less-pronounced boot in Port 1.Trim the boot on the cable that is installed in Port 1.Disable Express Setup with this command while in config mode:3850(config)# no setup express",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": "Automation is only checking Product ID.  Additional details can be found in the Field Notice.",
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/636/fn63697.html"
        },
        {
            "fieldNoticeId": 63704,
            "status": "P",
            "bulletinLastUpdated": "2019-02-05T00:00:00Z",
            "bulletinTitle": "FN63704 - ASR1000 - ASR1000-RP2: Actual ACTV/STBY LED State is Incorrect - Software Upgrade Recommended",
            "bulletinFirstPublished": "2014-01-08T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "From early August 2013 until the middle of September 2013, the ASR1000-RP2s shipped to the field had an incorrect ACTV/STBY LED state. This issue is seen with the V04 RP2. Although the RP2 state is active, the STBY LED actually lights up.",
            "background": "On September 25, 2013, Cisco temporarily stopped shipment of ASR1000-RP2s due to the ASR1k-RP2 LED issue. The ACTV/STBY LED state is reversed. The affected ASR1000-RP2s were shipped to the field starting in August of 2013. In the ASR1004, the RP2 status LED shows the opposite of the current state. In the ASR1006 and ASR1013 with redundant RP2s, the active RP2 shows standby and standby RP2s show active.  Cisco implemented a fix in the complex programmable logic device (CPLD) image to flip the ACTV/STBY status. The new image was available to manufacturing on September 29, 2013.",
            "problemSymptoms": "The ASR1000-RP2&#39;s actual ACTV/STBY LED state is incorrect. Although the RP2 state is active, the STBY LED lights up. This issue is seen with use of the V04 RP2.  The steps to reproduce this issue are:  1. Insert the V04 RP2 into the ASR1000 chassis. 2. Wait until the RP2 has fully booted.  The active/standby LED is identified as shown in this picture:",
            "workaround": "Cisco provided a new CPLD image version 13092401 that reverses back the LEDs and is provided in the form of a Field Programmable Device (FPD) package. The FPD package is already published at Cisco.com.  Do not apply this firmware upgrade to nonaffected boards. The CPLD image should only be applied to V04 systems. The Serial Number Verification Tool should also be used to confirm the systems with this issue.  The upgrade instructions for an Active Cisco ASR1000-RP2 were taken from http://www.cisco.com/en/US/docs/routers/asr1000/cpld/hw_fp_upgrade.html and were adapted for this case.  Upgrade the Active Cisco ASR1000-RP2  Complete these steps in order to perform a Cisco ASR1000-RP2 CPLD field upgrade. In the example described in these steps, R0 is the active RP2. If R1 is the active route processor (RP), follow the same upgrade steps on R1.  1. Copy the hw-programmable upgrade package to your hard disk as follows: copy tftp:/...asr1000-hw-programmables.03.07.04a.S.152-4.S4a.pkg harddisk:  In order to download this package from Cisco.com, log in with your Cisco.com password to: http://software.cisco.com/download/special/release.html?config=bc06fb8000c378dd87d70cd77eb67ef6.  2. Upgrade the active Cisco ASR1000-RP2 CPLD with this command: Router# upgrade hw-programmable CPLD filename harddisk: asr1000-hw-programmables.03.07.04a.S.152-4.S4a.pkg R0  Upgrade the CPLD on the Route-Processor 0 from the current version 10021901 to version 13092401.  This upgrade could take up to 10 minutes to complete. Do not power cycle the unit or the linecard until the upgrade is complete (the hardware might be unrecoverable). This command also issues a reset to the linecard at the end of the upgrade.  3. The active Cisco ASR1000-RP2 CPLD firmware is upgraded successfully and you will receive this success message:  SYSTEM HAS SUCCESFULLY UPGRADED THE cpld hw-programmable on Route-Processor 0. PLEASE POWER CYCLE THE CHASSIS NOW.  4. Power cycle the chassis.  5. After the power cycle, the active RP reboots with the latest CPLD programmable firmware and comes online. ________________________________________  Upgrade the Standby Cisco ASR1000-RP2  Complete these steps in order to perform a Cisco ASR1000-RP2 CPLD field upgrade. In the example described in these steps, R1 is the standby RP. If R0 is the standby RP, follow the same upgrade steps on R0.  1. Copy the hw-programmable upgrade package to your hard disk as follows:  copy tftp:/...asr1000-hw-programmables.03.07.04a.S.152-4.S4a.pkg harddisk:  In order to download this package from Cisco.com, log in with your Cisco.com password to: http://software.cisco.com/download/special/release.html?config=bc06fb8000c378dd87d70cd77eb67ef6.  2. Upgrade the standby RP with this command: Router# upgrade hw-programmable CPLD filename harddisk: asr1000-hw-programmables.03.07.04a.S.152-4.S4a.pkg R1  Upgrade the CPLD on Route-Processor 1 from the current version 100201901 to version 13092401.  This upgrade could take up to 10 minutes to complete. Do not power cycle the unit or the linecard until the upgrade is complete (the hardware might be unrecoverable). This command also issues a reset to the linecard at the end of the upgrade.  Reload Route-Processor 1 to Start the Upgrade  3. The standby RP is powered up and the CPLD firmware on the standby RP is upgraded.  4. After the upgrade is successful, you receive this success message in the active RP:  Jul 16 16:03:02.354: %CMRP-3-FRU_HWPRG_UPG_SUCCESS: R0/0: cmand: Hardware programmable CPLD on ASR1000-RP2 in slot R1 was successfully programed. Card can now be powercycled.  5. The active RP power cycles the standby RP. The standby RP reboots with the latest CPLD programmable firmware and comes online.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": "Automation is matching on PID, VID and Serial Number.  Manual verification of LED issue and CPLD version is required.",
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/637/fn63704.html"
        },
        {
            "fieldNoticeId": 63722,
            "status": "P",
            "bulletinLastUpdated": "2019-02-04T00:00:00Z",
            "bulletinTitle": "FN63722 - Protective Boot on Certain Network Cables Might Push the Mode Button and Cause an Unexpected Reset on the 48-Port Models of Cisco Catalyst 3560X and 3750X Series Switches - Workaround Provided",
            "bulletinFirstPublished": "2014-01-21T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "Certain types of snagless Ethernet cables have protective boots that extend too far forward and above the plastic latching tab. When this type of cable is installed in Port 1 of any 48-port model of the Cisco Catalyst C3560X or C3750X Series switches, the boot might press and hold the Mode button, which invokes Express Setup and reboots the system. (Reference Figures 1 through 3 for illustrations of the issue.)Note: This type of boot-cable can partially obscure port LEDs, air vents, and USB ports. Figure 1. Problematic Cable before Complete InsertionFigure 2. Problematic Cable Completely InsertedFigure 3. Problematic Cable Completely Inserted (side view)",
            "background": "Snagless Ethernet cables were developed many years ago in order to protect the plastic latching tab from becoming snagged, bent, or broken. There are various ways to achieve this goal, but the most common is to hide the tab under a plastic shroud or boot. Numerous types of snagless cables are available. However, most are designed in such a way that the protective device is less prominent and/or held more tightly to the tab, which prevents the aforementioned drawbacks.",
            "problemSymptoms": "When Express Setup is inadvertently invoked by the protective boot of the cable, these messages are seen in the syslog: %SYS-7-NV_BLOCK_INIT: Initialized the geometry of nvram%SYS-5-RELOAD: Reload requested by Hulc LED Process. Reload Reason: Reason unspecified.After this occurs, the device resets. The startup configuration is erased once the device enters Express Setup.",
            "workaround": "There are three options used in order to address this problem: Use a snagless cable with a less-pronounced boot in Port 1.Trim the boot on the cable that is installed in Port 1.Disable Express Setup with this command while in config mode:3750(config)# no setup express",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": "Matching vulnerability is based on PID only. Additional manual verification may be required to check Protective Boot on Certain Network Cables.",
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/637/fn63722.html"
        },
        {
            "fieldNoticeId": 63723,
            "status": "P",
            "bulletinLastUpdated": "2019-03-05T00:00:00Z",
            "bulletinTitle": "FN63723 - CISCO39xx and VG350 Fans Might Fail Due to Capacitor Issue - Replace on Failure",
            "bulletinFirstPublished": "2016-05-13T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "One or more fans in a 39XX or VG350 fan tray might fail or run at less than design Revolutions Per Minute (RPM) criteria due to a component issue. Routers that experience this issue should be monitored for temperature alarms. Customer&#39;s routers might experience this issue and not be aware since temperature or low fan speed alarms might not be generated. Many platforms can operate for extended duration with fan alarms and not experience temperature alarms. Temperature alarms should be given higher precedence (versus fan low speed alarm) and immediate fan tray replacement is required. Fan service should be scheduled during the next available maintenance window, and the fan tray in the router should be replaced.",
            "background": "Some of the fans provided by a specific supplier might have a faulty capacitor. The capacitor might deteriorate over time and eventually fail, which causes a loss of fan speed control.",
            "problemSymptoms": "A capacitor failure (from a specific supplier) in a 39XX or VG350 fan might cause the fan to run at a slow speed. This might not trigger a fan failure alarm. If a fan alarm is not generated, the customer might receive a router over temperature alarm. In either case, the sho env table command should be executed in order to review what the actual fan speeds are in operation.Fan Failure AlarmThis messages repeats on the console if a fan failure alarm is generated:\"Dec 4 03:56:41.194: %ENVMON-4-ONE_FAN_LOW_RPM: Warning: Fan 2 is running at low RPM. Rotation speed is now high for all other fans. Fan Tray replacement is recommended.\"Note: There are five fans in the 3900 fan tray. For this message, Fan 1, Fan 2, Fan 3, Fan 4, or Fan 5 will be identified in the low RPM warning message. If multiple fans have failed, each fan that fails will be reported. It is possible for the low fan speed condition to oscillate in and out of the range of the threshold to trigger an alarm. With this behavior, the message might be generated erratically if the fan speed increases above the lower threshold limit.The sho env table command should be executed and the fan speeds reviewed. Output should look similar to this:SYSTEM FAN STATUS=================Fan 1 OK, fan level 5, High speed setting, 6656 RPM, 100% PWMFan 2 Low RPMFan 3 OK, fan level 5, High speed setting, 6744 RPM, 100% PWMFan 4 OK, fan level 5, High speed setting, 1646 RPM, 100% PWMFan 5 OK, fan level 5, High speed setting, 7105 RPM, 100% PWMFan 2 is reported in a low RPM and failed state. The other fans have been set to the maximum speed setting. Note that Fan 4 runs at a much lower fan speed than the other fans even though it has not raised an alarm. Fan 4 is actually not ok. Fan speeds shown in the output of the sho env table should be compared to the minimum fan speed settings shown in the table included in this section. If the fan speed reported for a specific level is less than the value shown in the table, the fan capacitor has failed.Temperature AlarmThese messages repeat on the console if an over temperature alarm is generated.3925/45 \"Jan 9 13:11:46.728: %ENVMON-2-CPU_CRITICAL_OVERTEMP: Critical: CPU temperature 127C exceeds 115C threshold. Please resolve system cooling immediately to prevent system damage.\"3925/45e \"ENVMON-1-CPU_CORE_WARNING_OVERTEMP Warning: CPU core is very hot value = 20. It exceeds threshold 24. Please resolve system cooling immediately to prevent system damage.\"The sho env table command should be executed and the fan speeds reviewed. Output should look similar to this:SYSTEM FAN STATUS=================Fan 1 OK, fan level 3, Medium speed setting, 592 RPM, 62% PWMFan 2 OK, fan level 3, Medium speed setting, 503 RPM, 62% PWMFan 3 OK, fan level 3, Medium speed setting, 760 RPM, 62% PWMFan 4 OK, fan level 3, Medium speed setting, 414 RPM, 62% PWMFan 5 OK, fan level 3, Medium speed setting, 5381 RPM, 62% PWMSpeeds for Fans 1 through 4 are very low while the speed for Fan 5 is normal. The fan speed level of 3 is set by the temperature of the intake air as measured by the router. The speeds for Fans 1 through 4 are low but are not low enough to generate a fan alarm for a low RPM condition. This means those fans are not ok. Fan speeds shown in the output of the sho env table should be compared to the minimum fan speed settings shown in the table. If the fan speed reported for a specific level is less than the value shown in the table, the fan capacitor has failed.39XX and VG350 Fan Speed Minimum ValuesFAN LEVELMINIMUM RPMLevel 12800Level 24000Level 35000Level 45500Level 56000",
            "workaround": "No workaround is available. The fan tray must be replaced via the attached Upgrade Program.Actions to Take- Determine if the 3900 router or its fan tray assembly is susceptible to this failure mechanism with the procedure shown in the \"How to Identify Hardware Levels\" section.- For routers or fan tray assemblies that are determined to be \"Affected\" or generate over temperature or fan fail alarms, query the router with the sho env table command in order to determine if the fans operate correctly and examine the fan speeds.- If any fan&#39;s RPM is less than the minimum value listed in the table, replace the fan tray.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/637/fn63723.html"
        },
        {
            "fieldNoticeId": 63734,
            "status": "P",
            "bulletinLastUpdated": "2019-02-04T00:00:00Z",
            "bulletinTitle": "FN63734 - WS-X4748-UPOE+E, WS-X4748-RJ45V+E, and WS-X4748-RJ45-E Linecards Might Not Function with Some Deferred Software Releases - Software Upgrade Recommended",
            "bulletinFirstPublished": "2014-05-19T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "WS-X4748-RJ45-E with Version ID (VID) 03 and later, WS-X4748-RJ45V+E VID 05 and later, and WS-X4748-UPOE+E with VID 03 and later do not function with some deferred software releases.",
            "background": "The linecards listed in the \"Products Affected\" section produced in mid-2014 and later are affected by this issue. See the \"How To Identify Hardware Levels\" section in order to determine if a linecard is affected. The software releases that no longer operate are these versions:-3.1.0SG-3.1.1SG-3.2.0XO-3.2.0SG-3.2.1SG-3.2.4SG-3.4.0SG",
            "problemSymptoms": "When linecards in the affected range are used with the software releases mentioned in the \"Background\" section, they are marked as \"unsupported\" and do not operate. See example output as shown here of a WS-X4748-RJ45V+E linecard that runs on an unsupported software Version 3.4.0SG.#show moduleChassis Type : WS-C4507R+EPower consumed by backplane : 40 WattsMod Ports Card Type                              Model              Serial No.---+-----+--------------------------------------+------------------+----------- 4     4  Sup 7-E 10GE (SFP+), 1000BaseX (SFP)   WS-X45-SUP7-E      CAT1409L007  5     0  Unsupported module                     WS-X4748-RJ45V+E   CAT1650L00N  M MAC addresses                    Hw  Fw           Sw               Status--+--------------------------------+---+------------+----------------+--------- 4 1cdf.0f0b.4a44 to 1cdf.0f0b.4a47 1.0 15.0(1r)SG(0 03.04.00.SG      Ok        5 0000.0000.0000 to 0000.0000.0000 1.3                               Unsupport",
            "workaround": "If any of the software releases mentioned previously (all of which are deferred) are used, the software release must be replaced with a different version in order to use the affected hardware. Any release other than those listed previously will work, which include Versions 3.2.nSG, 3.4.1SG and later, and all newer releases. Reference the Catalyst 4500 Series Switch Software Configuration Guide for instructions on how to perform a software upgrade.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": "Automation is matching PID and VID.  Manual verification of IOS release is required.",
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/637/fn63734.html"
        },
        {
            "fieldNoticeId": 63741,
            "status": "P",
            "bulletinLastUpdated": "2018-08-02T00:00:00Z",
            "bulletinTitle": "FN63741 - ASA 5500 Series Appliances - Some Appliances Might Fail to Boot Up after a Power Cycle - Replace on Failure",
            "bulletinFirstPublished": "2014-03-03T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "The Cisco Adaptive Security Appliance (ASA) 5500 series might fail to boot up after a power cycle operation.",
            "background": "Cisco has been working with some customers on an issue related to memory components manufactured by a single supplier between 2005 and 2010. These memory components are widely used across the industry and are included in a number of Cisco products.Although the majority of Cisco products using these components are experiencing field failure rates below expected levels, some components may fail earlier than anticipated. A handful of our customers have recently experienced a higher number of failures, leading us to change our approach to managing this issue.While other vendors have chosen to address this issue in different ways, Cisco believes its approach is the best course of action for its customers. Despite the cost, we are demonstrating that we always make customer satisfaction a top priority. Customers can learn more about this topic at our Memory Component Issue web page.PLEASE NOTE: The products listed in this Field Notice have lower than expected failure rates. This assessment is based on actual usage of affected memory components, observed field failure rates, and product replacements since 2012.A degraded component will not affect the ongoing operation of a device, but will be exposed by a subsequent power cycle event. This event will result in a hard failure of the device, which cannot be recovered by a reboot or additional power cycle. For these reasons, additional caution is recommended for operational activities requiring the simultaneous power cycling of multiple devices. This issue has been observed most commonly on devices that have been in service for 24 months or more.",
            "problemSymptoms": "If the suspected hardware has been in operation for approximately 24 months, the product hardware might fail to boot up due to memory failure during a power cycle event. This is caused by one or more of these actions:-Power up after installation-Recover from a power outageNote: This issue does not affect ASA 5500 Series appliances while they are in operation. The appliance failure might occur after one or more of the actions listed are executed.",
            "workaround": "Normal SmartNet and warranty entitlement rules remain in place and are applied by the Cisco Technical Assistance Center (TAC) if you experience a failure in one of the products listed in the Field Notice. In other circumstances, such as out of warranty or out of contract, Cisco encourages you to raise your concern directly with your Cisco account team.Fix on Failure Replacement Guidelines: Request Return Material Authorization (RMA) product through normal service support channels. PIDActionPID ReplacementQuantityASA5510Replace memory moduleASA5510-MEM-1GB=1ASA5520Replace memory moduleASA5520-MEM-2GB=1ASA5540Replace memory moduleASA5540-MEM-2GB=1ASA5550Replace memory moduleASA5540-MEM-2GB=2ASA-SSM-AIP-10-K9Replace SSM cardASA-SSM-AIP-10-K9=1ASA-SSM-AIP-20-K9Replace SSM cardASA-SSM-AIP-20-K9=1ASA-SSM-CSC-10-K9Replace SSM cardASA-SSM-CSC-10-K9=1ASA-SSM-CSC-20-K9Replace SSM cardASA-SSM-CSC-20-K9=1Please refer to the Cisco ASA 5500 Series - Maintenance and Upgrade Procedures for instructions on how to replace the memory modules in the ASA 5500 Series appliances.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/637/fn63741.html"
        },
        {
            "fieldNoticeId": 63742,
            "status": "P",
            "bulletinLastUpdated": "2018-08-23T00:00:00Z",
            "bulletinTitle": "FN63742 - ASA 5505 Series Appliances - Some Appliances Might Fail to Boot Up After a Power Cycle - Replace on Failure",
            "bulletinFirstPublished": "2014-03-03T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "The Adaptive Security Appliance (ASA) 5505 might fail to boot up after a power cycle operation.",
            "background": "Cisco has been working with some customers on an issue related to memory components manufactured by a single supplier between 2005 and 2010. These memory components are widely used across the industry and are included in a number of Cisco products.Although the majority of Cisco products using these components are experiencing field failure rates below expected levels, some components may fail earlier than anticipated. A handful of our customers have recently experienced a higher number of failures, leading us to change our approach to managing this issue.While other vendors have chosen to address this issue in different ways, Cisco believes its approach is the best course of action for its customers. Despite the cost, we are demonstrating that we always make customer satisfaction a top priority. Customers can learn more about this topic at Memory Component Issue web page.PLEASE NOTE: The products listed in this Field Notice have lower than expected failure rates. This assessment is based on actual usage of affected memory components, observed field failure rates and product replacements since 2012.A degraded component will not affect the ongoing operation of a device, but will be exposed by a subsequent power cycle event. This event will result in a hard failure of the device, which cannot be recovered by a reboot or additional power cycle. For these reasons, additional caution is recommended for operational activities requiring the simultaneous power cycling of multiple devices. This issue has been observed most commonly on devices that have been in service for 24 months or more.",
            "problemSymptoms": "If the suspected hardware has been in operation for approximately 24 months, the appliance might fail to boot up due to memory failure during a power cycle event. This is caused by one of more of these actions:-Power up after installation-Recover from a power outageNote: This issue does not affect the ASA 5505 while in operation. The appliance failure might occur after one or more of the actions listed is executed.",
            "workaround": "Normal SmartNet and warranty entitlement rules remain in place and are applied by the Cisco Technical Assistance Center (TAC) if you experience a failure in one of the products listed in the Field Notice. In other circumstances, such as out of warranty or out of contract, Cisco encourages you to raise your concern directly with your Cisco account team.Fix on Failure Replacement Guidelines: Request Return Material Authorization (RMA) product through normal service support channels.PIDActionPID ReplacementQuantityASA5505Replace memory moduleASA5505-MEM-512=1ASA-SSC-AIP-5-K9Replace SSC cardASA-SSC-AIP-5-K9=1Refer to Cisco ASA 5505 Memory Upgrade Procedure video for instructions on how to replace the memory module in the ASA 5505 appliance.Note: The operating configuration is not affected when the memory module is replaced.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": "Automation doesn't support identifying memory DIMMs.  Automation is matching only on PID.  See Field Notice for additional manual checks.",
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/637/fn63742.html"
        },
        {
            "fieldNoticeId": 63743,
            "status": "P",
            "bulletinLastUpdated": "2018-08-23T00:00:00Z",
            "bulletinTitle": "FN63743 - Catalyst 6500 - Might Fail to Boot Up After a Software Upgrade or Power Cycle - Replace on Failure",
            "bulletinFirstPublished": "2014-03-03T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "Some Catalyst 6500 supervisors and linecards might fail to boot up after a software upgrade or other user actions where the board requires a power cycle operation.",
            "background": "Cisco has been working with some customers on an issue related to memory components manufactured by a single supplier between 2005 and 2010. These memory components are widely used across the industry and are included in a number of Cisco products.Although the majority of Cisco products using these components are experiencing field failure rates below expected levels, some components may fail earlier than anticipated. A handful of our customers have recently experienced a higher number of failures, leading us to change our approach to managing this issue.While other vendors have chosen to address this issue in different ways, Cisco believes its approach is the best course of action for its customers. Despite the cost, we are demonstrating that we always make customer satisfaction a top priority. Customers can learn more about this topic at Memory Component Issue web page.A degraded component will not affect the ongoing operation of a device, but will be exposed by a subsequent power cycle event. This event will result in a hard failure of the device, which cannot be recovered by a reboot or additional power cycle. For these reasons, additional caution is recommended for operational activities requiring the simultaneous power cycling of multiple devices. This issue has been observed most commonly on devices that have been in service for 24 months or more.",
            "problemSymptoms": "If the suspected Catalyst 6500 supervisor, linecard,  or fixed configuration hardware has been in operation for approximately 24 months, the product hardware might fail to boot up due to memory failure during a power cycle event. This is caused by one or more of these actions: - Upgrade the software - Reload entire product - Reload after Installation- Chassis power cycle - Online Insertion Removal/Replacement (OIR)Note: This issue does not affect boards while the boards are in operation. The board failure might occur after one or more of the actions listed are executed. For the affected Catalyst 6500 hardware, no error messages are common in all situations.  If error messages are seen, they might have these characteristics.----------------------------------------------------------------------------------------------------------------- Here is an example of an error message seen when a memory module has failed on the baseboard of a 6700 linecard:%ONLINE-SP-6-TIMER: Module *module number*, Proc. 0. Failed to bring onlinebecause of timer event%C6KPWR-SP-4-DISABLED: power to module in slot *slot number* set off(Module Failed SCP dnld)%ONLINE-SP-6-REGN_TIMER: Module *module number*, Proc. 0. Failed tobring online because of registration timer event%C6KPWR-SP-4-DISABLED: power to module in slot *slot number* set off(Module Failed SCP dnld)----------------------------------------------------------------------------------------------------------------- Here is an example of an error message seen when a memory module has failed on a DFC daughter card:%EARL-SP-2-PATCH_INVOCATION_LIMIT: 10 Recovery patch invocations in the last30 secs have been attempted. Max limit reached %EARL-SW1_SP-2-PATCH_INVOCATION_LIMIT: 10 Recovery patch invocations in the last 30 secs have been attempted. Max limit reached%EARL-SW2_SP-2-PATCH_INVOCATION_LIMIT: 10 Recovery patch invocations in thelast 30 secs have been attempted. Max limit reached ----------------------------------------------------------------------------------------------------------------- Here is an example of an error message seen on a Supervisor 720 when a memory module has failed on a Policy Feature Card (PFC) daughter card:%CONST_DIAG-SP-3-HM_TEST_FAIL: Module *module number* TestSPRPInbandPingconsecutive failure count:5 %CONST_DIAG-SP-4-HM_TEST_WARNING: Sup switchover will occur after 10consecutive failures%CONST_DIAG-SP-3-HM_TEST_FAIL: Module *module number* TestSPRPInbandPingconsecutive failure count:10 %CONST_DIAG-SP-2-HM_SUP_SWOVER: Supervisor card switchover due to unrecoverableerrors, Reason: Failed TestSPRPInbandPin-----------------------------------------------------------------------------------------------------------------Example of first of two possible error messages seen on a ME-C6524 when a memory module has failed:%DIAG-SP-3-MINOR: Module 1: Online Diagnostics detected a Minor Error. Pleaseuse 'show diagnostic result' to see test results.%CONST_DIAG-SP-3-BOOTUP_TEST_FAIL: Module 1: TestLoopback failed on port(s) 1-12%CONST_DIAG-SP-3-BOOTUP_TEST_FAIL: Module 1: TestProtocolMatchChannel failed%PM-SP-4-ERR_DISABLE: diagnostics error detected on Gi1/3, putting Gi1/3 inerr-disable state%PM-SP-4-ERR_DISABLE: diagnostics error detected on Gi1/4, putting Gi1/4 inerr-disable state%PM-SP-4-ERR_DISABLE: diagnostics error detected on Gi1/6, putting Gi1/6 inerr-disable state%PM-SP-4-ERR_DISABLE: diagnostics error detected on Gi1/7, putting Gi1/7 inerr-disable state%PM-SP-4-ERR_DISABLE: diagnostics error detected on Gi1/12, putting Gi1/12 inerr-disable state%OIR-SP-6-INSCARD: Card inserted in slot 1, interfaces are now online-----------------------------------------------------------------------------------------------------------------Example of second of two possible error messages seen on a ME-C6524 when a memory module has failed:IPC: Message 7C2EECD8 timed out waiting for AckIPC: MSG: ptr: 0x7C2EECD8, flags: 0x24100, retries: 21, seq: 0x102FC, refcount:2, rpc_result = 0x0, data_buffer= 0x6C8A61E8, header = 0xB83D0B0, data = 0xB83D0D0  HDR: src: 0x2210000, dst:0x10012, index: 0, seq: 764, sz: 28, type: 883, flags: 0x400, ext_flags: 0x0, hi: 0xA3D, lo: 0xB83D0D0  DATA: 02 F9 00 00 00 02 0000 00 02 00 10 D6 A8 B0 B2 97 8D 51 80 00 00 00 0?4 00 00 00 00%DUMPER-3-CRASHINFO_FILE_NAME: 12313: Crashinfo for process sbin/ios-base atbootflash:/crashinfo_ios-base-20140214-?151819%SYSMGR-3-ABNORMTERM: ios-base:1 (jid 76) abnormally terminated, restart disabled%SYSMGR-6-ERROR_EOK: ios-base:1 (jid 76) mandatory process exited, rebooting",
            "workaround": "Normal SmartNet and warranty entitlement rules remain in place and are applied by the Cisco Technical Assistance Center (TAC) if you experience a failure in one of the products listed in the Field Notice. In other circumstances, such as out of warranty or out of contract, Cisco encourages you to raise your concern directly with your Cisco account team. Fix on Failure Replacement Guidelines: Request Return Material Authorization (RMA) product through normal service support channels.If you need assistance in order to determine which hardware part(s) might need replacement, consult the error messages documented in the Problem Symptom section.For assistance with replacement part disposition, reference this table.  In cases where replacing the memory DIMM and/or daughter card is not a viable option, a request may be made to replace the entire card.Refer to this documentation for assistance on memory modules replacement:Memory Guidance for Cisco Catalyst 6500 Series Switches Catalyst 6500 Series DFC Memory Installation Note*The daughter card memory exposure is soldered memory; therefore, only the daughter card must be replaced in order to address exposure issues. Some daughter cards ship with memory DIMMs for the linecard baseboard as a part of the Cisco default packaging. It is not necessary for these DIMMs to be replaced unless there is exposure on the respective linecard baseboard as well.End of Support:PIDEnd of Support NoticeEnd of Support DateWS-SUP720EOL631717-DEC-2014WS-SUP720=EOL631717-DEC-2014WS-F6K-PISAEOL905730-SEP-2015",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": "Automation doesn't support identifying memory DIMMs.  Automation is matching only on PID.  See Field Notice for additional details.",
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/637/fn63743.html"
        },
        {
            "fieldNoticeId": 63744,
            "status": "P",
            "bulletinLastUpdated": "2018-08-23T00:00:00Z",
            "bulletinTitle": "FN63744 - Cat2K Might Fail to Boot After a Power Cycle - Replace on Failure",
            "bulletinFirstPublished": "2014-03-03T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "The Cisco Catalyst 2000 Series (CAT2K) switches (listed in the Products Affected section) might fail to boot up after the unit experiences a power cycle operation.",
            "background": "Cisco has been working with some customers on an issue related to memory components manufactured by a single supplier between 2005 and 2010. These memory components are widely used across the industry and are included in a number of Cisco products.Although the majority of Cisco products using these components are experiencing field failure rates below expected levels, some components may fail earlier than anticipated. A handful of our customers have recently experienced a higher number of failures, leading us to change our approach to managing this issue.While other vendors have chosen to address this issue in different ways, Cisco believes its approach is the best course of action for its customers. Despite the cost, we are demonstrating that we always make customer satisfaction a top priority. Customers can learn more about this topic at the Memory Component Issue web page.PLEASE NOTE - The products listed in this Field Notice have lower than expected failure rates. This assessment is based on actual usage of affected memory components, observed field failure rates and product replacements since 2012.A degraded component will not affect the ongoing operation of a device, but will be exposed by a subsequent power cycle event. This event will result in a hard failure of the device, which cannot be recovered by a reboot or additional power cycle. For these reasons, additional caution is recommended for operational activities requiring the simultaneous power cycling of multiple devices. This issue has been observed most commonly on devices that have been in service for 24 months or more.",
            "problemSymptoms": "If the affected hardware (listed in the Products Affected section) has been in continuous operation for approximately 24 months, then the hardware might fail to boot up due to memory failure during a power cycle event.This occurs when power is removed and reapplied to the switch (the switch is power cycled).Note: This issue does not affect switches while they are in operation. The switch failure might occur after the switch is power cycled.The failure symptom is observed when the switch fails to boot up with no console response (no characters are written to the console).",
            "workaround": "Normal SmartNet and warranty entitlement rules remain in place and are applied by the Cisco Technical Assistance Center (TAC) if you experience a failure in one of the products listed in the Field Notice. In other circumstances, such as out of warranty or out of contract, Cisco encourages you to raise your concern directly with your Cisco account team. Fix on Failure Replacement Guidelines: Request Return Material Authorization (RMA) product through normal service support channels.Please refer to this table for the appropriate Product ID replacement:Affected PIDActionReplacement PIDQuantityWS-C2350-48TD-SReplace UnitWS-C4948E, PWR-C49E-300AC-R1 EachWS-C2350-48TD-SDReplace UnitWS-C4948E, PWR-C49-300DC1 EachWS-C2918-24TC-CReplace UnitWS-C2918-24TC-C1WS-C2918-24TT-CReplace UnitWS-C2918-24TT-C1WS-C2918-48TC-CReplace UnitWS-C2918-48TC-C1WS-C2918-48TT-CReplace UnitWS-C2918-48TT-C1WS-C2960-24LC-SReplace UnitWS-C2960+24LC-S1WS-C2960-24LT-LReplace UnitWS-C2960+24LC-L1WS-C2960-24PC-LReplace UnitWS-C2960+24PC-L1WS-C2960-24PC-SReplace UnitWS-C2960+24PC-S1WS-C2960-24-SReplace UnitWS-C2960+24TC-S1WS-C2960-24TC-LReplace UnitWS-C2960+24TC-L1WS-C2960-24TC-SReplace UnitWS-C2960+24TC-S1WS-C2960-24TT-LReplace UnitWS-C2960+24TC-L1WS-C2960-48PST-LReplace UnitWS-C2960+48PST-L1WS-C2960-48PST-SReplace UnitWS-C2960+48PST-S1WS-C2960-48TC-LReplace UnitWS-C2960+48TC-L1WS-C2960-48TC-SReplace UnitWS-C2960+48TC-S1WS-C2960-48TT-LReplace UnitWS-C2960+48TC-L1WS-C2960-48TT-SReplace UnitWS-C2960+48TC-S1WS-C2960-8TC-LReplace UnitWS-C2960C-8TC-L1WS-C2960-8TC-SReplace UnitWS-C2960C-8TC-S1WS-C2960G-24TC-LReplace UnitWS-C2960X-24TS-L1WS-C2960G-48TC-LReplace UnitWS-C2960X-48TS-L1WS-C2960G-8TC-LReplace UnitWS-C2960CG-8TC-L1WS-C2975GS-48PS-L  Replace UnitWS-C2975GS-48PS-L 1WS-C2960PD-8TT-L Replace UnitWS-C2960CPD-8TT-L1Please note that following PIDs in the above table are now End of SupportEnd of Support PIDsEnd of Support NoticeEnd of Support DateWS-C2350-48TD-SEOL737831-July-2016WS-C2350-48TD-SDEOL737831-July-2016",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": "Automation is matching only on PID.  See Field Notice for additional manual checks.",
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/637/fn63744.html"
        },
        {
            "fieldNoticeId": 63745,
            "status": "P",
            "bulletinLastUpdated": "2019-10-25T00:00:00Z",
            "bulletinTitle": "FN63745 - Cat3K Might Fail to Boot After a Power Cycle - Replace on Failure",
            "bulletinFirstPublished": "2014-03-03T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "The Cisco Catalyst 3000 Series (CAT3K) switches (listed in the Products Affected section) might fail to boot up after the unit experiences a power cycle operation.",
            "background": "Cisco has been working with some customers on an issue related to memory components manufactured by a single supplier between 2005 and 2010. These memory components are widely used across the industry and are included in a number of Cisco products.\r\n\r\nAlthough the majority of Cisco products using these components are experiencing field failure rates below expected levels, some components may fail earlier than anticipated. A handful of our customers have recently experienced a higher number of failures, leading us to change our approach to managing this issue.\r\n\r\nWhile other vendors have chosen to address this issue in different ways, Cisco believes its approach is the best course of action for its customers. Despite the cost, we are demonstrating that we always make customer satisfaction a top priority. Customers can learn more about this topic at the <a href=\"www.cisco.com/go/memory\">Memory Component Issue</a> web page.\r\n\r\nPLEASE NOTE - The products listed in this Field Notice have lower than expected failure rates. This assessment is based on actual usage of affected memory components, observed field failure rates and product replacements since 2012.\r\n\r\nA degraded component will not affect the ongoing operation of a device, but will be exposed by a subsequent power cycle event. This event will result in a hard failure of the device, which cannot be recovered by a reboot or additional power cycle. For these reasons, additional caution is recommended for operational activities requiring the simultaneous power cycling of multiple devices. This issue has been observed most commonly on devices that have been in service for 24 months or more.",
            "problemSymptoms": "If the affected hardware (listed in the Products Affected section) has been in continuous operation for approximately 24 months, then the hardware might fail to boot up due to memory failure during a power cycle event.\r\n\r\nThis occurs when power is removed and reapplied to the switch (the switch is power cycled).\r\n\r\n<b>Note:</b> This issue does not affect switches while they are in operation. The switch failure might occur after the switch is power cycled.\r\n\r\nThe failure symptom is observed when the switch fails to boot up with no console response (no characters are written to the console).",
            "workaround": "Normal SmartNet and warranty entitlement rules remain in place and are applied by the Cisco Technical Assistance Center (TAC) if you experience a failure in one of the products listed in the Field Notice. In other circumstances, such as out of warranty or out of contract, Cisco encourages you to raise your concern directly with your Cisco account team.Fix on Failure Replacement Guidelines: Request Return Material Authorization (RMA) product through normal service support channels.If you need assistance in order to determine which hardware part(s) might need replacement, consult the error messages documented in the Problem Symptom section.When you introduce a unit to a stack and create a mixed stack, reference this table and ensure the minimum software version is loaded on each switch to support the mixed stack.Refer to this table for the appropriate Product ID replacement:Affected PIDActionReplacement PIDQuantityWS-C3560-12PC-SReplace unitWS-C3560C-12PC-S1WS-C3560-24PS-EReplace unitWS-C3560V2-24PS-E1WS-C3560-24PS-SReplace unitWS-C3560V2-24PS-S1WS-C3560-24TS-EReplace unitWS-C3560V2-2>1WS-C3560-24TS-SReplace unitWS-C3560V2-24TS-S1WS-C3560-48PS-EReplace unitWS-C3560V2-48PS-E1WS-C3560-48PS-SReplace unitWS-C3560V2-48PS-S1WS-C3560-48TS-EReplace unitWS-C3560V2-48TS-E1WS-C3560-48TS-SReplace unitWS-C3560V2-48TS-S1WS-C3560-8PC-SReplace unitWS-C3560C-8PC-S1WS-C3560E-12D-E(=)Replace unitWS-C4500X-16SFP+ and C4KX-PWR-750AC-R=1 eachWS-C3560E-12D-S(=)Replace unitWS-C4500X-16SFP+ and C4KX-PWR-750AC-R=1 eachWS-C3560E-12SD-E(=)Replace unitWS-C3750X-12S-E and C3KX-NM-10G=1 eachWS-C3560E-12SD-S(=)Replace unitWS-C3750X-12S-S and C3KX-NM-10G=1 eachWS-C3560E-24PD-EReplace unitWS-C3560X-24P-E and C3KX-NM-10G=1 eachWS-C3560E-24PD-SReplace unitWS-C3560X-24P-S and C3KX-NM-10G=1 eachWS-C3560E-24TD-EReplace unitWS-C3560X-24T-E and C3KX-NM-10G=1 eachWS-C3560E-24TD-SReplace unitWS-C3560X-24T-S and C3KX-NM-10G=1 eachWS-C3560E-24TD-SDReplace unitWS-C3560X-24T-S, C3KX-PWR-440WDC= and C3KX-NM-10G=1 eachWS-C3560E-48PD-EReplace unitWS-C3560X-48P-E and C3KX-NM-10G=1 eachWS-C3560E-48PD-EFReplace unit>WS-C3560X-48P-E and C3KX-NM-10G=1 eachWS-C3560E-48PD-SReplace unitWS-C3560X-48P-S and C3KX-NM-10G=1 eachWS-C3560E-48PD-SFReplace unitWS-C3560X-48P-S and C3KX-NM-10G=1 eachWS-C3560E-48TD-EReplace unitWS-C3560X-48T-E and C3KX-NM-10G=1 eachWS-C3560E-48TD-SReplace unitWS-C3560X-48T-S and C3KX-NM-10G=1 eachWS-C3560E-48TD-SDReplace unitWS-C3560X-48T-S, C3KX-PWR-440WDC= and C3KX-NM-10G=1 eachWS-C3560G-24PS-EReplace unitWS-C3560X-24P-E and C3KX-NM-1G=1 eachWS-C3560G-24PS-SReplace unitWS-C3560X-24P-S and C3KX-NM-1G=1 eachWS-C3560G-24TS-EReplace unitWS-C3560X-24T-E and C3KX-NM-1G=1 eachWS-C3560G-24TS-SReplace unitWS-C3560X-24T-S and C3KX-NM-1G=1 eachWS-C3560G-48PS-EReplace unitWS-C3560X-48P-E and C3KX-NM-1G=1 eachWS-C3560G-48PS-SReplace unitWS-C3560X-48P-S and C3KX-NM-1G=1 eachWS-C3560G-48TS-EReplace unitWS-C3560X-48T-E and C3KX-NM-1G=1 eachWS-C3560G-48TS-SReplace unitWS-C3560X-48T-S and C3KX-NM-1G=1 eachWS-C3560V2-24PS-EReplace unitWS-C3560V2-24PS-E1WS-C3560V2-24PS-SReplace unitWS-C3560V2-24PS-S1WS-C3560V2-24TS-EReplace unitWS-C3560V2-24TS-E1>WS-C3560V2-24TS-SReplace unitWS-C3560V2-24TS-S1WS-C3560V2-24TS-SDReplace unitWS-C3560V2-24TS-SD1WS-C3560V2-48PS-EReplace unitWS-C3560V2-48PS-E1WS-C3560V2-48PS-SReplace unitWS-C3560V2-48PS-S1WS-C3560V2-48TS-EReplace unitWS-C3560V2-48TS-E1WS-C3560V2-48TS-SReplace unitWS-C3560V2-48TS-S1WS-C3560X-48PF-SReplace unitWS-C3560X-48PF-S1WS-C3750-24FS-SReplace unitWS-C3750V2-24FS-S1WS-C3750-24PS-EReplace unitWSC3750V2-24PS-E1WS-C3750-24PS-SReplace unitWS-C3750V2-24PS-S1WS-C3750-24TS-EReplace unitWS-C3750V2-24TS-E1WS-C3750-24TS-SReplace unitWS-C3750V2-24TS-S1WS-C3750-48PS-EReplace unitWS-C3750V2-48PS-E1WS-C3750-48PS-SReplace unitWS-C3750V2-48PS-S1WS-C3750-48TS-EReplace unitWS-C3750V2-48TS-E1WS-C3750-48TS-SReplace unitWS-C3750V2-48TS-S1WS-C3750E-24PD-EReplace unitWS-C3750X-24P-E and C3KX-NM-10G=1 eachWS-C3750E-24PD-SReplace unitWS-C3750X-24P-S and C3>1 eachWS-C3750E-24TD-EReplace unitWS-C3750X-24T-E and C3KX-NM-10G=1 eachWS-C3750E-24TD-SReplace unitWS-C3750X-24T-S and C3KX-NM-10G=1 eachWS-C3750E-24TD-SDReplace unitWS-C3750X-24T-S, C3KX-PWR-440WDC= and C3KX-NM-10G=1 eachWS-C3750E-48PD-EReplace unitWS-C3750X-48P-E and C3KX-NM-10G=1 eachWS-C3750E-48PD-EFReplace unitWS-C3750X-48P-E and C3KX-NM-10G=1 eachWS-C3750E-48PD-SReplace unitWS-C3750X-48P-S and C3KX-NM-10G=1 eachWS-C3750E-48PD-SFReplace unitWS-C3750X-48PF-S and C3KX-NM-10G=1 eachWS-C3750E-48TD-EReplace unitWS-C3750X-48T-E and C3KX-NM-10G=1 eachWS-C3750E-48TD-SReplace unitWS-C3750X-48T-S and C3KX-NM-10G=1 eachWS-C3750E-48TD-SDReplace unitWS-C3750X-48T-S, C3KX-PWR-440WDC= and C3KX-NM-10G=1 eachWS-C3750G-12S-EReplace unitWS-C3750X-12S-E1WS-C3750G-12S-SReplace unitWS-C3750X-12S-S1WS-C3750G-12S-SDReplace unitWS-C3750X-12S-S and C3KX-PWR-440WDC=1 eachWS-C3750G-24PS-EReplace unitWS-C3750X-24P-E and C3KX-NM-1G=1 eachWS-C3750G-24PS-SReplace unitWS-C3750X-24P-S and C3KX-NM-1G=1 eachWS-C3750G-24T-EReplace unitWS-C3750X-24T-E1WS->Replace unitWS-C3750X-24T-S1WS-C3750G-24TS-E1UReplace unitWS-C3750X-24T-E and C3KX-NM-1G=1 eachWS-C3750G-24TS-S1UReplace unitWS-C3750X-24T-S and C3KX-NM-1G=1 eachWS-C3750G-48PS-EReplace unitWS-C3750X-48P-E and C3KX-NM-1G=1 eachWS-C3750G-48PS-SReplace unitWS-C3750X-48P-S and C3KX-NM-1G=1 eachWS-C3750G-48TS-EReplace unitWS-C3750X-48T-E and C3KX-NM-1G=1 eachWS-C3750G-48TS-SReplace unitWS-C3750X-48T-S and C3KX-NM-1G=1 eachWS-C3750V2-24PS-EReplace unitWS-C3750V2-24PS-E1WS-C3750V2-24PS-SReplace unitWS-C3750V2-24PS-S1WS-C3750V2-24TS-EReplace unitWS-C3750V2-24TS-E1WS-C3750V2-24TS-SReplace unitWS-C3750V2-24TS-S1WS-C3750V2-48PS-EReplace unitWS-C3750V2-48PS-E1WS-C3750V2-48PS-SReplace unitWS-C3750V2-48PS-S1WS-C3750V2-48TS-EReplace unitWS-C3750V2-48TS-E1WS-C3750V2-48TS-SReplace unitWS-C3750V2-48TS-S1 Product IDEnd of Life NoticeEnd of Sale DateLast Date of SupportWS-C3560-24PS-EEnd-of-Sale and End-of-Life Announcement for the Cisco Catalyst 3750 24- and 48-Port 10/100, 3560 24- and 48-Port 10/100 Switches2010-Jul-052015-Jul-31WS-C3560-24PS-SEnd-of-Sale and End-of-Life Announcement for the Cisco Catalyst 3750 24- and 48-Port 10/100, 3560 24- and 48-Port 10/100 Switches2010-Jul-052015-Jul-31WS-C3560-24TS-EEnd-of-Sale and End-of-Life Announcement for the Cisco Catalyst 3750 24- and 48-Port 10/100, 3560 24- and 48-Port 10/100 Switches2010-Jul-052015-Jul-31WS-C3560-24TS-SEnd-of-Sale and End-of-Life Announcement for the Cisco Catalyst 3750 24- and 48-Port 10/100, 3560 24- and 48-Port 10/100 Switches2010-Jul-052015-Jul-31WS-C3560-48PS-EEnd-of-Sale and End-of-Life Announcement for the Cisco Catalyst 3750 24- and 48-Port 10/100, 3560 24- and 48-Port 10/100 Switches2010-Jul-052015-Jul-31WS-C3560-48PS-SEnd-of-Sale and End-of-Life Announcement for the Cisco Catalyst 3750 24- and 48-Port 10/100, 3560 24- and 48-Port 10/100 Switches2010-Jul-052015-Jul-31WS-C3560-48TS-EEnd-of-Sale and End-of-Life Announcement for the Cisco Catalyst 3750 24- and 48-Port 10/100, 3560 24- and 48-Port 10/100 Switches2010-Jul-052015-Jul-31WS-C3560-48TS-SEnd-of-Sale and End-of-Life Announcement for the Cisco Catalyst 3750 24- and 48-Port 10/100, 3560 24- and 48-Port 10/100 Switches2010-Jul-052015-Jul-31WS-C3750-24PS-EEnd-of-Sale and End-of-Life Announcement for the Cisco Catalyst 3750 24- and 48-Port 10/100, 3560 24- and 48-Port 10/100 Switches2010-Jul-052015-Jul-31WS-C3750-24PS-SEnd-of-Sale and End-of-Life Announcement for the Cisco Catalyst 3750 24- and 48-Port 10/100, 3560 24- and 48-Port 10/100 Switches2010-Jul-052015-Jul-31WS-C3750-24TS-EEnd-of-Sale and End-of-Life Announcement for the Cisco Catalyst 3750 24- and 48-Port 10/100, 3560 24- and 48-Port 10/100 Switches2010-Jul-052015-Jul-31WS-C3750-24TS-SEnd-of-Sale and End-of-Life Announcement for the Cisco Catalyst 3750 24- and 48-Port 10/100, 3560 24- and 48-Port 10/100 Switches2010-Jul-052015-Jul-31WS-C3750-48PS-EEnd-of-Sale and End-of-Life Announcement for the Cisco Catalyst 3750 24- and 48-Port 10/100, 3560 24- and 48-Port 10/100 Switches2010-Jul-052015-Jul-31WS-C3750-48PS-SEnd-of-Sale and End-of-Life Announcement for the Cisco Catalyst 3750 24- and 48-Port 10/100, 3560 24- and 48-Port 10/100 Switches2010-Jul-052015-Jul-31WS-C3750-48TS-EEnd-of-Sale and End-of-Life Announcement for the Cisco Catalyst 3750 24- and 48-Port 10/100, 3560 24- and 48-Port 10/100 Switches2010-Jul-052015-Jul-31WS-C3750-48TS-SEnd-of-Sale and End-of-Life Announcement for the Cisco Catalyst 3750 24- and 48-Port 10/100, 3560 24- and 48-Port 10/100 Switches2010-Jul-052015-Jul-31",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": "Automation is matching only on PID.  See Field Notice for additional manual checks.",
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/637/fn63745.html"
        },
        {
            "fieldNoticeId": 63746,
            "status": "P",
            "bulletinLastUpdated": "2018-09-10T00:00:00Z",
            "bulletinTitle": "FN63746 - Catalyst C4500 and Catalyst 49xx Might Fail to Boot Up After a Software Upgrade or Power Cycle - Replace on Failure",
            "bulletinFirstPublished": "2014-03-03T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "Some Catalyst 49xx fixed switches and a Catalyst 4500 modular supervisor might fail to boot up after a software upgrade or other user action where the board requires a power cycle operation.",
            "background": "Cisco has been working with some customers on an issue related to memory components manufactured by a single supplier between 2005 and 2010. These memory components are widely used across the industry and are included in a number of Cisco products.Although the majority of Cisco products using these components are experiencing field failure rates below expected levels, some components may fail earlier than anticipated. A handful of our customers have recently experienced a higher number of failures, leading us to change our approach to managing this issue.While other vendors have chosen to address this issue in different ways, Cisco believes its approach is the best course of action for its customers. Despite the cost, we are demonstrating that we always make customer satisfaction a top priority. Customers can learn more about this topic at www.cisco.com/go/memory.PLEASE NOTE: The products listed in this Field Notice have lower than expected failure rates. This assessment is based on actual usage of affected memory components, observed field failure rates and product replacements since 2012.A degraded component will not affect the ongoing operation of a device, but will be exposed by a subsequent power cycle event. This event will result in a hard failure of the device, which cannot be recovered by a reboot or additional power cycle. For these reasons, additional caution is recommended for operational activities requiring the simultaneous power cycling of multiple devices. This issue has been observed most commonly on devices that have been in service for 24 months or more.",
            "problemSymptoms": "There is no known occurrence of failure due to the specific vendor of memory in the impacted PIDS on Catalyst 4500 and Catalyst 49xx platform. If the suspected Catalyst 4500 supervisor and 49xx fixed switch has been in operation for approximately ~24 months, the product hardware may fail to boot-up due to memory failure during a power cycle event caused by one or more of the following conditions: - Upgrade the software - Reload the entire product - Reload after installation - Online Insertion Removal/Replacement (OIR) for the modular supervisorNote: The issue does not affect boards while the boards are in operation. The board failure may occur after one or more of the above conditions are met.",
            "workaround": "Normal SmartNet and warranty entitlement rules remain in place and are applied by the Cisco Technical Assistance Center (TAC) if you experience a failure in one of the products listed in the Field Notice. In other circumstances, such as out of warranty or out of contract, Cisco encourages you to raise your concern directly with your Cisco account team. Fix on Failure Replacement Guidelines: Request Return Material Authorization (RMA) product through normal service support channels.Product or card replacement: Request RMA product through normal service support channels. For assistance with replacement memory module: Please refer to the Memory Replacement Guidance for Cisco Catalyst 4500 Series Modular Switch Supervisor for instructions on how to replace the memory modules.     PID    Action    PID Replacement    Quantity          Catalyst 4500 Supervisor                            WS-X4516-10GE    Replace Supervisor Memory Module    MEMC4K-512D-SDRAM=    1        Catalyst 49xx                            WS-C4948-10GE    Replace product    WS-C4948-10GE    1        WS-C4948-10GE-E    Replace product    WS-C4948-10GE-E    1        WS-C4948-10GE-S    Replace product    WS-C4948-10GE-S    1        WS-C4928-10GE    Replace product    WS-C4928-10GE    1        ME-4924-10GE    Replace product    ME-4924-10GE    1",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/637/fn63746.html"
        },
        {
            "fieldNoticeId": 63747,
            "status": "P",
            "bulletinLastUpdated": "2018-09-10T00:00:00Z",
            "bulletinTitle": "FN63747 - IE3000 - Products Affected Might Fail to Boot Up After a Power Cycle - Replace on Failure",
            "bulletinFirstPublished": "2014-03-10T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "IE3000 switches (listed in the Products Affected section) might fail to boot up after a power cycle operation.",
            "background": "Cisco has been working with some customers on an issue related to memory components manufactured by a single supplier between 2005 and 2010. These memory components are widely used across the industry and are included in a number of Cisco products.Although the majority of Cisco products using these components are experiencing field failure rates below expected levels, some components may fail earlier than anticipated. A handful of our customers have recently experienced a higher number of failures, leading us to change our approach to managing this issue.While  other vendors have chosen to address this issue in different ways, Cisco  believes its approach is the best course of action for its customers. Despite  the cost, we are demonstrating that we always make customer satisfaction a top  priority. Customers can learn more about this topic at Memory Component Issue web page.PLEASE NOTE - The products listed in this Field Notice have lower than expected failure rates. This assessment is based on actual usage of affected memory components, observed field failure rates and product replacements since 2012.A degraded component will not affect the ongoing operation of a device, but will be exposed by a subsequent power cycle event. This event will result in a hard failure of the device, which cannot be recovered by a reboot or additional power cycle. For these reasons, additional caution is recommended for operational activities requiring the simultaneous power cycling of multiple devices. This issue has been observed most commonly on devices that have been in service for 24 months or more.",
            "problemSymptoms": "If the IE3000 switch (listed in the Products Affected section) has been in operation for approximately 24 months, the switch might fail to boot up due to memory failure as a result of this condition: - Power is removed and reapplied to the switch (the switch is power cycled).Note: This issue does not affect switches while they are in operation. The switch failure might occur after the  condition is met.The failure symptom observed is as follows: - The switch fails to boot up with no console response (no characters are written to the console).",
            "workaround": "Normal SmartNet and warranty entitlement rules remain in place and are applied by the Cisco Technical Assistance Center (TAC) if you experience a failure in one of the products listed in the Field Notice. In other circumstances, such as out of warranty or out of contract, Cisco encourages you to raise your concern directly with your Cisco account team. Fix on Failure Replacement Guidelines: Request Return Material Authorization (RMA) product through normal service support channels.PIDActionReplacement PIDQuantityIE-3000-4TCReplace switchIE-3000-4TC1IE-3000-4TC-EReplace switchIE-3000-4TC-E1IE-3000-8TCReplace switchIE-3000-8TC1IE-3000-8TC-EReplace switchIE-3000-8TC-E1",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": "Automation is matching only on PID.  See Field Notice for additional manual checks.",
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/637/fn63747.html"
        },
        {
            "fieldNoticeId": 63751,
            "status": "P",
            "bulletinLastUpdated": "2018-09-10T00:00:00Z",
            "bulletinTitle": "FN63751 - Nexus 7000 - Products Affected Might Fail to Boot Up After a Software Upgrade or Power Cycle - Replace on Failure",
            "bulletinFirstPublished": "2014-03-03T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "The Nexus 7000 linecards (listed in the Products Affected section) might fail to boot up after a software upgrade or other user action where the board requires a power cycle operation.",
            "background": "Cisco has been working with some customers on an issue related to memory components manufactured by a single supplier between 2005 and 2010. These memory components are widely used across the industry and are included in a number of Cisco products.Although the majority of Cisco products using these components are experiencing field failure rates below expected levels, some components may fail earlier than anticipated. A handful of our customers have recently experienced a higher number of failures, leading us to change our approach to managing this issue.While  other vendors have chosen to address this issue in different ways, Cisco  believes its approach is the best course of action for its customers. Despite  the cost, we are demonstrating that we always make customer satisfaction a top  priority. Customers can learn more about this topic at Memory Component Issue web page.PLEASE NOTE - The products listed in this Field Notice have lower than expected failure rates. This assessment is based on actual usage of affected memory components, observed field failure rates and product replacements since 2012.A degraded component will not affect the ongoing operation of a device, but will be exposed by a subsequent power cycle event. This event will result in a hard failure of the device, which cannot be recovered by a reboot or additional power cycle. For these reasons, additional caution is recommended for operational activities requiring the simultaneous power cycling of multiple devices. This issue has been observed most commonly on devices that have been in service for 24 months or more.",
            "problemSymptoms": "If the Nexus 7000 linecard (listed in the Products Affected section) has been in continuous operation for approximately 24 months, then the Nexus 7000 hardware might fail to boot up due to memory failure during a power cycle event. This is caused by one or more of these actions: - Upgrade the software- Reload the entire product- Reload after installation  - Online Insertion Removal/Replacement (OIR) Note: This issue does not affect boards while the boards are in operation. The board failure might occur after one or more of the actions listed are executed.The card symptoms observed are shown here.The goal is to identify any error messages that differentiate memory component causing boot up failures from other boot up failures. If there is no error message, then no additional information is necessary.Supervisor console messages are shown here:2013 Nov 20 08:29:15 switch %$ VDC-1 %$ %PLATFORM-2-MOD_PWRUP: Module 1 powered up (Serial number JAFxxxxxxx)2013 Nov 20 08:29:15 switch %$ VDC-1 %$ %MODULE-2-MOD_FAIL: Initialization of module 1 (serial: JAFxxxxxxx) failed2013 Nov 20 08:29:16 switch %$ VDC-1 %$ %MODULE-2-MOD_FAIL: Initialization of module 1 (serial: JAFxxxxxxx) failed2013 Nov 20 08:29:16 switch %$ VDC-1 %$ %PLATFORM-2-MOD_PWRDN: Module 1 powered down (Serial number JAFxxxxxxx)switch# show mod Mod Ports Module-Type                      Model              Status--- ----- -------------------------------- ------------------ ------------1   0     10 Gbps Ethernet Module                             powered-dn5   0     Supervisor module-1X             N7K-SUP1           active Mod Power-Status Reason--- ------------ ---------------------------1   powered-dn   Reset (powered-down) because module does not bootThis  failure message can appear for other failures as well. Use the output of the show module internal activity module command in order to verify the failure is memory related.  The output of the show module internal activity module command has POST codes. A 0xE2 value of PWR_MGMT_LCP_STATUS_REG indicates memory failure. An example is shown here:switch# show module internal activity module x ****************** module activity log ***************1) At 999305 usecs after Thu Feb 20 07:22:55 2014DEBUG: Non-MTS eventcategory_id(2), event_id(104), resource_id(17942) At 999017 usecs after Thu Feb 20 07:22:55 2014Holding current transactionOP: MTS_OPC_PFM_MODULE_POWER_STATUS- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 6) At 998880 usecs after Thu Feb 20 07:22:55 2014Received MTS_OPC_PFM_MODULE_POWER_STATUS from node 1281 Platform managerPower status: Powered down- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 11) At 518989 usecs after Thu Feb 20 07:22:55 2014PWR_MGMT_SCRATCH_A_REG(0x1) = 0xdb, PWR_MGMT_POST_CODE_REG(0xb) = 0xe212) At 518914 usecs after Thu Feb 20 07:22:55 2014PWR_MGMT_REVISION_REG = 0x6e, PWR_MGMT_IO_CNTRL_REG = 0xc4PWR_MGMT_TRIPLE_IO_STATUS_REG1 = 0x6e, PWR_MGMT_LCP_STATUS_REG=0xe2",
            "workaround": "Normal SmartNet and warranty entitlement rules remain in place and are applied by the Cisco Technical Assistance Center (TAC) if you experience a failure in one of the products listed in the Field Notice. In other circumstances, such as out of warranty or out of contract, Cisco encourages you to raise your concern directly with your Cisco account team. Fix on Failure Replacement Guidelines: Request Return Material Authorization (RMA) product through normal service support channels.If you need assistance in order to determine which hardware part(s) might need replacement, consult the error messages documented in the Problem Symptom section.For assistance with replacement part disposition, reference this table. In cases where replacing the memory DIMM and/or daughter card is not a viable option, a request may be made to replace the entire card.Refer to this documentation for assistance on memory modules replacement:  Replacing Memory on a Cisco Nexus 7000 Series I/O Module      Affected  PID    Action    Replacement PID    Quantity        N7K-M148GT-11    Replace entire card or baseboard Memory  Module    N7K-M148GT-11 orN7K-DIMM-1GB=    1        N7K-M132XP-12    Replace entire card or baseboard Memory module    N7K-M132XP-12 orN7K-DIMM-1GB=    1",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": "Additonal notes",
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/637/fn63751.html"
        },
        {
            "fieldNoticeId": 63752,
            "status": "P",
            "bulletinLastUpdated": "2018-09-10T00:00:00Z",
            "bulletinTitle": "FN63752 - MDS 9000 Might Fail to Boot After a Software Upgrade or Power Cycle - Replace on Failure",
            "bulletinFirstPublished": "2014-03-03T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "The Cisco MDS 9000 Series switches (listed in the Products Affected section) might fail to boot up after a software upgrade or other user action where the board requires a power cycle operation.",
            "background": "Cisco has been working with some customers on an issue related to memory components manufactured by a single supplier between 2005 and 2010. These memory components are widely used across the industry and are included in a number of Cisco products.Although the majority of Cisco products using these components are experiencing field failure rates below expected levels, some components may fail earlier than anticipated. A handful of our customers have recently experienced a higher number of failures, leading us to change our approach to managing this issue.While other vendors have chosen to address this issue in different ways, Cisco believes its approach is the best course of action for its customers. Despite the cost, we are demonstrating that we always make customer satisfaction a top priority. Customers can learn more about this topic at the Memory Component Issue web page.PLEASE NOTE - The products listed in this Field Notice have lower than expected failure rates. This assessment is based on actual usage of affected memory components, observed field failure rates and product replacements since 2012.A degraded component will not affect the ongoing operation of a device, but will be exposed by a subsequent power cycle event. This event will result in a hard failure of the device, which cannot be recovered by a reboot or additional power cycle. For these reasons, additional caution is recommended for operational activities requiring the simultaneous power cycling of multiple devices. This issue has been observed most commonly on devices that have been in service for 24 months or more.",
            "problemSymptoms": "If the suspected hardware (listed in the Products Affected section) has been in operation for approximately 24 months, then the hardware might fail to boot up due to memory failure during a power cycle event. This is caused by one or more of these actions: - Upgrade the software - Reload the entire product - Reload after installation - Online Insertion Removal/Replacement (OIR)Note: This issue does not affect boards while the boards are in operation. The board failure might occur after one or more of the actions listed are executed. An In-Service Software Upgrade (ISSU) does not cause a loss of power to the module.The problem symptoms include these messages that might be observed on the Supervisor console:2012 Apr 14 21:57:22 mds9506 %PLATFORM-2-MOD_DETECT: Module 1 detected Module-Type 1/2/4 Gbps FC Module Model DS -X9148 2012 Apr 14 21:57:22 mds9506 %PLATFORM-2-MOD_PWRUP: Module 1 powered up 2012 Apr 14 22:00:24 mds9506 %MODULE-2-MOD_FAIL: Initialization of module 1 failed 2012 Apr 14 22:00:25 mds9506 %MODULE-2-MOD_FAIL: Initialization of module 1 failed 2012 Apr 14 22:00:25 mds9506 %PLATFORM-2-MOD_PWRDN: Module 1 powered dowswitch# show mod 1 Mod Ports Module-Type           Model    Status--- ----- --------------------- -------- -----------1   48    1/2/4 Gbps FC Module  DS-X9148 powered-dnMod Power-Status Reason --- ------------ --------------------------- 1   powered-dn   Reset (powered-down) because module does not bootThis failure message might appear due to other non-related failures. Use the output from the show module internal activity module command in order to further validate a memory failure.The output from this command includes POST codes. A 0xE2 value of PWR_MGMT_LCP_STATUS_REG indicates a memory failure. Here is an example:switch# show module internal activity module x****************** module activity log *************** 1) At 999305 usecs after Thu Feb 20 07:22:55 2014 DEBUG: Non-MTS event category_id(2), event_id(104), resource_id(1794) 2) At 999017 usecs after Thu Feb 20 07:22:55 2014 Holding current transaction OP: MTS_OPC_PFM_MODULE_POWER_STATUS - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 6) At 998880 usecs after Thu Feb 20 07:22:55 2014 Received MTS_OPC_PFM_MODULE_POWER_STATUS from node 1281 Platform manager Power status: Powered down - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 11) At 518989 usecs after Thu Feb 20 07:22:55 2014 PWR_MGMT_SCRATCH_A_REG(0x1) = 0xdb, PWR_MGMT_POST_CODE_REG(0xb) = 0xe2 12) At 518914 usecs after Thu Feb 20 07:22:55 2014 PWR_MGMT_REVISION_REG = 0x6e, PWR_MGMT_IO_CNTRL_REG = 0xc4 PWR_MGMT_TRIPLE_IO_STATUS_REG1 = 0x6e, w",
            "workaround": "Normal SmartNet and warranty entitlement rules remain in place and are applied by the Cisco Technical Assistance Center (TAC) if you experience a failure in one of the products listed in the Field Notice. In other circumstances, such as out of warranty or out of contract, Cisco encourages you to raise your concern directly with your Cisco account team. Fix on Failure Replacement Guidelines: Request Return Material Authorization (RMA) product through normal service support channels.If you need assistance in order to determine which hardware part(s) might need replacement, consult the error messages documented in the Problem Symptom section.For assistance with replacement part disposition, reference this table:Affected PIDActionReplacement PIDQuantityDS-C9124-K9 or DS-C9124AP-K9Replace entire unitDS-C9124-K9 or DS-C9124AP-K91DS-X9112Replace entire cardDS-X91121DS-X9124Replace entire cardDS-X91241DS-X9148Replace entire cardDS-X91481DS-X9530-SF2-K9Replace entire cardDS-X9530-SF2-K91DS-X9530-SF2AK9Replace entire cardDS-X9530-SF2AK91DS-HP-FC-K9 or  DS-HP-FC-LIC-K9Replace entire cardCustomer should work with HP support for information1DS-IBM-FC-LIC-K9Replace entire cardCustomer should work with IBM support for information1Notice of End of Support            PID      End of Support Notice      End of Support Date              DS-X9112      EOL6825      02/28/2015              DS-X9124      EOL6825      02/28/2015              DS-X9148      EOL6825      02/28/2015              DS-X9530-SF2-K9      EOL7377      07/31/2016              DS-HP-FC-K9      EOL7676      12/31/2016",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": "Automation is matching only on PID.  See Field Notice for additional manual checks.",
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/637/fn63752.html"
        },
        {
            "fieldNoticeId": 63753,
            "status": "P",
            "bulletinLastUpdated": "2018-09-10T00:00:00Z",
            "bulletinTitle": "FN63753 - RFGW10 Cards Might Fail to Boot After Software Upgrade or Power Cycle - Replace on Failure",
            "bulletinFirstPublished": "2014-03-03T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "The Cisco RFGW10 linecards (listed in the Products Affected section) might fail to boot up after a software upgrade or other user action where the board requires a power cycle operation.",
            "background": "Cisco has been working with some customers on an issue related to memory components manufactured by a single supplier between 2005 and 2010. These memory components are widely used across the industry and are included in a number of Cisco products.\r\n\r\nAlthough the majority of Cisco products using these components are experiencing field failure rates below expected levels, some components may fail earlier than anticipated. A handful of our customers have recently experienced a higher number of failures, leading us to change our approach to managing this issue.\r\n\r\nWhile other vendors have chosen to address this issue in different ways, Cisco believes its approach is the best course of action for its customers. Despite the cost, we are demonstrating that we always make customer satisfaction a top priority. Customers can learn more about this topic at the <a href=\"www.cisco.com/go/memory\">Memory Component Issue</a> web page.\r\n\r\nPLEASE NOTE - The products listed in this Field Notice have lower than expected failure rates. This assessment is based on actual usage of affected memory components, observed field failure rates and product replacements since 2012.\r\n\r\nA degraded component will not affect the ongoing operation of a device, but will be exposed by a subsequent power cycle event. This event will result in a hard failure of the device, which cannot be recovered by a reboot or additional power cycle. For these reasons, additional caution is recommended for operational activities requiring the simultaneous power cycling of multiple devices. This issue has been observed most commonly on devices that have been in service for 24 months or more.",
            "problemSymptoms": "If the Cisco RFGW10 linecards (listed in the Products Affected section) have been in continuous operation for approximately 24 months, then the hardware might fail to boot up due to memory failure during a power cycle event. This is caused by one or more of these actions:\r\n \r\n- Upgrade the software \r\n- Reload the entire product \r\n- Reload after installation \r\n- Online Insertion Removal/Replacement (OIR)\r\n\r\n<b>Note:</b> This issue does not affect boards while the boards are in operation. The board failure might occur after one or more of the actions listed are executed.",
            "workaround": "Normal SmartNet and warranty entitlement rules remain in place and will be applied by the Cisco TAC if you experience a failure in one of the products listed in the Field Notices. In other circumstances (e.g. out of warranty or out of contract), we'd encourage you to raise your concern directly with your Cisco account team.\r\n\r\nFix on Failure Replacement Guidelines: Request RMA product and memory modules through normal service support channels.\r\nIf you need assistance in order to determine which hardware part(s) might need replacement, consult the error messages documented in the Problem Symptom section.\r\n\r\nFor assistance with replacement part disposition, please reference this table:\r\n\r\n<IMG SRC=\"http://www-tac.cisco.com/Support_Library/field_alerts/fn63753_n1bnq0.png\"><br><br><br>\r\n\r\nPlease refer to the <a href =\" http://www.cisco.com/c/en/us/td/docs/interfaces_modules/cable/dimm/installation/guide/cisco_rfgw-10_sodimm.html\">Replacement of DIMM on the Cisco RF Gateway 10</a> Cisco article in order to replace the Memory modules on this product.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": "Automation is matching only on PID.  See Field Notice for additional manual checks.",
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/637/fn63753.html"
        },
        {
            "fieldNoticeId": 63754,
            "status": "P",
            "bulletinLastUpdated": "2018-09-10T00:00:00Z",
            "bulletinTitle": "FN63754 - uBR7200 Cards - Products Affected Might Fail to Boot up after a Software Upgrade or Power Cycle - Replace on Failure",
            "bulletinFirstPublished": "2014-03-03T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "The uBR7200 cards (listed in the Products Affected section) might fail to boot up after a software upgrade or other user action where the board requires a power cycle operation.",
            "background": "Cisco has been working with some customers on an issue related to memory components manufactured by a single supplier between 2005 and 2010. These memory components are widely used across the industry and are included in a number of Cisco products.\r\n\r\nAlthough the majority of Cisco products using these components are experiencing field failure rates below expected levels, some components may fail earlier than anticipated. A handful of our customers have recently experienced a higher number of failures, leading us to change our approach to managing this issue.\r\n\r\nWhile  other vendors have chosen to address this issue in different ways, Cisco  believes its approach is the best course of action for its customers. Despite  the cost, we are demonstrating that we always make customer satisfaction a top  priority. Customers can learn more about this topic at <a href=\"http://www.cisco.com/go/memory\">Memory Component Issue</a> web page.\r\n\r\nPLEASE NOTE - The products listed in this Field Notice have lower than expected failure rates. This assessment is based on actual usage of affected memory components, observed field failure rates and product replacements since 2012.\r\n\r\nA degraded component will not affect the ongoing operation of a device, but will be exposed by a subsequent power cycle event. This event will result in a hard failure of the device, which cannot be recovered by a reboot or additional power cycle. For these reasons, additional caution is recommended for operational activities requiring the simultaneous power cycling of multiple devices. This issue has been observed most commonly on devices that have been in service for 24 months or more.",
            "problemSymptoms": "If the uBR7200 card (listed in the Products Affected section) has been in operation for approximately 24 months, the uBR7200 card might fail to boot up due to memory failure during a power cycle event. This is caused by one or more of these actions:\r\n \r\n- Upgrade the software\r\n- Reload the entire product \r\n- Reload after installation \r\n- Online Insertion Removal/Replacement (OIR) \r\n\r\n<b>Note:</b> This issue does not affect boards while the boards are in operation. The board failure might occur after one or more of the actions listed are executed.\r\n\r\nThe card symptom observed is as follows:\r\n\r\n<IMG SRC=\"http://www-tac.cisco.com/Support_Library/field_alerts/fn63754_n1o6te.png\"><br><br><br>",
            "workaround": "Normal SmartNet and warranty entitlement rules remain in place and are applied by the Cisco Technical Assistance Center (TAC) if you experience a failure in one of the products listed in the Field Notice. In other circumstances, such as out of warranty or out of contract, Cisco encourages you to raise your concern directly with your Cisco account team. \r\n\r\nFix on Failure Replacement Guidelines: Request RMA product and memory modules through normal service support channels.\r\nIf you need assistance in order to determine which hardware part(s) might need replacement, consult the error messages documented in the Problem Symptom section.\r\n\r\nFor assistance with replacement part disposition, see the table shown here:\r\n\r\n<IMG SRC=\"http://www-tac.cisco.com/Support_Library/field_alerts/fn63754_n1o6rv.png\"><br><br><br>\r\n\r\nSee <a href=\"http://www.cisco.com/c/en/us/td/docs/interfaces_modules/cable/dimm/installation/guide/cisco_ubr7200_sodimm.html\">Replacement of DIMM on the Cisco uBR7200 Series Routers</a> in order to replace the memory modules on this product. \r\n\r\n<TABLE BORDER='1' CELLPADDING='0' CELLSPACING='2'><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'><B>End of Support (EOS) PID</B></FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'></FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'></FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'><B>PID</B></FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'><B>EOS Notice</B></FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'><B>EOS Date</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>UBR7200-NPE-G1</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'><a href=\"http://www.cisco.com/c/en/us/products/collateral/video/ubr7200-series-universal-broadband-routers/end_of_life_notice_c51-578811.html\">EOL7008</a></FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>07-31-2015</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>UBR-E-28U(=)</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'><a href=\" http://www.cisco.com/c/en/us/products/collateral/video/ubr7200-series-universal-broadband-routers/end_of_life_notice_c51-598459.html \">EOL7113</a></FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>10-31-2015</FONT></TD></TR></TABLE>",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": "Automation is matching only on PID.  See Field Notice for additional manual checks.",
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/637/fn63754.html"
        },
        {
            "fieldNoticeId": 63756,
            "status": "P",
            "bulletinLastUpdated": "2018-09-10T00:00:00Z",
            "bulletinTitle": "FN63756 - ME3400/E Switches - Products Affected Might Fail to Boot Up After a Power Cycle - Replace on Failure",
            "bulletinFirstPublished": "2014-03-03T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "The ME3400/E Switches (listed in the Products Affected section) might fail to boot up after the unit experiences a power cycle operation.",
            "background": "Cisco has been working with some customers on an issue related to memory components manufactured by a single supplier between 2005 and 2010. These memory components are widely used across the industry and are included in a number of Cisco products.Although the majority of Cisco products using these components are experiencing field failure rates below expected levels, some components may fail earlier than anticipated. A handful of our customers have recently experienced a higher number of failures, leading us to change our approach to managing this issue.While  other vendors have chosen to address this issue in different ways, Cisco  believes its approach is the best course of action for its customers. Despite  the cost, we are demonstrating that we always make customer satisfaction a top  priority. Customers can learn more about this topic at Memory Component Issue web page.PLEASE NOTE - The products listed in this Field Notice have lower than expected failure rates. This assessment is based on actual usage of affected memory components, observed field failure rates and product replacements since 2012.A degraded component will not affect the ongoing operation of a device, but will be exposed by a subsequent power cycle event. This event will result in a hard failure of the device, which cannot be recovered by a reboot or additional power cycle. For these reasons, additional caution is recommended for operational activities requiring the simultaneous power cycling of multiple devices. This issue has been observed most commonly on devices that have been in service for 24 months or more.",
            "problemSymptoms": "If the ME3400/E Switch (listed in the Products Affected section) has been in continuous operation for approximately 24 months, then the switch might fail to boot up due to memory failure during a power cycle event. This occurs when power is removed and reapplied to the switch (the switch is power cycled).Note: This issue does not affect switches while they are in operation. The switch failure might occur after the switch is power cycled.The failure symptom is observed when the switch fails to boot up with no console response (no characters are written to the console).",
            "workaround": "Normal SmartNet and warranty entitlement rules remain in place and are applied by the Cisco Technical Assistance Center (TAC) if you experience a failure in one of the products listed in the Field Notice. In other circumstances, such as out of warranty or out of contract, Cisco encourages you to raise your concern directly with your Cisco account team.Fix on Failure Replacement Guidelines: Request Return Material Authorization (RMA) product through normal service support channels. If you need assistance in order to determine which hardware part(s) might need replacement, consult the error messages documented in the Problem Symptom section.PIDActionPID ReplacementQuantityME-3400-24FS-AReplace SwitchME-3400-24FS-A1ME-3400-24TS-AReplace SwitchME-3400E-24TS-A1ME-3400-24TS-DReplace SwitchME-3400E-24TS-D1ME-3400E-24TS-MReplace SwitchME-3400E-24TS-M1ME-3400EG-12CS-MReplace SwitchME-3400EG-12CS-M1ME-3400EG-2CS-AReplace SwitchME-3400EG-2CS-A1ME-3400G-12CS-AReplace SwitchME-3400EG-12CS-A 1ME-3400G-12CS-DReplace SwitchME-3400G-12CS-D1ME-3400G-2CS-AReplace SwitchME-3400G-2CS-A1",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": "Automation is matching only on PID.  See Field Notice for additional manual checks.",
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/637/fn63756.html"
        },
        {
            "fieldNoticeId": 63758,
            "status": "P",
            "bulletinLastUpdated": "2018-08-01T00:00:00Z",
            "bulletinTitle": "FN63758 - ASR5000 and ASR5500 Products Might Fail to Boot Up After a Software Upgrade or Power Cycle - Replace on Failure",
            "bulletinFirstPublished": "2014-03-03T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "The Cisco Aggregation Services Router (ASR) 5000 and 5500 (listed in the Products Affected section) might fail to boot up after a software upgrade or other user action where the board requires a power cycle operation.",
            "background": "Cisco has been working with some customers on an issue related to memory components manufactured by a single supplier between 2005 and 2010. These memory components are widely used across the industry and are included in a number of Cisco products.Although the majority of Cisco products using these components are experiencing field failure rates below expected levels, some components may fail earlier than anticipated. A handful of our customers have recently experienced a higher number of failures, leading us to change our approach to managing this issue.While other vendors have chosen to address this issue in different ways, Cisco believes its approach is the best course of action for its customers. Despite the cost, we are demonstrating that we always make customer satisfaction a top priority. Customers can learn more about this topic at www.cisco.com/go/memory. PLEASE NOTE: The products listed in this Field Notice have lower than expected failure rates. This assessment is based on actual usage of affected memory components, observed field failure rates, and product replacements since 2012. A degraded component will not affect the ongoing operation of a device, but will be exposed by a subsequent power cycle event. This event will result in a hard failure of the device, which cannot be recovered by a reboot or additional power cycle. For these reasons, additional caution is recommended for operational activities requiring the simultaneous power cycling of multiple devices. This issue has been observed most commonly on devices that have been in service for 24 months or more.HistoryField Notice RevisionDateComments1.003-Mar-2014Initial: Announcement2.002-Feb-2015Update: Workaround Section Note3.005-Jan-2016Update: ASR5K-PSC-K9 added Note4.024-Aug-2016Update: End of Support date",
            "problemSymptoms": "If the suspected hardware has been in operation for approximately 24 months, the product hardware might fail to boot up due to memory failure during a power cycle event. This is caused by one or more of these actions:-Upgrade the software-Reload the entire product-Reload after installation-Online Insertion Removal/Replacement (OIR)  Note: The issue does not affect boards while the boards are in operation. The board failure may occur after one or more of the above conditions are met. The card symptoms observed are shown here:-Card fails to boot-Card reports memory failure",
            "workaround": "Normal SmartNet and warranty entitlement rules remain in place and are applied by the Cisco Technical Assistance Center (TAC) if you experience a failure in one of the products listed in the Field Notice. In other circumstances, such as out of warranty or out of contract, Cisco encourages you to raise your concern directly with your Cisco account team.Fix on Failure Replacement Guidelines: Request Return Material Authorization (RMA) product and memory modules through normal service support channels.If you need assistance in order to determine which hardware part(s) might need replacement, consult the error messages documented in the Problem Symptom section.PIDActionPID ReplacementQuantityASR55-DPC-K9Replace line cardASR55-DPC-K9=1ASR55-MIO-10GL2K9Replace line cardASR55-MIO-10GL2K9=1ASR55-MIO-10GS2K9Replace line cardASR55-MIO-10GS2K9=1ASR5K-SMC-K9Replace line cardASR5K-SMC-K9=1ASR5K-PSC-K9Replace line cardASR5K-PSC-16G-K9=1End of Support PIDPIDEnd of Support NoticeEnd of Support DateASR5K-PSC-K9EOL733107/31/2016",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": "Automation is matching only on PID.  See Field Notice for additional manual checks.",
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/637/fn63758.html"
        },
        {
            "fieldNoticeId": 63760,
            "status": "P",
            "bulletinLastUpdated": "2018-06-11T00:00:00Z",
            "bulletinTitle": "FN63760 - CISCO3825 & CISCO3845 Might Fail to Boot After a Power Cycle - Replace on Failure",
            "bulletinFirstPublished": "2014-03-03T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "The CISCO3825 & CISCO3845 Series hardware (listed in the Products Affected section) might fail to boot up after a user action where the board requires a power cycle operation.",
            "background": "Cisco has been working with some customers on an issue related to memory components manufactured by a single supplier between 2005 and 2010. These memory components are widely used across the industry and are included in a number of Cisco products.Although the majority of Cisco products using these components are experiencing field failure rates below expected levels, some components may fail earlier than anticipated. A handful of our customers have recently experienced a higher number of failures, leading us to change our approach to managing this issue.While other vendors have chosen to address this issue in different ways, Cisco believes its approach is the best course of action for its customers. Despite the cost, we are demonstrating that we always make customer satisfaction a top priority. Customers can learn more about this topic at the Memory Component Issue web page.A degraded component will not affect the ongoing operation of a device, but will be exposed by a subsequent power cycle event. This event will result in a hard failure of the device, which cannot be recovered by a reboot or additional power cycle. For these reasons, additional caution is recommended for operational activities requiring the simultaneous power cycling of multiple devices. This issue has been observed most commonly on devices that have been in service for 24 months or more.",
            "problemSymptoms": "If the CISCO3825 & CISCO3845 Series hardware (listed in the Products Affected section) has been in continuous operation for approximately 24 months, then the hardware might fail to boot up due to memory failure during a power cycle event. This is caused by one or more of these actions:- Power cycle the entire product- Power cycle after installation or Software Upgrade- Manual or facility power interruptionNote: This issue does not affect boards while the boards are in operation. The board failure might occur after one or more of the actions listed are executed.The problem symptoms include these memory failure messages that might be observed on suspect routers:- Bad RAM- SDRAM ECC Error",
            "workaround": "Please refer to this table for the appropriate Memory Product ID replacement: PIDActionPID Replacement Qty of Replacement PID&#39;sMEM3800-512D(=)Replace Memory ModuleMEM3800-512D=1MEM3800-256D(=)Replace Memory ModuleMEM3800-256D=1    NOTE: Routers may have multiple DIMMs. Please verify the individual DIMM slots using the command in the \"How to Identify Hardware Levels\" section of this Field Notice.Please refer to the SDRAM DIMM Removal and Installation section of the Cisco 3800 Series Hardware Installation Guide in order to replace the Memory modules on CISCO3825 & CISCO3845 Series products.Normal SmartNet and warranty entitlement rules remain in place and are applied by the Cisco Technical Assistance Center (TAC) if you experience a failure in one of the products listed in the Field Notice. In other circumstances, such as out of warranty or out of contract, Cisco encourages you to raise your concern directly with your Cisco account team.Fix on Failure Replacement Guidelines: Request Return Material Authorization (RMA) product through normal service support channels.If you need assistance in order to determine which hardware part(s) might need replacement, consult the error messages documented in the Problem Symptom section.End of Support DatePIDEnd of Support NoticeEnd of Support DateCISCO3825EOL724710/31/2016CISCO3825-NONVPNEOL724710/31/2016CISCO3845EOL724710/31/2016CISCO3845-NONVPNEOL724710/31/2016How to Identify Hardware LevelsEnter the show platform command in order to obtain the size of the DIMM(s) of the router in question. If there is no DIMM in the second slot \"Memory Slot Empty\" will show in the output. Please see the output below as reference. If the CLI is not available, physically inspect in order to locate the PID.",
            "hardwareLevels": "",
            "upgradeProgram": "",
            "caveat": null,
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/637/fn63760.html"
        },
        {
            "fieldNoticeId": 63761,
            "status": "P",
            "bulletinLastUpdated": "2018-09-10T00:00:00Z",
            "bulletinTitle": "FN63761 - CISCO8XX, IAD8XX, and CISCO1941W-XXX Might Fail to Boot Up After a Power Cycle - Replace on Failure",
            "bulletinFirstPublished": "2014-03-03T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "CISCO8XX, IAD8XX, and CISCO1941W-XXX might fail to boot up after user actions where the board requires a power cycle operation.",
            "background": "Cisco has been working with some customers on an issue related to memory components manufactured by a single supplier between 2005 and 2010. These memory components are widely used across the industry and are included in a number of Cisco products.\r\n\r\nAlthough the majority of Cisco products using these components are experiencing field failure rates below expected levels, some components may fail earlier than anticipated. A handful of our customers have recently experienced a higher number of failures, leading us to change our approach to managing this issue.\r\n\r\nWhile other vendors have chosen to address this issue in different ways, Cisco believes its approach is the best course of action for its customers. Despite the cost, we are demonstrating that we always make customer satisfaction a top priority. Customers can learn more about this topic at <a href=\"www.cisco.com/go/memory\">www.cisco.com/go/memory</a>\r\n\r\nPLEASE NOTE - The products listed in this Field Notice have lower than expected failure rates. This assessment is based on actual usage of affected memory components, observed field failure rates and product replacements since 2012.\r\n\r\nA degraded component will not affect the ongoing operation of a device, but will be exposed by a subsequent power cycle event. This event will result in a hard failure of the device, which cannot be recovered by a reboot or additional power cycle. For these reasons, additional caution is recommended for operational activities requiring the simultaneous power cycling of multiple devices. This issue has been observed most commonly on devices that have been in service for 24 months or more.",
            "problemSymptoms": "If the suspected hardware has been in operation for approximately 24 months, the product hardware might fail to boot up due to memory failure during a power cycle event. This is caused by one or more of these actions:\r\n\r\nPower cycle the entire product \r\nPower cycle after installation or Software Upgrade\r\nManual or facility power interruption\r\n\r\n<b>Note:</b> This issue does not affect boards while the boards are in operation. The board failure might occur after one or more of the actions listed are executed.",
            "workaround": "Request CISCO8XX, IAD8XX, and CISCO1941W-XXX product RMAs through normal service support channels.\r\n\r\nNormal SmartNet and warranty entitlement rules remain in place and are applied by the Cisco Technical Assistance Center (TAC) if you experience a failure in one of the products listed in the Field Notice. In other circumstances, such as out of warranty or out of contract, Cisco encourages you to raise your concern directly with your Cisco account team.\r\n\r\nFix on Failure Replacement Guidelines: Request Return Material Authorization (RMA) product through normal service support channels. \r\n\r\nIf you need assistance in order to determine which hardware part(s) might need replacement, consult the error messages documented in the Problem Symptom section.\r\n\r\nNOTICE OF END OF SUPPORT\r\n\r\n<TABLE BORDER='1' CELLPADDING='0' CELLSPACING='2'><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>PRODUCT ID</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>EOL NOTICE</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>DATE END OF SUPPORT</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>CISCO867W-GN-A-K9</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'><a href=\"http://www.cisco.com/c/en/us/products/collateral/routers/800-series-routers/eol_c51_638188.html\">EOL7271</a></FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>12/31/2016</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>CISCO867W-GN-E-K9</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'><a href=\"http://www.cisco.com/c/en/us/products/collateral/routers/800-series-routers/eol_c51_638188.html\">EOL7271</a></FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>12/31/2016</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>CISCO886GW-GN-E-K9</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'><a href=\"http://www.cisco.com/c/en/us/products/collateral/routers/800-series-routers/eol_c51_638191.html\">EOL7272</a></FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>12/31/2016</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>CISCO886W-GN-E-K9</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'><a href=\"http://www.cisco.com/c/en/us/products/collateral/routers/800-series-routers/eol_c51_638191.html\">EOL7272</a></FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>12/31/2016</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>CISCO887GW-GN-A-K9</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'><a href=\"http://www.cisco.com/c/en/us/products/collateral/routers/800-series-routers/eol_c51_638141.html\">EOL7273</a></FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>12/31/2016</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>CISCO887GW-GN-E-K9</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'><a href=\"http://www.cisco.com/c/en/us/products/collateral/routers/800-series-routers/eol_c51_638141.html\">EOL7273</a></FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>12/31/2016</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>CISCO887MW-GN-E-K9</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'><a href=\"http://www.cisco.com/c/en/us/products/collateral/routers/800-series-routers/eol_c51_638141.html\">EOL7273</a></FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>12/31/2016</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>CISCO887W-GN-A-K9</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'><a href=\"http://www.cisco.com/c/en/us/products/collateral/routers/800-series-routers/eol_c51_638141.html\">EOL7273</a></FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>12/31/2016</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>CISCO887W-GN-E-K9</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'><a href=\"http://www.cisco.com/c/en/us/products/collateral/routers/800-series-routers/eol_c51_638141.html\">EOL7273</a></FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>12/31/2016</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'></FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'></FONT></TD><TH BGCOLOR='#CCCCCC'></TD></TR></TABLE>",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": "Automation is matching only on PID.  See Field Notice for additional manual checks.",
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/637/fn63761.html"
        },
        {
            "fieldNoticeId": 63762,
            "status": "P",
            "bulletinLastUpdated": "2018-08-23T00:00:00Z",
            "bulletinTitle": "FN63762 - EHWIC-3G-XXX, EMV-IPVS-16A, HWIC-3G-XXX, NME-XXX, and SM-XXX Might Fail to Boot After a Power Cycle - Replace on Failure",
            "bulletinFirstPublished": "2014-03-03T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "The Cisco EHWIC-3G-XXX, EMV-IPVS-16A, HWIC-3G-XXX, NME-XXX, and SM-XXX hardware (listed in the Products Affected section) might fail to boot up after a user action where the board requires a power cycle operation.",
            "background": "Cisco has been working with some customers on an issue related to memory components manufactured by a single supplier between 2005 and 2010. These memory components are widely used across the industry and are included in a number of Cisco products.Although the majority of Cisco products using these components are experiencing field failure rates below expected levels, some components may fail earlier than anticipated. A handful of our customers have recently experienced a higher number of failures, leading us to change our approach to managing this issue.While other vendors have chosen to address this issue in different ways, Cisco believes its approach is the best course of action for its customers. Despite the cost, we are demonstrating that we always make customer satisfaction a top priority. Customers can learn more about this topic at the Memory Component Issue web page.PLEASE NOTE - The products listed in this Field Notice have lower than expected failure rates. This assessment is based on actual usage of affected memory components, observed field failure rates and product replacements since 2012.A degraded component will not affect the ongoing operation of a device, but will be exposed by a subsequent power cycle event. This event will result in a hard failure of the device, which cannot be recovered by a reboot or additional power cycle. For these reasons, additional caution is recommended for operational activities requiring the simultaneous power cycling of multiple devices. This issue has been observed most commonly on devices that have been in service for 24 months or more.",
            "problemSymptoms": "If the suspected hardware (listed in the Products Affected section) has been in continuous operation for approximately 24 months, then the hardware might fail to boot up due to memory failure during a power cycle event. This is caused by one or more of these actions:- Power cycle the entire product- Power cycle after installation or Software Upgrade- Manual or facility power interruptionNote: This issue does not affect boards while the boards are in operation. The board failure might occur after one or more of the actions listed are executed.",
            "workaround": "Request EHWIC-3G-XXX, EMV-IPVS-16A, HWIC-3G-XXX, NME-XXX, and SM-XXX product Return Material Authorizations (RMAs) through normal service support channels.Normal SmartNet and warranty entitlement rules remain in place and are applied by the Cisco Technical Assistance Center (TAC) if you experience a failure in one of the products listed in the Field Notice. In other circumstances, such as out of warranty or out of contract, Cisco encourages you to raise your concern directly with your Cisco account team.Fix on failure Replacement Guidelines: Request RMA product through normal service support channels.If you need assistance in order to determine which hardware part(s) might need replacement, consult the error messages documented in the Problem Symptom section. Note: These Product IDs (PIDs) are affected but have now reached end of support:PIDEnd of Support DateEOL NoticeHWIC-3G-GSM(=) 06/30/2015EOL6959NME-XD-24ES-1S-P04/30/2015EOL6757EVM-IPVS-16A(=)07/31/2016EOL7305NME-16ES-1G(=)11/30/2016EOL7469NME-16ES-1G-P(=)11/30/2016EOL7469NME-X-23ES-1G(=)11/30/2016EOL7469NME-X-23ES-1G-P(=)11/30/2016EOL7469NME-XD-48ES-2S-P(=)11/30/2016EOL7469",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": "Automation is matching only on PID.  See Field Notice for additional manual checks.",
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/637/fn63762.html"
        },
        {
            "fieldNoticeId": 63763,
            "status": "P",
            "bulletinLastUpdated": "2018-09-10T00:00:00Z",
            "bulletinTitle": "FN63763 - AP1250, AP1140, AP1520, and AP1130 Might Fail to Boot Up after a Software Upgrade or Power Cycle - Replace on Failure",
            "bulletinFirstPublished": "2014-03-03T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "AP1250, AP1140, AP1520, and AP1130 might fail to boot up after a software upgrade or other user actions where the unit requires a power cycle operation.",
            "background": "Cisco has been working with some customers on an issue related to memory components manufactured by a single supplier between 2005 and 2010. These memory components are widely used across the industry and are included in a number of Cisco products.Although the majority of Cisco products using these components are experiencing field failure rates below expected levels, some components may fail earlier than anticipated. A handful of our customers have recently experienced a higher number of failures, leading us to change our approach to managing this issue.While other vendors have chosen to address this issue in different ways, Cisco believes its approach is the best course of action for its customers. Despite the cost, we are demonstrating that we always make customer satisfaction a top priority. Customers can learn more about this topic at Memory Component Issue web page.PLEASE NOTE - The products listed in this Field Notice have lower than expected failure rates. This assessment is based on actual usage of affected memory components, observed field failure rates and product replacements since 2012.A degraded component will not affect the ongoing operation of a device, but will be exposed by a subsequent power cycle event. This event will result in a hard failure of the device, which cannot be recovered by a reboot or additional power cycle. For these reasons, additional caution is recommended for operational activities requiring the simultaneous power cycling of multiple devices. This issue has been observed most commonly on devices that have been in service for 24 months or more.",
            "problemSymptoms": "If the suspected access point has been in operation for approximately 24 months, the product hardware might fail to boot up due to memory failure during a power cycle event. This is caused by one or more of these actions:-Upgrade the software-Reboot the system-A power cycleNote: This issue does not affect units while the units are in operation. The unit failure might occur after one or more of the actions listed are executed.These product symptoms are observed:-The AP does not boot-The AP&#39;s LEDs are all red-The AP does not respond on its console",
            "workaround": "Normal SmartNet and warranty entitlement rules remain in place and are applied by the Cisco Technical Assistance Center (TAC) if you experience a failure in one of the products listed in the Field Notice. In other circumstances, such as out of warranty or out of contract, Cisco encourages you to raise your concern directly with your Cisco account team. Fix on Failure Replacement Guidelines: Request Return Material Authorization (RMA) product through normal service support channels. If you need assistance in order to determine which hardware part(s) might need replacement, consult the error messages documented in the Problem Symptom section.PIDActionPID ReplacementQuantityAIR-AP1142N-A-K9Replace unitAIR-AP1142N-A-K91AIR-AP1142N-C-K9Replace unitAIR-AP1142N-C-K91AIR-AP1250(=)Replace unitAIR-AP1262N-A-K91AIR-AP1252AG-A-K9Replace unitAIR-AP1262N-A-K91AIR-AP1252AG-C-K9Replace unitAIR-AP1262N-C-K91AIR-AP1252AG-E-K9Replace unitAIR-AP1262N-E-K91AIR-AP1252AG-I-K9Replace unitAIR-AP1262N-I-K91AIR-AP1252AG-K-K9Replace unitAIR-AP1262N-K-K91AIR-AP1252AG-N-K9Replace unitAIR-AP1262N-N-K91AIR-AP1252AG-P-K9Replace unitAIR-AP1262N-Q-K91AIR-AP1252AG-S-K9Replace unitAIR-AP1262N-S-K91AIR-AP1252AG-T-K9Replace unitAIR-AP1262N-T-K91AIR-AP1252G-A-K9Replace unitAIR-AP1262N-A-K91AIR-AP1252G-E-K9Replace unitAIR-AP1262N-E-K91AIR-AP1252G-P-K9Replace unitAIR-AP1262N-Q-K91AIR-LAP1131G-A-K9Replace unitAIR-LAP1131G-A-K91AIR-LAP1131G-E-K9Replace unitAIR-LAP1131G-E-K91AIR-LAP1142N-A-K9Replace unitAIR-LAP1142N-A-K91AIR-LAP1142N-A-K9Z(=)Replace unitAIR-LAP1142N-A-K9Z1AIR-LAP1142N-C-K9Replace unitAIR-LAP1142N-C-K91AIR-LAP1142N-E-K9Replace unitAIR-CAP2602I-E-K91AIR-LAP1142N-E-K9Z(=)Replace unitAIR-CAP2602I-E-K91AIR-LAP1142N-K-K9Replace unitAIR-LAP1142N-K-K91AIR-LAP1142N-N-K9Replace unitAIR-LAP1142N-N-K91AIR-LAP1142N-P-K9Replace unitAIR-LAP1142N-P-K91AIR-LAP1250(=)Replace unitAIR-LAP1262N-A-K91AIR-LAP1252AG-A-K9Replace unitAIR-LAP1262N-A-K91AIR-LAP1252AG-C-K9Replace unitAIR-LAP1262N-C-K91AIR-LAP1252AG-E-K9Replace unitAIR-LAP1262N-E-K91AIR-LAP1252AG-I-K9Replace unitAIR-LAP1262N-I-K91AIR-LAP1252AG-K-K9Replace unitAIR-LAP1262N-K-K91AIR-LAP1252AG-N-K9Replace unitAIR-LAP1262N-N-K91AIR-LAP1252AG-P-K9Replace unitAIR-LAP1262N-Q-K91AIR-LAP1252AG-S-K9Replace unitAIR-LAP1262N-S-K91AIR-LAP1252AG-T-K9Replace unitAIR-LAP1262N-T-K91AIR-LAP1252G-A-K9Replace unitAIR-LAP1261N-A-K91AIR-LAP1252G-E-K9Replace unitAIR-LAP1261N-E-K91AIR-LAP1252G-P-K9Replace unitAIR-LAP1261N-Q-K91AIR-LAP1522AG-A-K9Replace unitAIR-CAP1552E-A-K91AIR-LAP1522AG-C-K9Replace unitAIR-CAP1552E-C-K91AIR-LAP1522AG-E-K9Replace unitAIR-CAP1552E-E-K91AIR-LAP1522AG-K-K9Replace unitAIR-CAP1552E-K-K91AIR-LAP1522AG-M-K9Replace unitAIR-CAP1552E-M-K91AIR-LAP1522AG-N-K9Replace unitAIR-CAP1552E-N-K91AIR-LAP1522AG-P-K9Replace unitAIR-CAP1552E-Q-K91AIR-LAP1522AG-S-K9Replace unitAIR-CAP1552E-S-K91AIR-LAP1522AG-T-K9Replace unitAIR-CAP1552E-T-K91AIR-LAP1522CM-A-K9Replace unitAIR-CAP1552C-A-K91AIR-LAP1522HZ-A-K9Replace unitAIR-LAP1522HZ-A-K91AIR-LAP1522HZ-C-K9Replace unitAIR-LAP1522HZ-C-K91AIR-LAP1522HZ-E-K9Replace unitAIR-LAP1522HZ-E-K91AIR-LAP1522HZ-N-K9Replace unitAIR-LAP1522HZ-N-K91AIR-LAP1522HZ-S-K9Replace unitAIR-LAP1522HZ-S-K91AIR-LAP1522PC-A-K9Replace unitAIR-LAP1522PC-A-K91AIR-LAP1522PC-N-K9Replace unitAIR-LAP1522PC-N-K91AIR-LAP1523CM-A-K9Replace unitAIR-LAP1523CM-A-K91AIR-LAP1524-C-K9Replace unitAIR-LAP1524-C-K91AIR-LAP1524PS-A-K9Replace unitAIR-LAP1524PS-A-K91AIR-LAP1524SB-A-K9Replace unitAIR-LAP1524SB-A-K91AIR-LAP1524SB-C-K9Replace unitAIR-LAP1524SB-C-K91AIR-LAP1524SB-E-K9Replace unitAIR-LAP1524SB-E-K91AIR-LAP1524SB-K-K9Replace unitAIR-LAP1524SB-K-K91AIR-LAP1524SB-M-K9Replace unitAIR-LAP1524SB-M-K91AIR-LAP1524SB-N-K9Replace unitAIR-LAP1524SB-N-K91AIR-LAP1524SB-S-K9Replace unitAIR-LAP1524SB-S-K91AIR-LAP1524SB-T-K9Replace unitAIR-LAP1524SB-S-K91When you replace a failed AP1252 model with an AP1262, ensure that the correct bracket is shipped to the customer.The universal bracket PID is AIR-AP-BRACKET-2=.The low profile bracket PID is AIR-AP-BRACKET-1=.Refer to this link for more detailed information on bracket selection: www.cisco.com/go/bracketNormal SmartNet and warranty entitlement rules remain in place and will be applied by the Cisco TAC if you experience a failure in one of the products listed in the Field Notices. In other circumstances (e.g. out of warranty or out of contract), we&#39;d encourage you to raise your concern directly with your Cisco account team.Fix on failure Replacement Guidelines: Request RMA product through normal service support channels.If you need assistance in order to determine which hardware part(s) might need replacement, consult the error messages documented in the Problem Symptom section.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/637/fn63763.html"
        },
        {
            "fieldNoticeId": 63764,
            "status": "P",
            "bulletinLastUpdated": "2018-09-10T00:00:00Z",
            "bulletinTitle": "FN63764 - Some ASR1000 Products Might Fail to Boot Up After a Power Cycle - Replace on Failure",
            "bulletinFirstPublished": "2014-03-03T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "Some Aggregation Services Router (ASR) 1000 products (see the Products Affected section) might fail to boot up after a power cycle operation.",
            "background": "Cisco has been working with some customers on an issue related to memory components manufactured by a single supplier between 2005 and 2010. These memory components are widely used across the industry and are included in a number of Cisco products.Although the majority of Cisco products using these components are experiencing field failure rates below expected levels, some components may fail earlier than anticipated. A handful of our customers have recently experienced a higher number of failures, leading us to change our approach to managing this issue.While other vendors have chosen to address this issue in different ways, Cisco believes its approach is the best course of action for its customers. Despite the cost, we are demonstrating that we always make customer satisfaction a top priority. Customers can learn more about this topic at Memory Component Issue web page.A degraded component will not affect the ongoing operation of a device, but will be exposed by a subsequent power cycle event. This event will result in a hard failure of the device, which cannot be recovered by a reboot or additional power cycle. For these reasons, additional caution is recommended for operational activities requiring the simultaneous power cycling of multiple devices. This issue has been observed most commonly on devices that have been in service for 24 months or more.",
            "problemSymptoms": "If the suspected ASR 1000 hardware has been in operation for approximately 24 months, the product hardware might fail to boot up due to memory failure during a power cycle event. This is caused by one or more of these actions:     Power cycle the chassisOnline Insertion Removal/Replacement (OIR)    Note: This issue does not affect modules while in operation. The memory failure in the base ASR 1000 platform affects only the hardware cryptographic capability of the system. The board failure might occur after one or more of the actions listed is executed.These are the linecard symptoms observed. Error messages associated with this failure:          CDT: %IMGR-0-FIPS_FMFP_N2_SEVERE_ERR_FAIL: F[x]: fman_fp_image:Cryptographic coprocessor severe failure: RSA operation error CDT: %ASR1000_OIR-6-OFFLINECARD: Card (fp) offline in slot F[x].May 27 23:39:16 CDT: %ASR1000_RP_ALARM-6-INFO: ASSERT MAJOR moduleF[x] Unknown state CDT: %ASR1000_RP_ALARM-6-INFO: ASSERT CRITICAL module R[x] No Working ESP CDT: %CPPHA-3-FAULT: F0: cpp_ha: CPP:0 desc:CPP Client process failed:FMAN-FP det:HA class:CLIENT_SW sev:FATAL id:1 cppstate:RUNNING res:UNKNOWNflags:0x0 cdmflags:0x0 CDT: %IOSXE-6-PLATFORM: F[x]: cpp_ha: Shutting down CPP MDM while client(s)still connected CDT: %PMAN-3-PROCHOLDDOWN: F[x]: pman.sh: The process fman_fp_image has beenhelddown (rc 134) CDT: %PMAN-3-PROCHOLDDOWN: F[x]: pman.sh: The process cpp_ha_top_level_serverhas been helddown (rc 69) CDT: %PMAN-0-PROCFAILCRIT: F[x]: pvp.sh: A critical process fman_fp_imagehas failed (rc 134)",
            "workaround": "Normal SmartNet and warranty entitlement rules remain in place and are applied by the Cisco Technical Assistance Center (TAC) if you experience a failure in one of the products listed in the Field Notice. In other circumstances, such as out of warranty or out of contract, Cisco encourages you to raise your concern directly with your Cisco account team.Fix on Failure Replacement Guidelines: Request Return Material Authorization (RMA) product through normal service support channels.If you need assistance in order to determine which hardware part(s) might need replacement, consult the error messages documented in the Problem Symptom section.There are two workarounds that are available for this problem. Refer to the table in order to obtain the necessary action for your configuration: ASR1000 Router ConfigurationActionFIPS not enabled AND IPSec not configuredDownload SW Patch (Scenario 1)FIPS enabled OR IPSec ConfiguredFollow Fix on Failure (Scenario 2)Scenario 1 (Software Workaround): If the ASR1000 Router does not have FIPS enabled AND is not configured for IPSec it is possible to fix the issue with a software patch. You can verify these configurations using the steps below: A) Verify if FIPS mode is enabled     ASR1000#sho romvar  inc FIPS    FIPS_MODE = 1If \"FIPS_MODE = 1\" is displayed, FIPS mode is enabled and the software patch is not an option. If anything else is displayed (including nothing being displayed) FIPS mode is not enabled. B) Verify if IPSec is configured IPSec is configured if any of the following situations is true: 1. A crypto map is applied to a physical interface     interface Serial0    ip address 20.20.20.20 255.255.255.0    no ip mroute-cache    no fair-queue    crypto map armadillo2. If \"Tunnel Protection\" is applied to tunnel interface:     interface Tunnel0    bandwidth 1000    ip address 10.0.0.1 255.255.255.0    <snip>    tunnel protection ipsec profile vpnprof    <snip>OR     interface virtual-template 1 type tunnel    bandwidth 1000    ip address 10.0.0.1 255.255.255.0    <snip>    tunnel protection ipsec profile vpnprof     <snip>If any of the above configuration snippets reflect the router configuration than IPSec is configured and the software patch is not an option. If both situations are not true than it is possible to fix the issue with a software patch. Use the information below to download the minimum version software patch: For ESP10/ESP20/ESP40 (CSCuc82634): 15.2(4)S3/XE3.7.3S 15.3(1)S2/XE3.8.2S 15.3(2)S/XE3.9.0S 15.3(3)S/XE3.10.0S For ESP5/ASR1002-F/ASR1001 (CSCui03023): 15.2(04)S05/XE3.7.5S 15.3(03)S01/XE3.10.1S 15.4(01)S/XE3.11.0S Using your Cisco.com userid, the user can locate the Software patch by clicking the Software download ASR1000 URL.Depending on product affected, Select the Product type and search for the IOS-XE version listed above. Download the Software and apply the patch to your Router. Scenario 2 (Fix on Failure Replacement Guidelines): Request RMA product through normal service support channels only on failure. PIDActionPID ReplacementQuantityASR1000-ESP5Replace cardASR1000-ESP5=1ASR1000-ESP10Replace cardASR1000-ESP10=1ASR1000-ESP20Replace cardASR1000-ESP20=1ASR1000-ESP40Replace cardASR1000-ESP40=1ASR1001Replace systemASR1001=1ASR1002-FReplace systemASR1002-X=1",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": "Automation is matching only on PID.   Automation is not checking if the software fix is in place as identified in the Field Notice.  See Field Notice for additional manual checks.",
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/637/fn63764.html"
        },
        {
            "fieldNoticeId": 63765,
            "status": "P",
            "bulletinLastUpdated": "2018-09-10T00:00:00Z",
            "bulletinTitle": "FN63765 - Some 7200/7300 Products Might Fail to Boot Up After a Power Cycle - Replace on Failure",
            "bulletinFirstPublished": "2014-03-03T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "Some 7200/7300 products might fail to boot up after user actions where the board requires a power cycle operation.",
            "background": "Cisco has been working with some customers on an issue related to memory components manufactured by a single supplier between 2005 and 2010. These memory components are widely used across the industry and are included in a number of Cisco products.Although the majority of Cisco products using these components are experiencing field failure rates below expected levels, some components may fail earlier than anticipated. A handful of our customers have recently experienced a higher number of failures, leading us to change our approach to managing this issue.While other vendors have chosen to address this issue in different ways, Cisco believes its approach is the best course of action for its customers. Despite the cost, we are demonstrating that we always make customer satisfaction a top priority. Customers can learn more about this topic at Memory Component Issue web page.PLEASE NOTE - The products listed in this Field Notice have lower than expected failure rates. This assessment is based on actual usage of affected memory components, observed field failure rates and product replacements since 2012.A degraded component will not affect the ongoing operation of a device, but will be exposed by a subsequent power cycle event. This event will result in a hard failure of the device, which cannot be recovered by a reboot or additional power cycle. For these reasons, additional caution is recommended for operational activities requiring the simultaneous power cycling of multiple devices. This issue has been observed most commonly on devices that have been in service for 24 months or more.",
            "problemSymptoms": "If the suspected hardware has been in operation for approximately 24 months, the product hardware might fail to boot up due to memory failure during a power cycle event. This is caused by one of more of these actions:     Power cycle the chassisOnline Insertion Removal/Replacement (OIR)    Note: This issue does not affect boards while  in operation. The board failure might occur after  one or more of the actions listed is executed.  These are the linecard symptoms observed:                  NPE-G1          The card does not boot to ROMMON.                   NPE-G2          The card does not boot to ROMMON, and the SYST STAT LED on the front panel  repeatedly blinks yellow.                   7300-NSE-150, 7304-NPE-G100          The card does not boot to ROMMON, and the Active, Standby, and System-Up LEDs remain solid yellow.                   7300-CC-PA          00:00:33: %PACC-3-NOPATYPE: No port adapter type obtained for slot [x] 00:00:33: %LC-3-DEACTIVATED: line card in slot [x] deactivated.          PA-2T3/E3-EC, PA-MC-2T3-EC, PA-MC-T3-EC, PA-T3/E3-EC After a power up of the affected port adapter, you might see one of these error messages on the console or in the log:T3E3_EC-3-PA_SW_ERR: T3E3_EC on 3: incorrect number of pci devices found Software error was encountered. T3E3 EC image size too big T3E3 EC image location not setup firmware_download_verify failed for RTOS image firmware_download_verify failed for APPS image pa_t3e3_ec__analyze_pa t3e3_ec_port_init failed for port x T3E3_EC failed to initialize T3E3_EC_TASK Then, this message displays: PA-3-DEACTIVATED: port adapter in bay [x] powered off.         C7200-VSA Nitrox Memory VSA n2_verify_ddr_mem nitrox_mult_rd_ddr_ram failed (0x0, 10485760, 0) VSA ERROR: DDR Verification (0x0, 0xA00000, 0x12345678) Failed VSA test_nitrox_ddr(0x0608DA20) failed VSA OIR FAILED, state is 1 FPGA Memory When the SA RAM fails, you may notice the following CLI output: %CRYPTO-4-RECVD_PKT_INV_SPI: decaps: rec'd IPSEC packet has invalid spi fordestaddr=11.0.0.41, prot=50, spi=0xCED7831(216889393), srcaddr=11.0.0.61,input interface=GigabitEthernet0/3         Once you receive this CLI output, you might query the status for the SA Error Register in order to confirm that an error has occurred: show pas vsa info  inc ERR 0x800C SA_ERR_REG 0x00000020",
            "workaround": "Normal SmartNet and warranty entitlement rules remain in place and are applied by the Cisco Technical Assistance Center (TAC) if you experience a failure in one of the products listed in the Field Notice. In other circumstances, such as out of warranty or out of contract, Cisco encourages you to raise your concern directly with your Cisco account team.Fix on Failure Replacement Guidelines: Request Return Material Authorization (RMA) product through normal service support channels.If you need assistance in order to determine which hardware part(s) might need replacement, consult the error messages documented in the Problem Symptom section.PIDActionPID ReplacementQuantity7300-CC-PAReplace card7300-CC-PA=17300-NSE-150Replace card7300-NSE-150=17304-NPE-G100Replace card7304-NPE-G100=1C7200-VSAReplace cardC7200-VSA=1NPE-G1Replace cardNPE-G1=1NPE-G2Replace cardNPE-G2=1PA-2T3/E3-ECReplace cardPA-2T3/E3-EC=1PA-MC-2T3-ECReplace cardPA-MC-2T3-EC=1PA-T3/E3-ECReplace cardPA-T3/E3-EC=1PA-MC-T3-ECReplace cardPA-MC-T3-EC=1End of Support      PID    End of Support Notice    End of Support Date        7300-CC-PA(=)    EOL6972    31-Jul-2015        7300-NSE-150(=)    EOL6972    31-Jul-2015        7304-NPE-6100(=)    EOL6972    31-Jul-2015",
            "hardwareLevels": "",
            "upgradeProgram": "",
            "caveat": null,
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/637/fn63765.html"
        },
        {
            "fieldNoticeId": 63770,
            "status": "P",
            "bulletinLastUpdated": "2018-10-11T00:00:00Z",
            "bulletinTitle": "FN63770 - WLC21XX, WLC44XX, WiSM Might Fail to Boot Up After a Software Upgrade or Power Cycle - Replace on Failure",
            "bulletinFirstPublished": "2014-03-03T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "WLC21XX, WLC44XX, and WiSM might fail to boot up after a software upgrade or other user actions where the unit requires a power cycle operation.",
            "background": "Cisco has been working with some customers on an issue related to memory components manufactured by a single supplier between 2005 and 2010. These memory components are widely used across the industry and are included in a number of Cisco products.Although the majority of Cisco products using these components are experiencing field failure rates below expected levels, some components may fail earlier than anticipated. A handful of our customers have recently experienced a higher number of failures, leading us to change our approach to managing this issue.While other vendors have chosen to address this issue in different ways, Cisco believes its approach is the best course of action for its customers. Despite the cost, we are demonstrating that we always make customer satisfaction a top priority. Customers can learn more about this topic at Memory Component Issue web page.PLEASE NOTE: The products listed in this Field Notice have lower than expected failure rates. This assessment is based on actual usage of affected memory components, observed field failure rates and product replacements since 2012.A degraded component will not affect the ongoing operation of a device, but will be exposed by a subsequent power cycle event. This event will result in a hard failure of the device, which cannot be recovered by a reboot or additional power cycle. For these reasons, additional caution is recommended for operational activities requiring the simultaneous power cycling of multiple devices. This issue has been observed most commonly on devices that have been in service for 24 months or more.",
            "problemSymptoms": "If the suspected product has been in operation for approximately 24 months, the product hardware might fail to boot up due to memory failure during a power cycle event. This is caused by one or more of these actions:- Upgrade the software- Reboot the system- Power cycleNote: This issue does not affect units while the units are in operation. The unit failure might occur after one or more of the actions listed are executed.These product symptoms are observed:The AP does not bootThe status LED is solid orange",
            "workaround": "Normal SmartNet and warranty entitlement rules remain in place and are applied by the Cisco Technical Assistance Center (TAC) if you experience a failure in one of the products listed in the Field Notice. In other circumstances, such as out of warranty or out of contract, Cisco encourages you to raise your concern directly with your Cisco account team.Fix on Failure Replacement Guidelines: Request Return Material Authorization (RMA) product through normal service support channels.If you need assistance in order to determine which hardware part(s) might need replacement, consult the error messages documented in the Problem Symptom section.End of Support",
            "hardwareLevels": "",
            "upgradeProgram": "",
            "caveat": null,
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/637/fn63770.html"
        },
        {
            "fieldNoticeId": 63771,
            "status": "P",
            "bulletinLastUpdated": "2018-10-11T00:00:00Z",
            "bulletinTitle": "FN63771 - ONS 15310 and ONS 15454 - Products Affected Might Fail to Boot After Power Cycle - Replace on Failure",
            "bulletinFirstPublished": "2014-03-03T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "The ONS 15310 and ONS 15454 cards (listed in the Products Affected section) might fail to boot up after a user action where the board requires a power cycle operation.",
            "background": "Cisco has been working with some customers on an issue related to memory components manufactured by a single supplier between 2005 and 2010. These memory components are widely used across the industry and are included in a number of Cisco products.Although the majority of Cisco products using these components are experiencing field failure rates below expected levels, some components may fail earlier than anticipated. A handful of our customers have recently experienced a higher number of failures, leading us to change our approach to managing this issue.While other vendors have chosen to address this issue in different ways, Cisco believes its approach is the best course of action for its customers. Despite the cost, we are demonstrating that we always make customer satisfaction a top priority. Customers can learn more about this topic at the Memory Component Issue web page.PLEASE NOTE - The products listed in this Field Notice have lower than expected failure rates. This assessment is based on actual usage of affected memory components, observed field failure rates and product replacements since 2012.A degraded component will not affect the ongoing operation of a device, but will be exposed by a subsequent power cycle event. This event will result in a hard failure of the device, which cannot be recovered by a reboot or additional power cycle. For these reasons, additional caution is recommended for operational activities requiring the simultaneous power cycling of multiple devices. This issue has been observed most commonly on devices that have been in service for 24 months or more.",
            "problemSymptoms": "If the suspected hardware (listed in the Products Affected section) has been in operation for approximately 24 months, then the hardware might fail to boot up due to memory failure during a power cycle event. This is caused by one or more of these actions:- Power cycle the product- Online Insertion Removal/Replacement (OIR)Note: This issue does not affect boards while the boards are in operation. The board failure might occur after one or more of the actions listed are executed.",
            "workaround": "Normal SmartNet and warranty entitlement rules remain in place and are applied by the Cisco Technical Assistance Center (TAC) if you experience a failure in one of the products listed in the Field Notice. In other circumstances, such as out of warranty or out of contract, Cisco encourages you to raise your concern directly with your Cisco account team.Fix on Failure Replacement Guidelines: Request Return Material Authorization (RMA) product through normal service support channels.Note that Product 15454-FC-MR-4 will not be supported.Product IDEnd of Support NoticeEnd of Support Date15454-FC-MR-4EOL711730-June-2016   If you need assistance in order to determine which hardware part(s) might need replacement, consult the error messages documented in the Problem Symptom section.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": "Automation is matching only on PID.  See Field Notice for additional manual checks.",
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/637/fn63771.html"
        },
        {
            "fieldNoticeId": 63772,
            "status": "P",
            "bulletinLastUpdated": "2018-10-11T00:00:00Z",
            "bulletinTitle": "FN63772 - IP Phones - May Fail to Boot-Up After A Power Cycle - Replace on Failure",
            "bulletinFirstPublished": "2014-03-03T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "IP Phones (listed in the Products Affected section) might fail to boot up after any power cycle event on the phone. This can be from a power cube, Power over Ethernet (PoE), or a recycle of the access switch while PoE is in use.\r\n\r\nPhones that fail remain in a stalled boot-up state where the LCD is blank and the speakerphone lamp is lit. The phone will no longer recover back to an operational state.",
            "background": "Cisco has been working with some customers on an issue related to memory components manufactured by a single supplier between 2009 and 2011. These memory components are widely used across the industry and are included in a number of Cisco products.\r\n\r\nAlthough the majority of Cisco products using these components are experiencing field failure rates below expected levels, some components may fail earlier than anticipated. A handful of our customers have recently experienced a higher number of failures, leading us to change our approach to managing this issue.\r\n\r\nWhile  other vendors have chosen to address this issue in different ways, Cisco  believes its approach is the best course of action for its customers. Despite  the cost, we are demonstrating that we always make customer satisfaction a top  priority. Customers can learn more about this topic at <a href=\"http://www.cisco.com/go/memory\">Memory Component Issue</a> web page.\r\n\r\n\r\nPLEASE NOTE - The products listed in this Field Notice have lower than expected failure rates. This assessment is based on actual usage of affected memory components, observed field failure rates and product replacements since 2012.\r\n\r\nA degraded component will not affect the ongoing operation of a device, but will be exposed by a subsequent power cycle event. This event will result in a hard failure of the device, which cannot be recovered by a reboot or additional power cycle. For these reasons, additional caution is recommended for operational activities requiring the simultaneous power cycling of multiple devices. This issue has been observed most commonly on devices that have been in service for 24 months or more.",
            "problemSymptoms": "If the suspected hardware has been in operation for approximately 24 months, the product hardware might fail to boot up due to memory failure during a power cycle event caused by one or more of these conditions: \r\n \r\n- Power cycle from a power cube\r\n- PoE\r\n- Recycle of the access switch while PoE is in use\r\n\r\n<b>Note:</b> The issue does not affect boards while the boards are in operation. The board failure might occur after one or more of the above conditions are met.\r\n\r\nAfter a power cycle event, the memory might malfunction which leads to a boot-up failure. The failure would be a hard failure, that is, it cannot recover with another power cycle or reboot. This issue might be observed on suspect hardware after approximately 24 months in operation.",
            "workaround": "Normal SmartNet and warranty entitlement rules remain in place and are applied by the Cisco Technical Assistance Center (TAC) if you experience a failure in one of the products listed in the Field Notice. In other circumstances, such as out of warranty or out of contract, Cisco encourages you to raise your concern directly with your Cisco account team.\r\nFix on failure Replacement Guidelines: Request Return Material Authorization (RMA) product through normal service support channels.\r\nFor the CP-7962G(=) phone, the replacement PID is the CP-7965G(=) phone. \r\nIf you need assistance in order to determine which hardware part(s) might need replacement, consult the error messages documented in the Problem Symptom section. PSE NOTE: THE WORDING BELOW WILL REQUIRE SOME MODIFICATION PRIOR TO SENDING THIS FIELD NOTICE OUT FOR REVIEW. IN ADDITION, THIS SENTENCE SHOULD BE DELETED PRIOR TO THE REVIEW PHASE.",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/637/fn63772.html"
        },
        {
            "fieldNoticeId": 63773,
            "status": "P",
            "bulletinLastUpdated": "2018-09-20T00:00:00Z",
            "bulletinTitle": "FN63773 - SPA Modules Might Fail to Boot After a Software Upgrade or Power Cycle - Replace on Failure",
            "bulletinFirstPublished": "2014-03-03T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "The Cisco SPA Modules (listed in the Products Affected section) might fail to boot up after a software upgrade or other user action where the board requires a power cycle operation.",
            "background": "Cisco has been working with some customers on an issue related to memory components manufactured by a single supplier between 2005 and 2010. These memory components are widely used across the industry and are included in a number of Cisco products.\r\n\r\nAlthough the majority of Cisco products using these components are experiencing field failure rates below expected levels, some components may fail earlier than anticipated. A handful of our customers have recently experienced a higher number of failures, leading us to change our approach to managing this issue.\r\n\r\nWhile other vendors have chosen to address this issue in different ways, Cisco believes its approach is the best course of action for its customers. Despite the cost, we are demonstrating that we always make customer satisfaction a top priority. Customers can learn more about this topic at the <a href=\"www.cisco.com/go/memory\">Memory Component Issue</a> web page.\r\n\r\nA degraded component will not affect the ongoing operation of a device, but will be exposed by a subsequent power cycle event. This event will result in a hard failure of the device, which cannot be recovered by a reboot or additional power cycle. For these reasons, additional caution is recommended for operational activities requiring the simultaneous power cycling of multiple devices. This issue has been observed most commonly on devices that have been in service for 24 months or more.",
            "problemSymptoms": "If the suspected hardware (listed in the Products Affected section) has been in operation for approximately 24 months, then the hardware might fail to boot up due to memory failure during a power cycle event. This is caused by one or more of these actions:\r\n \r\n- Upgrade the software \r\n- Reload the entire product \r\n- Reload after installation \r\n- Online Insertion Removal/Replacement (OIR)\r\n\r\nSPA may come up but interface remain in down state. This can be verified through CLI for ( SPA-2XCHOC12/DS0, SPA-1XCHOC12/DS0)\r\n\r\n<b>Log to refer for error message:</b>\r\n \r\n<i>o show hw-module subslot <> errors fpga\r\nNetwork Proc  = 218\r\nFramer-2    = 389   <??Here\r\n\r\no sloginfo\r\n\r\nNov 03 05:51:21 nto chop_cema_app: --------End of SPI3 Status Dump-------\r\n\r\nNov 03 05:51:21 nto chop_cema_app: handleTigrisInterrupt: Tigris miscellaneous error #21 >>>\r\n\r\n<b>For IOS routers:</b>\r\n\r\n\r\no conft\r\n\r\no service int\r\n\r\no end\r\n\r\no ASR1k: ipc-con <slot> <bay>  (or)  7600:attach <slot>  ===== to enter into LC console\r\n\r\no enable\r\n\r\no sh hw-module subslot <bay> errors fpga\r\n\r\no Type \"^C^C^C\" to end this session\r\n\r\no attach <slot> spa <bay>\r\n\r\no sloginfo | less\r\n\r\no Type \"^C^C^C\" to end this session\r\n\r\n<b>For XR routers:</b>\r\n\r\no show hw-module subslot <Rack/Slot/Bay> errors fpga\r\n\r\no run attach <Rack/Slot/CPU0>\r\n\r\no spa_attach -fnode<Rack_slot_bay>\r\n\r\no sloginfo | less\r\n\r\no quit\r\n\r\no exit\r\n\r\n<i>\r\n\r\n<b>Note:</b> This issue does not affect boards while the boards are in operation. The board failure might occur after one or more of the actions listed are executed.",
            "workaround": "Normal SmartNet and warranty entitlement rules remain in place and are applied by the Cisco Technical Assistance Center (TAC) if you experience a failure in one of the products listed in the Field Notice. In other circumstances, such as out of warranty or out of contract, Cisco encourages you to raise your concern directly with your Cisco account team. \r\n\r\nFix on Failure Replacement Guidelines: Request Return Material Authorization (RMA) product through normal service support channels.\r\n\r\nIf you need assistance in order to determine which hardware part(s) might need replacement, consult the Logs to refer  documented in the Problem Symptom section.\r\n\r\nPlease refer to this table for the appropriate Product ID (PID) replacement:\r\n<TABLE BORDER='1' CELLPADDING='0' CELLSPACING='2'><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>PID</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Action</FONT></TD>\r\n<TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>PID Replacement</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Quantity</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>SPA-4XT-SERIAL</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Replace card</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>SPA-4XT-SERIAL=</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>1</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>SPA-IPSEC-2G</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Replace card</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>SPA-IPSEC-2G=</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>1</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>SPA-2XOC3-ATM</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Replace card</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>SPA-2XOC3-ATM=</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>1</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>SPA-1XOC48-ATM</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Replace card</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>SPA-1XOC48-ATM=</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>1</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>SPA-1XOC12-ATM</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Replace card</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>SPA-1XOC12-ATM=</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>1</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>SPA-1XCHOC12/DS0</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Replace card</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>SPA-1XCHOC12/DS0=</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>1</FONT></TD></TR>\r\n<TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>SPA-2XCHOC12/DS0</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Replace card</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>SPA-2XCHOC12/DS0=</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>1</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>SPA-3XOC3-ATM-V2</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Replace card</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>SPA-3XOC3-ATM-V2=</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>1</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>SPA-4XOC3-ATM</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Replace card</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>SPA-3XOC3-ATM-V2=</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>1</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>SPA-1XOC3-ATM-V2</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Replace card</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>SPA-1XOC3-ATM-V2=</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>1</FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>SPA-1XOC12-ATM-V2</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>Replace card</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>SPA-1XOC12-ATM-V2=</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>1</FONT></TD></TR></TABLE>\r\n\r\n\r\n<b> Notice Of End Of Support:</b>\r\n\r\n<TABLE BORDER='1' CELLPADDING='0' CELLSPACING='2'><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>PID</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>End Of Support Date </FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>End Of Support Note </FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>SPA-1XOC12-ATM</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>12/31/2016</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'><a href=\"http://www.cisco.com/c/en/us/products/collateral/interfaces-modules/shared-port-adapters-spa-interface-processors/eol_c51_639575.html/\">EOL7292</a></FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>SPA-2XOC3-ATM</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>12/31/2016</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'><a href=\"http://www.cisco.com/c/en/us/products/collateral/interfaces-modules/shared-port-adapters-spa-interface-processors/eol_c51_639578.html/\">EOL7290</a></FONT></TD></TR><TR><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>SPA-4XOC3-ATM</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'>12/31/2016</FONT></TD><TH BGCOLOR='#CCCCCC'><FONT COLOR='#000000'><a href=\"http://www.cisco.com/c/en/us/products/collateral/interfaces-modules/shared-port-adapters-spa-interface-processors/eol_c51_639576.html/\">EOL7291</a></FONT></TD></TR></TABLE>",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": "Automation is matching only on PID.  See Field Notice for additional manual checks.",
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/637/fn63773.html"
        },
        {
            "fieldNoticeId": 63774,
            "status": "P",
            "bulletinLastUpdated": "2018-09-20T00:00:00Z",
            "bulletinTitle": "FN63774 - MGX Cards Might Fail to Boot Up After a Software Upgrade or Power Cycle - Replace on Failure",
            "bulletinFirstPublished": "2014-03-03T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "MGX cards might fail to boot up after a software upgrade or other user actions where the board requires a power cycle operation.",
            "background": "Cisco has been working with some customers on an issue related to memory components manufactured by a single supplier between 2005 and 2010. These memory components are widely used across the industry and are included in a number of Cisco products.Although the majority of Cisco products using these components are experiencing field failure rates below expected levels, some components may fail earlier than anticipated. A handful of our customers have recently experienced a higher number of failures, leading us to change our approach to managing this issue.While other vendors have chosen to address this issue in different ways, Cisco believes its approach is the best course of action for its customers. Despite the cost, we are demonstrating that we always make customer satisfaction a top priority. Customers can learn more about this topic at Memory Component Issue web page.PLEASE NOTE: The products listed in this Field Notice have lower than expected failure rates. This assessment is based on actual usage of affected memory components, observed field failure rates and product replacements since 2012.A degraded component will not affect the ongoing operation of a device, but will be exposed by a subsequent power cycle event. This event will result in a hard failure of the device, which cannot be recovered by a reboot or additional power cycle. For these reasons, additional caution is recommended for operational activities requiring the simultaneous power cycling of multiple devices. This issue has been observed most commonly on devices that have been in service for 24 months or more.",
            "problemSymptoms": "If the suspected hardware has been in operation for approximately 24 months, the product hardware might fail to boot up due to memory failure during a power cycle event. This is caused by one or more of these actions:-Upgrade the software-Reload the entire product-Reload after installation-Online Insertion Removal/Replacement (OIR)Note: This issue does not affect boards while the boards are in operation. The board failure might occur after one or more of the actions listed are executed.",
            "workaround": "Normal SmartNet and warranty entitlement rules remain in place and are applied by the Cisco Technical Assistance Center (TAC) if you experience a failure in one of the products listed in the Field Notice. In other circumstances, such as out of warranty or out of contract, Cisco encourages you to raise your concern directly with your Cisco account team.Fix on Failure Replacement Guidelines: Request Return Material Authorization (RMA) product through normal service support channels.If you need assistance in order to determine which hardware part(s) might need replacement, consult the error messages documented in the Problem Symptom section.PIDActionPID ReplacementQuantityAXSM-16-155-XGReplace CardAXSM-16-155-XG=1AXSM-8-622-XGReplace CardAXSM-8-622-XG=1MGX-VXSM-155Replace CardMGX-VXSM-155=1MGX-VXSM-T1E1Replace CardMGX-VXSM-T1E1=1MPSM-16-T1E1Replace CardMPSM-16-T1E1=1MPSM-T3E3-155Replace CardMPSM-T3E3-155=1PXM45/CReplace CardPXM45/C=1End of Support PIDEnd of Support DateEOL NoticeAXSM-16-155-XG31-JUL-2016EOL7164AXSM-8-622-XG31-JUL-2016EOL7164MPSM-16-T1E131-JUL-2016EOL7165MPSM-T3E3-15531-JUL-2016EOL7165",
            "hardwareLevels": null,
            "upgradeProgram": null,
            "caveat": null,
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/637/fn63774.html"
        },
        {
            "fieldNoticeId": 63777,
            "status": "P",
            "bulletinLastUpdated": "2018-08-23T00:00:00Z",
            "bulletinTitle": "FN63777 - UC520/UC540 Might Fail to Boot After a Software Upgrade or Power Cycle - Replace on Failure",
            "bulletinFirstPublished": "2014-03-03T00:00:00Z",
            "distributionCode": "E",
            "fieldNoticeType": "H",
            "problemDescription": "",
            "background": "",
            "problemSymptoms": "",
            "workaround": "",
            "hardwareLevels": "",
            "upgradeProgram": "",
            "caveat": null,
            "url": "http://www.cisco.com/c/en/us/support/docs/field-notices/637/fn63777.html"
        }
    ],
    "Pagination": {
        "page": 1,
        "pages": 3,
        "rows": 100,
        "total": 283
    }
}